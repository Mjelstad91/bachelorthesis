<html>
<head><meta http-equiv=Content-Type content="text/html; charset=UTF-8">
<style type="text/css">
<!--
span.cls_002{font-family:Arial,serif;font-size:12.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
div.cls_002{font-family:Arial,serif;font-size:12.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
span.cls_003{font-family:Arial,serif;font-size:12.1px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
div.cls_003{font-family:Arial,serif;font-size:12.1px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
span.cls_004{font-family:Times,serif;font-size:12.1px;color:rgb(0,0,0);font-weight:bold;font-style:normal;text-decoration: none}
div.cls_004{font-family:Times,serif;font-size:12.1px;color:rgb(0,0,0);font-weight:bold;font-style:normal;text-decoration: none}
span.cls_005{font-family:Arial,serif;font-size:12.1px;color:rgb(0,0,0);font-weight:bold;font-style:normal;text-decoration: none}
div.cls_005{font-family:Arial,serif;font-size:12.1px;color:rgb(0,0,0);font-weight:bold;font-style:normal;text-decoration: none}
span.cls_007{font-family:Arial,serif;font-size:10.0px;color:rgb(0,0,0);font-weight:bold;font-style:normal;text-decoration: none}
div.cls_007{font-family:Arial,serif;font-size:10.0px;color:rgb(0,0,0);font-weight:bold;font-style:normal;text-decoration: none}
span.cls_008{font-family:Arial,serif;font-size:10.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
div.cls_008{font-family:Arial,serif;font-size:10.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
span.cls_009{font-family:Arial,serif;font-size:24.8px;color:rgb(0,0,0);font-weight:bold;font-style:normal;text-decoration: none}
div.cls_009{font-family:Arial,serif;font-size:24.8px;color:rgb(0,0,0);font-weight:bold;font-style:normal;text-decoration: none}
span.cls_010{font-family:Arial,serif;font-size:14.4px;color:rgb(0,0,0);font-weight:bold;font-style:normal;text-decoration: none}
div.cls_010{font-family:Arial,serif;font-size:14.4px;color:rgb(0,0,0);font-weight:bold;font-style:normal;text-decoration: none}
span.cls_011{font-family:Arial,serif;font-size:20.7px;color:rgb(0,0,0);font-weight:bold;font-style:normal;text-decoration: none}
div.cls_011{font-family:Arial,serif;font-size:20.7px;color:rgb(0,0,0);font-weight:bold;font-style:normal;text-decoration: none}
span.cls_012{font-family:"Calibri Light",serif;font-size:12.8px;color:rgb(45,116,181);font-weight:normal;font-style:normal;text-decoration: none}
div.cls_012{font-family:"Calibri Light",serif;font-size:12.8px;color:rgb(45,116,181);font-weight:normal;font-style:normal;text-decoration: none}
span.cls_014{font-family:"Calibri",serif;font-size:8.9px;color:rgb(31,72,124);font-weight:normal;font-style:normal;text-decoration: none}
div.cls_014{font-family:"Calibri",serif;font-size:8.9px;color:rgb(31,72,124);font-weight:normal;font-style:normal;text-decoration: none}
span.cls_027{font-family:"Calibri",serif;font-size:8.9px;color:rgb(4,98,193);font-weight:normal;font-style:normal;text-decoration: underline}
div.cls_027{font-family:"Calibri",serif;font-size:8.9px;color:rgb(4,98,193);font-weight:normal;font-style:normal;text-decoration: none}
span.cls_017{font-family:Arial,serif;font-size:12.0px;color:rgb(0,0,0);font-weight:bold;font-style:normal;text-decoration: none}
div.cls_017{font-family:Arial,serif;font-size:12.0px;color:rgb(0,0,0);font-weight:bold;font-style:normal;text-decoration: none}
span.cls_018{font-family:Arial,serif;font-size:7.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
div.cls_018{font-family:Arial,serif;font-size:7.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
span.cls_019{font-family:Arial,serif;font-size:5.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
div.cls_019{font-family:Arial,serif;font-size:5.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
span.cls_028{font-family:Arial,serif;font-size:10.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: line-through}
div.cls_028{font-family:Arial,serif;font-size:10.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
span.cls_020{font-family:Arial,serif;font-size:9.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
div.cls_020{font-family:Arial,serif;font-size:9.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
span.cls_021{font-family:Arial,serif;font-size:11.2px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
div.cls_021{font-family:Arial,serif;font-size:11.2px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
span.cls_022{font-family:Arial,serif;font-size:10.6px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
div.cls_022{font-family:Arial,serif;font-size:10.6px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
span.cls_023{font-family:Arial,serif;font-size:10.6px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
div.cls_023{font-family:Arial,serif;font-size:10.6px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
span.cls_024{font-family:Arial,serif;font-size:9.2px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
div.cls_024{font-family:Arial,serif;font-size:9.2px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
span.cls_025{font-family:Arial,serif;font-size:8.7px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
div.cls_025{font-family:Arial,serif;font-size:8.7px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
span.cls_026{font-family:Arial,serif;font-size:9.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
div.cls_026{font-family:Arial,serif;font-size:9.0px;color:rgb(0,0,0);font-weight:normal;font-style:normal;text-decoration: none}
-->
</style>
<script type="text/javascript" src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/wz_jsgraphics.js"></script>
</head>
<body>
<div style="position:absolute;left:50%;margin-left:-297px;top:0px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background001.jpg" width=595 height=841></div>
<div style="position:absolute;left:155.73px;top:326.14px" class="cls_002"><span class="cls_002">FACULTY OF TECHNOLOGY, ART AND DESIGN</span></div>
<div style="position:absolute;left:145.15px;top:376.09px" class="cls_002"><span class="cls_002">Anomaly Detection on the Norwegian Tax Administrations</span></div>
<div style="position:absolute;left:154.06px;top:390.04px" class="cls_002"><span class="cls_002">Production Data using Unsupervised Machine Learning</span></div>
<div style="position:absolute;left:266.55px;top:403.98px" class="cls_002"><span class="cls_002">Techniques</span></div>
<div style="position:absolute;left:265.70px;top:489.93px" class="cls_002"><span class="cls_002">Supervisors:</span></div>
<div style="position:absolute;left:176.32px;top:503.88px" class="cls_002"><span class="cls_002">Anis Yazidi, Stefano Nichele, Nader Aeinehchi</span></div>
<div style="position:absolute;left:274.52px;top:536.44px" class="cls_002"><span class="cls_002">Authors:</span></div>
<div style="position:absolute;left:188.51px;top:550.38px" class="cls_002"><span class="cls_002">Kim Mikal Torp, Øyvind Innvær Mjelstad</span></div>
<div style="position:absolute;left:210.46px;top:564.33px" class="cls_002"><span class="cls_002">André Fagereng, August Reinholt</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:851px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background002.jpg" width=595 height=841></div>
<div style="position:absolute;left:407.91px;top:31.43px" class="cls_003"><span class="cls_003">PROSJEKT NR.</span></div>
<div style="position:absolute;left:407.91px;top:45.35px" class="cls_003"><span class="cls_003">22</span></div>
<div style="position:absolute;left:167.65px;top:58.31px" class="cls_004"><span class="cls_004">Institutt for Informasjonsteknologi</span></div>
<div style="position:absolute;left:101.41px;top:71.99px" class="cls_003"><span class="cls_003">Postadresse: Postboks 4 St. Olavs plass, 0130 Oslo</span></div>
<div style="position:absolute;left:407.19px;top:71.75px" class="cls_003"><span class="cls_003">TILGJENGELIGHET</span></div>
<div style="position:absolute;left:101.41px;top:85.92px" class="cls_003"><span class="cls_003">Besøksadresse: Holbergs plass, Oslo</span></div>
<div style="position:absolute;left:407.19px;top:85.92px" class="cls_003"><span class="cls_003">Privat</span></div>
<div style="position:absolute;left:445.88px;top:106.08px" class="cls_003"><span class="cls_003">Telefon: 22 45 32 00</span></div>
<div style="position:absolute;left:198.80px;top:129.60px" class="cls_005"><span class="cls_005">BACHELORPROSJEKT</span></div>
<div style="position:absolute;left:103.81px;top:158.16px" class="cls_003"><span class="cls_003">HOVEDPROSJEKTETS  TITTEL</span></div>
<div style="position:absolute;left:416.55px;top:158.16px" class="cls_003"><span class="cls_003">DATO</span></div>
<div style="position:absolute;left:103.81px;top:172.08px" class="cls_003"><span class="cls_003">Anomaly Detection on the Norwegian Tax Administrations</span></div>
<div style="position:absolute;left:416.55px;top:172.08px" class="cls_003"><span class="cls_003">23.05.19</span></div>
<div style="position:absolute;left:103.81px;top:186.00px" class="cls_003"><span class="cls_003">Production Data using Unsupervised Machine Learning</span></div>
<div style="position:absolute;left:103.81px;top:199.92px" class="cls_003"><span class="cls_003">Techniques</span></div>
<div style="position:absolute;left:416.55px;top:206.16px" class="cls_003"><span class="cls_003">ANTALL SIDER / BILAG</span></div>
<div style="position:absolute;left:416.55px;top:220.08px" class="cls_003"><span class="cls_003">126</span></div>
<div style="position:absolute;left:103.81px;top:254.16px" class="cls_003"><span class="cls_003">PROSJEKTDELTAKERE</span></div>
<div style="position:absolute;left:416.55px;top:254.16px" class="cls_003"><span class="cls_003">INTERN VEILEDER</span></div>
<div style="position:absolute;left:103.81px;top:268.08px" class="cls_003"><span class="cls_003">Kim Mikal Torp (s315278), Øyvind Innvær Mjelstad (s315273),</span></div>
<div style="position:absolute;left:416.55px;top:268.08px" class="cls_003"><span class="cls_003">Anis Yazidi, Stefano Nichele,</span></div>
<div style="position:absolute;left:103.81px;top:282.01px" class="cls_003"><span class="cls_003">August Reinholt (s301438), André Fagereng (s182417)</span></div>
<div style="position:absolute;left:103.81px;top:345.37px" class="cls_003"><span class="cls_003">OPPDRAGSGIVER</span></div>
<div style="position:absolute;left:416.55px;top:345.37px" class="cls_003"><span class="cls_003">KONTAKTPERSON</span></div>
<div style="position:absolute;left:103.81px;top:359.29px" class="cls_003"><span class="cls_003">Skatteetaten</span></div>
<div style="position:absolute;left:416.55px;top:359.29px" class="cls_003"><span class="cls_003">Nader Aeinehchi</span></div>
<div style="position:absolute;left:103.81px;top:408.01px" class="cls_003"><span class="cls_003">SAMMENDRAG</span></div>
<div style="position:absolute;left:103.81px;top:421.93px" class="cls_003"><span class="cls_003">Denne bacheloroppgaven er skrevet ved OsloMet i samarbeid med Skatteetaten. Gjennom</span></div>
<div style="position:absolute;left:103.81px;top:435.85px" class="cls_003"><span class="cls_003">prosjektperioden har vi anvendt fire forskjellige ”unsupervised”  maskinlæringsalgoritmer på</span></div>
<div style="position:absolute;left:103.81px;top:449.77px" class="cls_003"><span class="cls_003">reell data. Vi har preprossesert og tilpasset denne dataen til de ulike algoritmene. Dataen vi</span></div>
<div style="position:absolute;left:103.81px;top:463.69px" class="cls_003"><span class="cls_003">jobbet med stammer fra A-meldingen. A-meldingen er en rapport alle arbeidsgivere i Norge</span></div>
<div style="position:absolute;left:103.81px;top:477.61px" class="cls_003"><span class="cls_003">leverer til Skatteetaten hver måned. Resultatene har så blitt nøye evaluert og sjekket opp</span></div>
<div style="position:absolute;left:103.81px;top:491.54px" class="cls_003"><span class="cls_003">mot domeneeksperter.</span></div>
<div style="position:absolute;left:104.77px;top:662.66px" class="cls_003"><span class="cls_003">3 STIKKORD</span></div>
<div style="position:absolute;left:104.77px;top:691.23px" class="cls_003"><span class="cls_003">Anomaly Detection</span></div>
<div style="position:absolute;left:104.77px;top:705.15px" class="cls_003"><span class="cls_003">Unsupervised Learning</span></div>
<div style="position:absolute;left:104.77px;top:719.07px" class="cls_003"><span class="cls_003">Clustering</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:1702px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background003.jpg" width=595 height=841></div>
<div style="position:absolute;left:274.74px;top:275.67px" class="cls_007"><span class="cls_007">Abstract</span></div>
<div style="position:absolute;left:139.75px;top:297.59px" class="cls_008"><span class="cls_008">Anomaly detection has become an important field of research as companies</span></div>
<div style="position:absolute;left:124.80px;top:309.54px" class="cls_008"><span class="cls_008">turn towards obtaining and mining big data.  Through computations one can</span></div>
<div style="position:absolute;left:124.80px;top:321.50px" class="cls_008"><span class="cls_008">find trends and patterns that do not conform to the rest of the data. The ap-</span></div>
<div style="position:absolute;left:124.80px;top:333.46px" class="cls_008"><span class="cls_008">plication of anomaly detection ranges from intrusion detection and surveillance</span></div>
<div style="position:absolute;left:124.80px;top:345.41px" class="cls_008"><span class="cls_008">to data cleanup.</span></div>
<div style="position:absolute;left:139.75px;top:357.37px" class="cls_008"><span class="cls_008">This thesis serves as a proof of concept for the Norwegian Tax Administration</span></div>
<div style="position:absolute;left:124.80px;top:369.32px" class="cls_008"><span class="cls_008">(NTA), to give them an inclination of how anomaly detection techniques could</span></div>
<div style="position:absolute;left:124.80px;top:381.28px" class="cls_008"><span class="cls_008">be applied to their data and what challenges they might face.  Currently, if</span></div>
<div style="position:absolute;left:124.80px;top:393.23px" class="cls_008"><span class="cls_008">an anomaly gets through the already in-place countermeasures, the NTA does</span></div>
<div style="position:absolute;left:124.80px;top:405.19px" class="cls_008"><span class="cls_008">not have a system for discovering, nor handling those anomalies. The anomaly</span></div>
<div style="position:absolute;left:124.80px;top:417.14px" class="cls_008"><span class="cls_008">will then propagate through the system to other agencies such as NAV and</span></div>
<div style="position:absolute;left:124.80px;top:429.10px" class="cls_008"><span class="cls_008">Statistics Norway (SSB). The consequences can range from a transaction level</span></div>
<div style="position:absolute;left:124.80px;top:441.05px" class="cls_008"><span class="cls_008">loss to reputational damage and revenue loss due to fraud.</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:2553px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background004.jpg" width=595 height=841></div>
<div style="position:absolute;left:249.25px;top:364.01px" class="cls_007"><span class="cls_007">Acknowledgements</span></div>
<div style="position:absolute;left:124.80px;top:385.93px" class="cls_008"><span class="cls_008">The greatest appreciation to our internal advisers, Professor Anis Yazidi and</span></div>
<div style="position:absolute;left:124.80px;top:397.88px" class="cls_008"><span class="cls_008">Associate Professor Stefano Nichele, for their continuous encouragement and</span></div>
<div style="position:absolute;left:124.80px;top:409.84px" class="cls_008"><span class="cls_008">sharing of their expertise.  Thanks to the OsloMet AI Lab for letting us use</span></div>
<div style="position:absolute;left:124.80px;top:421.80px" class="cls_008"><span class="cls_008">their facilities.</span></div>
<div style="position:absolute;left:139.75px;top:433.75px" class="cls_008"><span class="cls_008">A big thanks to our external supervisor, Nader Aeinehchi, for helping us</span></div>
<div style="position:absolute;left:124.80px;top:445.71px" class="cls_008"><span class="cls_008">with time management, managing stand-up meetings every week and providing</span></div>
<div style="position:absolute;left:124.80px;top:457.66px" class="cls_008"><span class="cls_008">us with what we needed throughout the semester.</span></div>
<div style="position:absolute;left:139.75px;top:469.62px" class="cls_008"><span class="cls_008">Also thanks to Stian Simble Berglund and Wenche Tjelle Solbjør from the</span></div>
<div style="position:absolute;left:124.80px;top:481.57px" class="cls_008"><span class="cls_008">Norwegian Tax Administration for providing excellent domain knowledge.</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:3404px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background005.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:189.78px" class="cls_009"><span class="cls_009">Contents</span></div>
<div style="position:absolute;left:124.80px;top:266.38px" class="cls_007"><span class="cls_007">1</span></div>
<div style="position:absolute;left:139.75px;top:266.38px" class="cls_007"><span class="cls_007">Introduction</span></div>
<div style="position:absolute;left:462.79px;top:266.38px" class="cls_007"><span class="cls_007">6</span></div>
<div style="position:absolute;left:139.75px;top:278.33px" class="cls_008"><span class="cls_008">1.1</span></div>
<div style="position:absolute;left:162.66px;top:278.33px" class="cls_008"><span class="cls_008">The Norwegian Tax Administration</span></div>
<div style="position:absolute;left:463.53px;top:278.33px" class="cls_008"><span class="cls_008">6</span></div>
<div style="position:absolute;left:139.75px;top:290.29px" class="cls_008"><span class="cls_008">1.2</span></div>
<div style="position:absolute;left:162.66px;top:290.29px" class="cls_008"><span class="cls_008">A-ordningen</span></div>
<div style="position:absolute;left:463.54px;top:290.29px" class="cls_008"><span class="cls_008">6</span></div>
<div style="position:absolute;left:139.75px;top:302.24px" class="cls_008"><span class="cls_008">1.3</span></div>
<div style="position:absolute;left:162.66px;top:302.24px" class="cls_008"><span class="cls_008">A-meldingen</span></div>
<div style="position:absolute;left:463.53px;top:302.24px" class="cls_008"><span class="cls_008">7</span></div>
<div style="position:absolute;left:139.75px;top:314.20px" class="cls_008"><span class="cls_008">1.4</span></div>
<div style="position:absolute;left:162.66px;top:314.20px" class="cls_008"><span class="cls_008">Motivation</span></div>
<div style="position:absolute;left:463.53px;top:314.20px" class="cls_008"><span class="cls_008">7</span></div>
<div style="position:absolute;left:139.75px;top:326.15px" class="cls_008"><span class="cls_008">1.5</span></div>
<div style="position:absolute;left:162.66px;top:326.15px" class="cls_008"><span class="cls_008">Goal</span></div>
<div style="position:absolute;left:463.54px;top:326.15px" class="cls_008"><span class="cls_008">7</span></div>
<div style="position:absolute;left:139.75px;top:338.11px" class="cls_008"><span class="cls_008">1.6</span></div>
<div style="position:absolute;left:162.66px;top:338.11px" class="cls_008"><span class="cls_008">Contract</span></div>
<div style="position:absolute;left:463.53px;top:338.11px" class="cls_008"><span class="cls_008">8</span></div>
<div style="position:absolute;left:124.80px;top:360.03px" class="cls_007"><span class="cls_007">2</span></div>
<div style="position:absolute;left:139.75px;top:360.03px" class="cls_007"><span class="cls_007">Work Process and Methodology</span></div>
<div style="position:absolute;left:462.78px;top:360.03px" class="cls_007"><span class="cls_007">9</span></div>
<div style="position:absolute;left:139.75px;top:371.98px" class="cls_008"><span class="cls_008">2.1</span></div>
<div style="position:absolute;left:162.66px;top:371.98px" class="cls_008"><span class="cls_008">Initial project planning</span></div>
<div style="position:absolute;left:463.53px;top:371.98px" class="cls_008"><span class="cls_008">9</span></div>
<div style="position:absolute;left:162.66px;top:383.94px" class="cls_008"><span class="cls_008">2.1.1</span></div>
<div style="position:absolute;left:194.54px;top:383.94px" class="cls_008"><span class="cls_008">Startup phase</span></div>
<div style="position:absolute;left:458.55px;top:383.94px" class="cls_008"><span class="cls_008">10</span></div>
<div style="position:absolute;left:162.66px;top:395.89px" class="cls_008"><span class="cls_008">2.1.2</span></div>
<div style="position:absolute;left:194.54px;top:395.89px" class="cls_008"><span class="cls_008">Data Analysis phase</span></div>
<div style="position:absolute;left:458.55px;top:395.89px" class="cls_008"><span class="cls_008">10</span></div>
<div style="position:absolute;left:162.66px;top:407.85px" class="cls_008"><span class="cls_008">2.1.3</span></div>
<div style="position:absolute;left:194.54px;top:407.85px" class="cls_008"><span class="cls_008">Development phase</span></div>
<div style="position:absolute;left:458.55px;top:407.85px" class="cls_008"><span class="cls_008">10</span></div>
<div style="position:absolute;left:162.66px;top:419.80px" class="cls_008"><span class="cls_008">2.1.4</span></div>
<div style="position:absolute;left:194.54px;top:419.80px" class="cls_008"><span class="cls_008">Analysis and Evaluation phase  . .</span></div>
<div style="position:absolute;left:458.55px;top:419.80px" class="cls_008"><span class="cls_008">10</span></div>
<div style="position:absolute;left:162.66px;top:431.76px" class="cls_008"><span class="cls_008">2.1.5</span></div>
<div style="position:absolute;left:194.54px;top:431.76px" class="cls_008"><span class="cls_008">Project Completion phase</span></div>
<div style="position:absolute;left:458.55px;top:431.76px" class="cls_008"><span class="cls_008">11</span></div>
<div style="position:absolute;left:139.75px;top:443.71px" class="cls_008"><span class="cls_008">2.2</span></div>
<div style="position:absolute;left:162.66px;top:443.71px" class="cls_008"><span class="cls_008">Project Management</span></div>
<div style="position:absolute;left:458.55px;top:443.71px" class="cls_008"><span class="cls_008">11</span></div>
<div style="position:absolute;left:162.66px;top:455.67px" class="cls_008"><span class="cls_008">2.2.1</span></div>
<div style="position:absolute;left:194.54px;top:455.67px" class="cls_008"><span class="cls_008">Meetings with the NTA</span></div>
<div style="position:absolute;left:458.55px;top:455.67px" class="cls_008"><span class="cls_008">11</span></div>
<div style="position:absolute;left:162.66px;top:467.62px" class="cls_008"><span class="cls_008">2.2.2</span></div>
<div style="position:absolute;left:194.54px;top:467.62px" class="cls_008"><span class="cls_008">Meetings with supervisors</span></div>
<div style="position:absolute;left:458.55px;top:467.62px" class="cls_008"><span class="cls_008">11</span></div>
<div style="position:absolute;left:162.66px;top:479.58px" class="cls_008"><span class="cls_008">2.2.3</span></div>
<div style="position:absolute;left:194.54px;top:479.58px" class="cls_008"><span class="cls_008">Dividing Tasks</span></div>
<div style="position:absolute;left:458.55px;top:479.58px" class="cls_008"><span class="cls_008">13</span></div>
<div style="position:absolute;left:124.80px;top:501.50px" class="cls_007"><span class="cls_007">3</span></div>
<div style="position:absolute;left:139.75px;top:501.50px" class="cls_007"><span class="cls_007">Theory</span></div>
<div style="position:absolute;left:457.05px;top:501.50px" class="cls_007"><span class="cls_007">14</span></div>
<div style="position:absolute;left:139.75px;top:513.45px" class="cls_008"><span class="cls_008">3.1</span></div>
<div style="position:absolute;left:162.66px;top:513.45px" class="cls_008"><span class="cls_008">Machine Learning</span></div>
<div style="position:absolute;left:458.55px;top:513.45px" class="cls_008"><span class="cls_008">14</span></div>
<div style="position:absolute;left:162.66px;top:525.41px" class="cls_008"><span class="cls_008">3.1.1</span></div>
<div style="position:absolute;left:194.54px;top:525.41px" class="cls_008"><span class="cls_008">Features</span></div>
<div style="position:absolute;left:458.55px;top:525.41px" class="cls_008"><span class="cls_008">14</span></div>
<div style="position:absolute;left:162.66px;top:537.36px" class="cls_008"><span class="cls_008">3.1.2</span></div>
<div style="position:absolute;left:194.54px;top:537.36px" class="cls_008"><span class="cls_008">Supervised Learning</span></div>
<div style="position:absolute;left:458.55px;top:537.36px" class="cls_008"><span class="cls_008">15</span></div>
<div style="position:absolute;left:162.66px;top:549.32px" class="cls_008"><span class="cls_008">3.1.3</span></div>
<div style="position:absolute;left:194.54px;top:549.32px" class="cls_008"><span class="cls_008">Unsupervised Learning</span></div>
<div style="position:absolute;left:458.55px;top:549.32px" class="cls_008"><span class="cls_008">15</span></div>
<div style="position:absolute;left:139.75px;top:561.27px" class="cls_008"><span class="cls_008">3.2</span></div>
<div style="position:absolute;left:162.66px;top:561.27px" class="cls_008"><span class="cls_008">Anomaly Detection</span></div>
<div style="position:absolute;left:458.55px;top:561.27px" class="cls_008"><span class="cls_008">15</span></div>
<div style="position:absolute;left:139.75px;top:573.23px" class="cls_008"><span class="cls_008">3.3</span></div>
<div style="position:absolute;left:162.66px;top:573.23px" class="cls_008"><span class="cls_008">Clustering</span></div>
<div style="position:absolute;left:458.55px;top:573.23px" class="cls_008"><span class="cls_008">15</span></div>
<div style="position:absolute;left:162.66px;top:585.18px" class="cls_008"><span class="cls_008">3.3.1</span></div>
<div style="position:absolute;left:194.54px;top:585.18px" class="cls_008"><span class="cls_008">K-means Clustering</span></div>
<div style="position:absolute;left:458.55px;top:585.18px" class="cls_008"><span class="cls_008">15</span></div>
<div style="position:absolute;left:162.66px;top:597.14px" class="cls_008"><span class="cls_008">3.3.2</span></div>
<div style="position:absolute;left:194.54px;top:597.14px" class="cls_008"><span class="cls_008">Density-Based Spatial Clustering of Applications with Noise</span></div>
<div style="position:absolute;left:458.55px;top:597.14px" class="cls_008"><span class="cls_008">18</span></div>
<div style="position:absolute;left:139.75px;top:609.09px" class="cls_008"><span class="cls_008">3.4</span></div>
<div style="position:absolute;left:162.66px;top:609.09px" class="cls_008"><span class="cls_008">Local Outlier Factor</span></div>
<div style="position:absolute;left:458.55px;top:609.09px" class="cls_008"><span class="cls_008">21</span></div>
<div style="position:absolute;left:139.75px;top:621.05px" class="cls_008"><span class="cls_008">3.5</span></div>
<div style="position:absolute;left:162.66px;top:621.05px" class="cls_008"><span class="cls_008">Pattern Mining</span></div>
<div style="position:absolute;left:458.55px;top:621.05px" class="cls_008"><span class="cls_008">22</span></div>
<div style="position:absolute;left:162.66px;top:633.00px" class="cls_008"><span class="cls_008">3.5.1</span></div>
<div style="position:absolute;left:194.54px;top:633.00px" class="cls_008"><span class="cls_008">Frequent Pattern Mining</span></div>
<div style="position:absolute;left:458.55px;top:633.00px" class="cls_008"><span class="cls_008">23</span></div>
<div style="position:absolute;left:162.66px;top:644.96px" class="cls_008"><span class="cls_008">3.5.2</span></div>
<div style="position:absolute;left:194.54px;top:644.96px" class="cls_008"><span class="cls_008">Rare itemset Mining</span></div>
<div style="position:absolute;left:458.56px;top:644.96px" class="cls_008"><span class="cls_008">23</span></div>
<div style="position:absolute;left:139.75px;top:656.91px" class="cls_008"><span class="cls_008">3.6</span></div>
<div style="position:absolute;left:162.66px;top:656.91px" class="cls_008"><span class="cls_008">Euclidean metric</span></div>
<div style="position:absolute;left:458.55px;top:656.91px" class="cls_008"><span class="cls_008">25</span></div>
<div style="position:absolute;left:139.75px;top:668.87px" class="cls_008"><span class="cls_008">3.7</span></div>
<div style="position:absolute;left:162.66px;top:668.87px" class="cls_008"><span class="cls_008">Principal Component Analysis</span></div>
<div style="position:absolute;left:458.55px;top:668.87px" class="cls_008"><span class="cls_008">26</span></div>
<div style="position:absolute;left:139.75px;top:680.82px" class="cls_008"><span class="cls_008">3.8</span></div>
<div style="position:absolute;left:162.66px;top:680.82px" class="cls_008"><span class="cls_008">Packages and Tools</span></div>
<div style="position:absolute;left:458.55px;top:680.82px" class="cls_008"><span class="cls_008">26</span></div>
<div style="position:absolute;left:162.66px;top:692.78px" class="cls_008"><span class="cls_008">3.8.1</span></div>
<div style="position:absolute;left:194.54px;top:692.78px" class="cls_008"><span class="cls_008">Python</span></div>
<div style="position:absolute;left:458.55px;top:692.78px" class="cls_008"><span class="cls_008">26</span></div>
<div style="position:absolute;left:162.66px;top:704.73px" class="cls_008"><span class="cls_008">3.8.2</span></div>
<div style="position:absolute;left:194.54px;top:704.73px" class="cls_008"><span class="cls_008">Pandas</span></div>
<div style="position:absolute;left:458.55px;top:704.73px" class="cls_008"><span class="cls_008">26</span></div>
<div style="position:absolute;left:294.17px;top:740.60px" class="cls_008"><span class="cls_008">2</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:4255px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background006.jpg" width=595 height=841></div>
<div style="position:absolute;left:162.66px;top:124.91px" class="cls_008"><span class="cls_008">3.8.3</span></div>
<div style="position:absolute;left:194.54px;top:124.91px" class="cls_008"><span class="cls_008">Scikit-learn</span></div>
<div style="position:absolute;left:458.55px;top:124.91px" class="cls_008"><span class="cls_008">27</span></div>
<div style="position:absolute;left:162.66px;top:136.86px" class="cls_008"><span class="cls_008">3.8.4</span></div>
<div style="position:absolute;left:194.54px;top:136.86px" class="cls_008"><span class="cls_008">Matplotlib</span></div>
<div style="position:absolute;left:458.55px;top:136.86px" class="cls_008"><span class="cls_008">27</span></div>
<div style="position:absolute;left:162.66px;top:148.82px" class="cls_008"><span class="cls_008">3.8.5</span></div>
<div style="position:absolute;left:194.54px;top:148.82px" class="cls_008"><span class="cls_008">Numpy</span></div>
<div style="position:absolute;left:458.55px;top:148.82px" class="cls_008"><span class="cls_008">27</span></div>
<div style="position:absolute;left:162.66px;top:160.77px" class="cls_008"><span class="cls_008">3.8.6</span></div>
<div style="position:absolute;left:194.54px;top:160.77px" class="cls_008"><span class="cls_008">Server</span></div>
<div style="position:absolute;left:458.56px;top:160.77px" class="cls_008"><span class="cls_008">27</span></div>
<div style="position:absolute;left:162.66px;top:172.73px" class="cls_008"><span class="cls_008">3.8.7</span></div>
<div style="position:absolute;left:194.54px;top:172.73px" class="cls_008"><span class="cls_008">SSH</span></div>
<div style="position:absolute;left:458.55px;top:172.73px" class="cls_008"><span class="cls_008">27</span></div>
<div style="position:absolute;left:162.66px;top:184.68px" class="cls_008"><span class="cls_008">3.8.8</span></div>
<div style="position:absolute;left:194.54px;top:184.68px" class="cls_008"><span class="cls_008">Jupyter Notebook</span></div>
<div style="position:absolute;left:458.55px;top:184.68px" class="cls_008"><span class="cls_008">28</span></div>
<div style="position:absolute;left:124.80px;top:206.60px" class="cls_007"><span class="cls_007">4</span></div>
<div style="position:absolute;left:139.75px;top:206.60px" class="cls_007"><span class="cls_007">Data Analysis</span></div>
<div style="position:absolute;left:457.05px;top:206.60px" class="cls_007"><span class="cls_007">30</span></div>
<div style="position:absolute;left:139.75px;top:218.56px" class="cls_008"><span class="cls_008">4.1</span></div>
<div style="position:absolute;left:162.66px;top:218.56px" class="cls_008"><span class="cls_008">Data Structure</span></div>
<div style="position:absolute;left:458.55px;top:218.56px" class="cls_008"><span class="cls_008">30</span></div>
<div style="position:absolute;left:139.75px;top:230.51px" class="cls_008"><span class="cls_008">4.2</span></div>
<div style="position:absolute;left:162.66px;top:230.51px" class="cls_008"><span class="cls_008">Structural errors</span></div>
<div style="position:absolute;left:458.55px;top:230.51px" class="cls_008"><span class="cls_008">33</span></div>
<div style="position:absolute;left:139.75px;top:242.47px" class="cls_008"><span class="cls_008">4.3</span></div>
<div style="position:absolute;left:162.66px;top:242.47px" class="cls_008"><span class="cls_008">Correcting Errors in the A-melding</span></div>
<div style="position:absolute;left:458.55px;top:242.47px" class="cls_008"><span class="cls_008">33</span></div>
<div style="position:absolute;left:162.66px;top:254.42px" class="cls_008"><span class="cls_008">4.3.1</span></div>
<div style="position:absolute;left:194.54px;top:254.42px" class="cls_008"><span class="cls_008">Replacement ID</span></div>
<div style="position:absolute;left:458.55px;top:254.42px" class="cls_008"><span class="cls_008">34</span></div>
<div style="position:absolute;left:162.66px;top:266.38px" class="cls_008"><span class="cls_008">4.3.2</span></div>
<div style="position:absolute;left:194.54px;top:266.38px" class="cls_008"><span class="cls_008">Correction Messages</span></div>
<div style="position:absolute;left:458.55px;top:266.38px" class="cls_008"><span class="cls_008">34</span></div>
<div style="position:absolute;left:139.75px;top:278.33px" class="cls_008"><span class="cls_008">4.4</span></div>
<div style="position:absolute;left:162.66px;top:278.33px" class="cls_008"><span class="cls_008">Decoding</span></div>
<div style="position:absolute;left:458.55px;top:278.33px" class="cls_008"><span class="cls_008">34</span></div>
<div style="position:absolute;left:139.75px;top:290.29px" class="cls_008"><span class="cls_008">4.5</span></div>
<div style="position:absolute;left:162.66px;top:290.29px" class="cls_008"><span class="cls_008">Feature Extraction</span></div>
<div style="position:absolute;left:458.55px;top:290.29px" class="cls_008"><span class="cls_008">35</span></div>
<div style="position:absolute;left:139.75px;top:302.24px" class="cls_008"><span class="cls_008">4.6</span></div>
<div style="position:absolute;left:162.66px;top:302.24px" class="cls_008"><span class="cls_008">Missing values</span></div>
<div style="position:absolute;left:458.55px;top:302.24px" class="cls_008"><span class="cls_008">35</span></div>
<div style="position:absolute;left:139.75px;top:314.20px" class="cls_008"><span class="cls_008">4.7</span></div>
<div style="position:absolute;left:162.66px;top:314.20px" class="cls_008"><span class="cls_008">Normalization</span></div>
<div style="position:absolute;left:458.55px;top:314.20px" class="cls_008"><span class="cls_008">36</span></div>
<div style="position:absolute;left:139.75px;top:326.15px" class="cls_008"><span class="cls_008">4.8</span></div>
<div style="position:absolute;left:162.66px;top:326.15px" class="cls_008"><span class="cls_008">Visualizing the distribution of the dataset</span></div>
<div style="position:absolute;left:458.55px;top:326.15px" class="cls_008"><span class="cls_008">37</span></div>
<div style="position:absolute;left:124.80px;top:348.07px" class="cls_007"><span class="cls_007">5</span></div>
<div style="position:absolute;left:139.75px;top:348.07px" class="cls_007"><span class="cls_007">Implementing the algorithms</span></div>
<div style="position:absolute;left:457.05px;top:348.07px" class="cls_007"><span class="cls_007">43</span></div>
<div style="position:absolute;left:139.75px;top:360.03px" class="cls_008"><span class="cls_008">5.1</span></div>
<div style="position:absolute;left:162.66px;top:360.03px" class="cls_008"><span class="cls_008">Feature selection</span></div>
<div style="position:absolute;left:458.55px;top:360.03px" class="cls_008"><span class="cls_008">43</span></div>
<div style="position:absolute;left:162.66px;top:371.98px" class="cls_008"><span class="cls_008">5.1.1</span></div>
<div style="position:absolute;left:194.54px;top:371.98px" class="cls_008"><span class="cls_008">Categorical data</span></div>
<div style="position:absolute;left:458.55px;top:371.98px" class="cls_008"><span class="cls_008">44</span></div>
<div style="position:absolute;left:162.66px;top:383.94px" class="cls_008"><span class="cls_008">5.1.2</span></div>
<div style="position:absolute;left:194.54px;top:383.94px" class="cls_008"><span class="cls_008">Scaling the data</span></div>
<div style="position:absolute;left:458.55px;top:383.94px" class="cls_008"><span class="cls_008">45</span></div>
<div style="position:absolute;left:162.66px;top:395.89px" class="cls_008"><span class="cls_008">5.1.3</span></div>
<div style="position:absolute;left:194.54px;top:395.89px" class="cls_008"><span class="cls_008">Principal Component Analysis  .</span></div>
<div style="position:absolute;left:458.55px;top:395.89px" class="cls_008"><span class="cls_008">45</span></div>
<div style="position:absolute;left:139.75px;top:407.85px" class="cls_008"><span class="cls_008">5.2</span></div>
<div style="position:absolute;left:162.66px;top:407.85px" class="cls_008"><span class="cls_008">Implementation of K-means</span></div>
<div style="position:absolute;left:458.55px;top:407.85px" class="cls_008"><span class="cls_008">46</span></div>
<div style="position:absolute;left:162.66px;top:419.80px" class="cls_008"><span class="cls_008">5.2.1</span></div>
<div style="position:absolute;left:194.54px;top:419.80px" class="cls_008"><span class="cls_008">Elbow Method</span></div>
<div style="position:absolute;left:458.55px;top:419.80px" class="cls_008"><span class="cls_008">46</span></div>
<div style="position:absolute;left:162.66px;top:431.76px" class="cls_008"><span class="cls_008">5.2.2</span></div>
<div style="position:absolute;left:194.54px;top:431.76px" class="cls_008"><span class="cls_008">Running K-means</span></div>
<div style="position:absolute;left:458.55px;top:431.76px" class="cls_008"><span class="cls_008">49</span></div>
<div style="position:absolute;left:162.66px;top:443.71px" class="cls_008"><span class="cls_008">5.2.3</span></div>
<div style="position:absolute;left:194.54px;top:443.71px" class="cls_008"><span class="cls_008">Using K-means to detect outliers</span></div>
<div style="position:absolute;left:458.55px;top:443.71px" class="cls_008"><span class="cls_008">50</span></div>
<div style="position:absolute;left:139.75px;top:455.67px" class="cls_008"><span class="cls_008">5.3</span></div>
<div style="position:absolute;left:162.66px;top:455.67px" class="cls_008"><span class="cls_008">Implementation of DBSCAN</span></div>
<div style="position:absolute;left:458.55px;top:455.67px" class="cls_008"><span class="cls_008">52</span></div>
<div style="position:absolute;left:162.66px;top:467.62px" class="cls_008"><span class="cls_008">5.3.1</span></div>
<div style="position:absolute;left:194.54px;top:467.62px" class="cls_008"><span class="cls_008">Setting eps values</span></div>
<div style="position:absolute;left:458.56px;top:467.62px" class="cls_008"><span class="cls_008">53</span></div>
<div style="position:absolute;left:162.66px;top:479.58px" class="cls_008"><span class="cls_008">5.3.2</span></div>
<div style="position:absolute;left:194.54px;top:479.58px" class="cls_008"><span class="cls_008">Setting MinPts values</span></div>
<div style="position:absolute;left:458.55px;top:479.58px" class="cls_008"><span class="cls_008">54</span></div>
<div style="position:absolute;left:162.66px;top:491.53px" class="cls_008"><span class="cls_008">5.3.3</span></div>
<div style="position:absolute;left:194.54px;top:491.53px" class="cls_008"><span class="cls_008">Output</span></div>
<div style="position:absolute;left:458.55px;top:491.53px" class="cls_008"><span class="cls_008">55</span></div>
<div style="position:absolute;left:139.75px;top:503.49px" class="cls_008"><span class="cls_008">5.4</span></div>
<div style="position:absolute;left:162.66px;top:503.49px" class="cls_008"><span class="cls_008">Implementation of Local Outlier Factor</span></div>
<div style="position:absolute;left:458.55px;top:503.49px" class="cls_008"><span class="cls_008">55</span></div>
<div style="position:absolute;left:162.66px;top:515.44px" class="cls_008"><span class="cls_008">5.4.1</span></div>
<div style="position:absolute;left:194.54px;top:515.44px" class="cls_008"><span class="cls_008">Setting n-neighbors parameter  .</span></div>
<div style="position:absolute;left:458.55px;top:515.44px" class="cls_008"><span class="cls_008">55</span></div>
<div style="position:absolute;left:162.66px;top:527.40px" class="cls_008"><span class="cls_008">5.4.2</span></div>
<div style="position:absolute;left:194.54px;top:527.40px" class="cls_008"><span class="cls_008">Setting contamination parameter</span></div>
<div style="position:absolute;left:458.55px;top:527.40px" class="cls_008"><span class="cls_008">55</span></div>
<div style="position:absolute;left:162.66px;top:539.35px" class="cls_008"><span class="cls_008">5.4.3</span></div>
<div style="position:absolute;left:194.54px;top:539.35px" class="cls_008"><span class="cls_008">Output</span></div>
<div style="position:absolute;left:458.55px;top:539.35px" class="cls_008"><span class="cls_008">55</span></div>
<div style="position:absolute;left:139.75px;top:551.31px" class="cls_008"><span class="cls_008">5.5</span></div>
<div style="position:absolute;left:162.66px;top:551.31px" class="cls_008"><span class="cls_008">Implementation of AprioriRare</span></div>
<div style="position:absolute;left:458.55px;top:551.31px" class="cls_008"><span class="cls_008">57</span></div>
<div style="position:absolute;left:162.66px;top:563.27px" class="cls_008"><span class="cls_008">5.5.1</span></div>
<div style="position:absolute;left:194.54px;top:563.27px" class="cls_008"><span class="cls_008">Quantization</span></div>
<div style="position:absolute;left:458.55px;top:563.27px" class="cls_008"><span class="cls_008">57</span></div>
<div style="position:absolute;left:162.66px;top:575.22px" class="cls_008"><span class="cls_008">5.5.2</span></div>
<div style="position:absolute;left:194.54px;top:575.22px" class="cls_008"><span class="cls_008">Setting values</span></div>
<div style="position:absolute;left:458.55px;top:575.22px" class="cls_008"><span class="cls_008">59</span></div>
<div style="position:absolute;left:124.80px;top:597.14px" class="cls_007"><span class="cls_007">6</span></div>
<div style="position:absolute;left:139.75px;top:597.14px" class="cls_007"><span class="cls_007">Results and Experiments</span></div>
<div style="position:absolute;left:457.05px;top:597.14px" class="cls_007"><span class="cls_007">60</span></div>
<div style="position:absolute;left:139.75px;top:609.09px" class="cls_008"><span class="cls_008">6.1</span></div>
<div style="position:absolute;left:162.66px;top:609.09px" class="cls_008"><span class="cls_008">Results - K-means</span></div>
<div style="position:absolute;left:458.55px;top:609.09px" class="cls_008"><span class="cls_008">60</span></div>
<div style="position:absolute;left:162.66px;top:621.05px" class="cls_008"><span class="cls_008">6.1.1</span></div>
<div style="position:absolute;left:194.54px;top:621.05px" class="cls_008"><span class="cls_008">Three features</span></div>
<div style="position:absolute;left:458.56px;top:621.05px" class="cls_008"><span class="cls_008">60</span></div>
<div style="position:absolute;left:162.66px;top:633.00px" class="cls_008"><span class="cls_008">6.1.2</span></div>
<div style="position:absolute;left:194.54px;top:633.00px" class="cls_008"><span class="cls_008">Four features</span></div>
<div style="position:absolute;left:458.55px;top:633.00px" class="cls_008"><span class="cls_008">64</span></div>
<div style="position:absolute;left:162.66px;top:644.96px" class="cls_008"><span class="cls_008">6.1.3</span></div>
<div style="position:absolute;left:194.54px;top:644.96px" class="cls_008"><span class="cls_008">Five features</span></div>
<div style="position:absolute;left:458.56px;top:644.96px" class="cls_008"><span class="cls_008">68</span></div>
<div style="position:absolute;left:162.66px;top:656.91px" class="cls_008"><span class="cls_008">6.1.4</span></div>
<div style="position:absolute;left:194.54px;top:656.91px" class="cls_008"><span class="cls_008">Comparing K-means results</span></div>
<div style="position:absolute;left:458.55px;top:656.91px" class="cls_008"><span class="cls_008">72</span></div>
<div style="position:absolute;left:139.75px;top:668.87px" class="cls_008"><span class="cls_008">6.2</span></div>
<div style="position:absolute;left:162.66px;top:668.87px" class="cls_008"><span class="cls_008">Results - DBSCAN</span></div>
<div style="position:absolute;left:458.55px;top:668.87px" class="cls_008"><span class="cls_008">74</span></div>
<div style="position:absolute;left:162.66px;top:680.82px" class="cls_008"><span class="cls_008">6.2.1</span></div>
<div style="position:absolute;left:194.54px;top:680.82px" class="cls_008"><span class="cls_008">Three Features</span></div>
<div style="position:absolute;left:458.55px;top:680.82px" class="cls_008"><span class="cls_008">74</span></div>
<div style="position:absolute;left:162.66px;top:692.78px" class="cls_008"><span class="cls_008">6.2.2</span></div>
<div style="position:absolute;left:194.54px;top:692.78px" class="cls_008"><span class="cls_008">Four Features</span></div>
<div style="position:absolute;left:458.55px;top:692.78px" class="cls_008"><span class="cls_008">78</span></div>
<div style="position:absolute;left:162.66px;top:704.73px" class="cls_008"><span class="cls_008">6.2.3</span></div>
<div style="position:absolute;left:194.54px;top:704.73px" class="cls_008"><span class="cls_008">Five Features</span></div>
<div style="position:absolute;left:458.55px;top:704.73px" class="cls_008"><span class="cls_008">83</span></div>
<div style="position:absolute;left:294.17px;top:740.60px" class="cls_008"><span class="cls_008">3</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:5106px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background007.jpg" width=595 height=841></div>
<div style="position:absolute;left:162.66px;top:124.91px" class="cls_008"><span class="cls_008">6.2.4</span></div>
<div style="position:absolute;left:194.54px;top:124.91px" class="cls_008"><span class="cls_008">Comparing DBSCAN results</span></div>
<div style="position:absolute;left:458.55px;top:124.91px" class="cls_008"><span class="cls_008">86</span></div>
<div style="position:absolute;left:139.75px;top:136.86px" class="cls_008"><span class="cls_008">6.3</span></div>
<div style="position:absolute;left:162.66px;top:136.86px" class="cls_008"><span class="cls_008">Results - Local Outlier Factor</span></div>
<div style="position:absolute;left:458.55px;top:136.86px" class="cls_008"><span class="cls_008">88</span></div>
<div style="position:absolute;left:162.66px;top:148.82px" class="cls_008"><span class="cls_008">6.3.1</span></div>
<div style="position:absolute;left:194.54px;top:148.82px" class="cls_008"><span class="cls_008">Three Features</span></div>
<div style="position:absolute;left:458.55px;top:148.82px" class="cls_008"><span class="cls_008">88</span></div>
<div style="position:absolute;left:162.66px;top:160.77px" class="cls_008"><span class="cls_008">6.3.2</span></div>
<div style="position:absolute;left:194.54px;top:160.77px" class="cls_008"><span class="cls_008">Four Features</span></div>
<div style="position:absolute;left:458.55px;top:160.77px" class="cls_008"><span class="cls_008">93</span></div>
<div style="position:absolute;left:162.66px;top:172.73px" class="cls_008"><span class="cls_008">6.3.3</span></div>
<div style="position:absolute;left:194.54px;top:172.73px" class="cls_008"><span class="cls_008">Five Features</span></div>
<div style="position:absolute;left:458.55px;top:172.73px" class="cls_008"><span class="cls_008">97</span></div>
<div style="position:absolute;left:139.75px;top:184.68px" class="cls_008"><span class="cls_008">6.4</span></div>
<div style="position:absolute;left:162.66px;top:184.68px" class="cls_008"><span class="cls_008">Results - Rare Itemset Mining</span></div>
<div style="position:absolute;left:453.57px;top:184.68px" class="cls_008"><span class="cls_008">102</span></div>
<div style="position:absolute;left:162.66px;top:196.64px" class="cls_008"><span class="cls_008">6.4.1</span></div>
<div style="position:absolute;left:194.54px;top:196.64px" class="cls_008"><span class="cls_008">Three features</span></div>
<div style="position:absolute;left:453.57px;top:196.64px" class="cls_008"><span class="cls_008">102</span></div>
<div style="position:absolute;left:162.66px;top:208.59px" class="cls_008"><span class="cls_008">6.4.2</span></div>
<div style="position:absolute;left:194.54px;top:208.59px" class="cls_008"><span class="cls_008">Four and five features</span></div>
<div style="position:absolute;left:453.57px;top:208.59px" class="cls_008"><span class="cls_008">105</span></div>
<div style="position:absolute;left:162.66px;top:220.55px" class="cls_008"><span class="cls_008">6.4.3</span></div>
<div style="position:absolute;left:194.54px;top:220.55px" class="cls_008"><span class="cls_008">Comparing AprioriRare results</span></div>
<div style="position:absolute;left:453.57px;top:220.55px" class="cls_008"><span class="cls_008">107</span></div>
<div style="position:absolute;left:139.75px;top:232.51px" class="cls_008"><span class="cls_008">6.5</span></div>
<div style="position:absolute;left:162.66px;top:232.51px" class="cls_008"><span class="cls_008">Comparing the Results</span></div>
<div style="position:absolute;left:453.57px;top:232.51px" class="cls_008"><span class="cls_008">109</span></div>
<div style="position:absolute;left:139.75px;top:244.46px" class="cls_008"><span class="cls_008">6.6</span></div>
<div style="position:absolute;left:162.66px;top:244.46px" class="cls_008"><span class="cls_008">Discussion</span></div>
<div style="position:absolute;left:453.57px;top:244.46px" class="cls_008"><span class="cls_008">113</span></div>
<div style="position:absolute;left:124.80px;top:266.38px" class="cls_007"><span class="cls_007">7</span></div>
<div style="position:absolute;left:139.75px;top:266.38px" class="cls_007"><span class="cls_007">Conclusion</span></div>
<div style="position:absolute;left:451.33px;top:266.38px" class="cls_007"><span class="cls_007">116</span></div>
<div style="position:absolute;left:139.75px;top:278.33px" class="cls_008"><span class="cls_008">7.1</span></div>
<div style="position:absolute;left:162.66px;top:278.33px" class="cls_008"><span class="cls_008">Future Work</span></div>
<div style="position:absolute;left:453.57px;top:278.33px" class="cls_008"><span class="cls_008">117</span></div>
<div style="position:absolute;left:294.17px;top:740.60px" class="cls_008"><span class="cls_008">4</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:5957px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background008.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:189.78px" class="cls_009"><span class="cls_009">Glossary</span></div>
<div style="position:absolute;left:124.80px;top:255.70px" class="cls_010"><span class="cls_010">Abbreviations</span></div>
<div style="position:absolute;left:130.78px;top:280.41px" class="cls_008"><span class="cls_008">DBSCAN</span></div>
<div style="position:absolute;left:185.47px;top:280.41px" class="cls_008"><span class="cls_008">Density-based Spatial Clustering of Applications with Noise</span></div>
<div style="position:absolute;left:152.64px;top:292.36px" class="cls_008"><span class="cls_008">LOF</span></div>
<div style="position:absolute;left:185.47px;top:292.36px" class="cls_008"><span class="cls_008">Local outlier factor</span></div>
<div style="position:absolute;left:157.76px;top:304.32px" class="cls_008"><span class="cls_008">ML</span></div>
<div style="position:absolute;left:185.47px;top:304.32px" class="cls_008"><span class="cls_008">Machine Learning</span></div>
<div style="position:absolute;left:153.89px;top:316.27px" class="cls_008"><span class="cls_008">mRI</span></div>
<div style="position:absolute;left:185.47px;top:316.27px" class="cls_008"><span class="cls_008">Minimal Rare Itemset</span></div>
<div style="position:absolute;left:151.81px;top:328.23px" class="cls_008"><span class="cls_008">NTA</span></div>
<div style="position:absolute;left:185.47px;top:328.23px" class="cls_008"><span class="cls_008">The Norwegian Tax Administration</span></div>
<div style="position:absolute;left:151.67px;top:340.18px" class="cls_008"><span class="cls_008">PCA</span></div>
<div style="position:absolute;left:185.47px;top:340.18px" class="cls_008"><span class="cls_008">Principal Component Analysis</span></div>
<div style="position:absolute;left:153.06px;top:352.14px" class="cls_008"><span class="cls_008">RIM</span></div>
<div style="position:absolute;left:185.47px;top:352.14px" class="cls_008"><span class="cls_008">Rare Itemset Mining</span></div>
<div style="position:absolute;left:154.99px;top:364.09px" class="cls_008"><span class="cls_008">SSB</span></div>
<div style="position:absolute;left:185.47px;top:364.09px" class="cls_008"><span class="cls_008">Statistics Norway</span></div>
<div style="position:absolute;left:150.29px;top:376.05px" class="cls_008"><span class="cls_008">XML</span></div>
<div style="position:absolute;left:185.47px;top:376.05px" class="cls_008"><span class="cls_008">Extensible Markup Language</span></div>
<div style="position:absolute;left:125.35px;top:399.16px" class="cls_010"><span class="cls_010">Translations</span></div>
<div style="position:absolute;left:139.75px;top:427.46px" class="cls_008"><span class="cls_008">The data we received from the NTA was labeled in Norwegian, hence many</span></div>
<div style="position:absolute;left:124.80px;top:439.41px" class="cls_008"><span class="cls_008">screenshots taken directly from the data contains Norwegian. The table below</span></div>
<div style="position:absolute;left:124.80px;top:451.37px" class="cls_008"><span class="cls_008">contains the most important translations and their corresponding abbreviations.</span></div>
<div style="position:absolute;left:124.80px;top:463.32px" class="cls_008"><span class="cls_008">They will be used throughout this thesis.</span></div>
<div style="position:absolute;left:159.84px;top:485.58px" class="cls_008"><span class="cls_008">Antall Timer</span></div>
<div style="position:absolute;left:229.23px;top:485.58px" class="cls_008"><span class="cls_008">Hours worked</span></div>
<div style="position:absolute;left:133.68px;top:497.54px" class="cls_008"><span class="cls_008">Arbeidstidsordning</span></div>
<div style="position:absolute;left:229.23px;top:497.54px" class="cls_008"><span class="cls_008">Working time arrangement (WTA)</span></div>
<div style="position:absolute;left:130.78px;top:509.49px" class="cls_008"><span class="cls_008">Erstattermeldingsid</span></div>
<div style="position:absolute;left:229.23px;top:509.49px" class="cls_008"><span class="cls_008">Replacement-Id</span></div>
<div style="position:absolute;left:149.87px;top:521.45px" class="cls_008"><span class="cls_008">Forskuddstrekk</span></div>
<div style="position:absolute;left:229.23px;top:521.45px" class="cls_008"><span class="cls_008">Prepayment deductions (PPD)</span></div>
<div style="position:absolute;left:131.20px;top:533.40px" class="cls_008"><span class="cls_008">Korreksjonsmelding</span></div>
<div style="position:absolute;left:229.23px;top:533.40px" class="cls_008"><span class="cls_008">Correction-message</span></div>
<div style="position:absolute;left:168.66px;top:545.36px" class="cls_008"><span class="cls_008">MeldingsId</span></div>
<div style="position:absolute;left:229.23px;top:545.36px" class="cls_008"><span class="cls_008">Message-Id</span></div>
<div style="position:absolute;left:150.04px;top:557.31px" class="cls_008"><span class="cls_008">Stillingsprosent</span></div>
<div style="position:absolute;left:229.23px;top:557.31px" class="cls_008"><span class="cls_008">Full-time equivalent (FTE)</span></div>
<div style="position:absolute;left:162.91px;top:569.27px" class="cls_008"><span class="cls_008">Totalinntekt</span></div>
<div style="position:absolute;left:229.23px;top:569.27px" class="cls_008"><span class="cls_008">Total income</span></div>
<div style="position:absolute;left:294.17px;top:740.60px" class="cls_008"><span class="cls_008">5</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:6808px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background009.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:188.93px" class="cls_011"><span class="cls_011">Chapter 1</span></div>
<div style="position:absolute;left:124.80px;top:234.62px" class="cls_009"><span class="cls_009">Introduction</span></div>
<div style="position:absolute;left:124.80px;top:302.84px" class="cls_010"><span class="cls_010">1.1</span></div>
<div style="position:absolute;left:161.56px;top:302.84px" class="cls_010"><span class="cls_010">The Norwegian Tax Administration</span></div>
<div style="position:absolute;left:124.80px;top:329.05px" class="cls_008"><span class="cls_008">The Norwegian Tax Administration (NTA) is the government agency responsible</span></div>
<div style="position:absolute;left:124.80px;top:341.00px" class="cls_008"><span class="cls_008">for resident registration and tax collection in Norway. The agency is subordinate</span></div>
<div style="position:absolute;left:124.80px;top:352.96px" class="cls_008"><span class="cls_008">to the Ministry of Finance and employs around 6000 people. The NTA is one of</span></div>
<div style="position:absolute;left:124.80px;top:364.91px" class="cls_008"><span class="cls_008">the largest IT-environments in Norway and they process huge amounts of data</span></div>
<div style="position:absolute;left:124.80px;top:376.87px" class="cls_008"><span class="cls_008">related to the income of Norwegian taxpayers.</span></div>
<div style="position:absolute;left:139.75px;top:388.82px" class="cls_008"><span class="cls_008">The Norwegian Tax Administration’s platform for A-ordningen (see 1.2)</span></div>
<div style="position:absolute;left:124.80px;top:400.78px" class="cls_008"><span class="cls_008">benefits from an Event Driven Architecture.  Phenomena occurring inside or</span></div>
<div style="position:absolute;left:124.80px;top:412.73px" class="cls_008"><span class="cls_008">outside of the NTA are modeled as "events".  Events are then queued as data</span></div>
<div style="position:absolute;left:124.80px;top:424.69px" class="cls_008"><span class="cls_008">streams.  Having processed an event, the system outputs a new event which</span></div>
<div style="position:absolute;left:124.80px;top:436.64px" class="cls_008"><span class="cls_008">is written to another data stream.  Data streams are often chained like Unix</span></div>
<div style="position:absolute;left:124.80px;top:448.60px" class="cls_008"><span class="cls_008">pipe commands.  If there is some form of error in the data, the error rapidly</span></div>
<div style="position:absolute;left:124.80px;top:460.55px" class="cls_008"><span class="cls_008">propagates to the next parts of the chain. In worst case scenarios, errors may</span></div>
<div style="position:absolute;left:124.80px;top:472.51px" class="cls_008"><span class="cls_008">propagate to external parts like NAV or SSB. External parts are dependent</span></div>
<div style="position:absolute;left:124.80px;top:484.46px" class="cls_008"><span class="cls_008">upon the validity of the data they receive and process. The impact from getting</span></div>
<div style="position:absolute;left:124.80px;top:496.42px" class="cls_008"><span class="cls_008">polluted data can damage the credibility of the NTA, as well as all the external</span></div>
<div style="position:absolute;left:124.80px;top:508.37px" class="cls_008"><span class="cls_008">parts that are using the data.  In accordance with the Statistics act of 1989,</span></div>
<div style="position:absolute;left:124.80px;top:520.33px" class="cls_008"><span class="cls_008">Statistics Norway (SSB) is the central body for preparation and dissemination of</span></div>
<div style="position:absolute;left:124.80px;top:532.28px" class="cls_008"><span class="cls_008">official statistics [14]. Therefore the quality of the data they use is of paramount</span></div>
<div style="position:absolute;left:124.80px;top:544.24px" class="cls_008"><span class="cls_008">importance.</span></div>
<div style="position:absolute;left:124.80px;top:572.80px" class="cls_010"><span class="cls_010">1.2</span></div>
<div style="position:absolute;left:161.56px;top:572.80px" class="cls_010"><span class="cls_010">A-ordningen</span></div>
<div style="position:absolute;left:124.80px;top:599.01px" class="cls_008"><span class="cls_008">A-ordningen is an efficient reporting service used by Norwegian employers to</span></div>
<div style="position:absolute;left:124.80px;top:610.96px" class="cls_008"><span class="cls_008">report information about their employees. The information is passed to NAV,</span></div>
<div style="position:absolute;left:124.80px;top:622.92px" class="cls_008"><span class="cls_008">SSB and the NTA. It is a digital service, submitted electronically through either</span></div>
<div style="position:absolute;left:124.80px;top:634.87px" class="cls_008"><span class="cls_008">Altinns system or through the employers own payroll system.  The NTA is</span></div>
<div style="position:absolute;left:124.80px;top:646.83px" class="cls_008"><span class="cls_008">responsible for administrating the service on behalf of the other public agencies.</span></div>
<div style="position:absolute;left:294.17px;top:740.60px" class="cls_008"><span class="cls_008">6</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:7659px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background010.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:120.52px" class="cls_010"><span class="cls_010">1.3</span></div>
<div style="position:absolute;left:161.56px;top:120.52px" class="cls_010"><span class="cls_010">A-meldingen</span></div>
<div style="position:absolute;left:124.80px;top:146.73px" class="cls_008"><span class="cls_008">A-meldingen is a monthly report that every employer in Norway is required to</span></div>
<div style="position:absolute;left:124.80px;top:158.68px" class="cls_008"><span class="cls_008">submit to the NTA. The report consists of information about income, working</span></div>
<div style="position:absolute;left:124.80px;top:170.64px" class="cls_008"><span class="cls_008">conditions, and preliminary tax for the employees, among other things.  A-</span></div>
<div style="position:absolute;left:124.80px;top:182.59px" class="cls_008"><span class="cls_008">meldingen should be reported at a minimum of once per month. A-meldingen</span></div>
<div style="position:absolute;left:124.80px;top:194.55px" class="cls_008"><span class="cls_008">started to take effect from the 1st of January, 2015.  The system it replaced</span></div>
<div style="position:absolute;left:124.80px;top:206.51px" class="cls_008"><span class="cls_008">consisted of five different forms with different deadlines and recipients, which</span></div>
<div style="position:absolute;left:124.80px;top:218.46px" class="cls_008"><span class="cls_008">made the reporting process tedious.  A-meldingen was a long sought after im-</span></div>
<div style="position:absolute;left:124.80px;top:230.42px" class="cls_008"><span class="cls_008">provement.</span></div>
<div style="position:absolute;left:124.80px;top:258.98px" class="cls_010"><span class="cls_010">1.4</span></div>
<div style="position:absolute;left:161.56px;top:258.98px" class="cls_010"><span class="cls_010">Motivation</span></div>
<div style="position:absolute;left:124.80px;top:285.18px" class="cls_008"><span class="cls_008">Currently, the NTA has a set of pre-programmed validation rules for discov-</span></div>
<div style="position:absolute;left:124.80px;top:297.14px" class="cls_008"><span class="cls_008">ering anomalies.  Using Machine Learning (ML), the NTA aims to potentially</span></div>
<div style="position:absolute;left:124.80px;top:309.09px" class="cls_008"><span class="cls_008">to discover new types of anomalies.  Since the NTA is planning to give other</span></div>
<div style="position:absolute;left:124.80px;top:321.05px" class="cls_008"><span class="cls_008">organizations access to A-ordningen, it is crucial to prevent anomalies.  This</span></div>
<div style="position:absolute;left:124.80px;top:333.00px" class="cls_008"><span class="cls_008">thesis aims to analyze the data in A-meldingen to detect potential anomalies.</span></div>
<div style="position:absolute;left:124.80px;top:361.56px" class="cls_010"><span class="cls_010">1.5</span></div>
<div style="position:absolute;left:161.56px;top:361.56px" class="cls_010"><span class="cls_010">Goal</span></div>
<div style="position:absolute;left:124.80px;top:387.77px" class="cls_008"><span class="cls_008">Our goal is to utilize ML algorithms to detect anomalies in A-meldings that the</span></div>
<div style="position:absolute;left:124.80px;top:399.72px" class="cls_008"><span class="cls_008">NTA receives from employers all around Norway. The data we received from the</span></div>
<div style="position:absolute;left:124.80px;top:411.68px" class="cls_008"><span class="cls_008">NTA is unlabeled, meaning that there is no blueprint as to whether a specific</span></div>
<div style="position:absolute;left:124.80px;top:423.63px" class="cls_008"><span class="cls_008">event is of normal or anomalous behaviour.  There is definitely a need for a</span></div>
<div style="position:absolute;left:124.80px;top:435.59px" class="cls_008"><span class="cls_008">system to detect and stop the anomalous data from propagating further down</span></div>
<div style="position:absolute;left:124.80px;top:447.55px" class="cls_008"><span class="cls_008">the chain and into other systems that the NTA collaborate with.  We aim to</span></div>
<div style="position:absolute;left:124.80px;top:459.50px" class="cls_008"><span class="cls_008">detect anomalies based solely on the natural features of the provided data. We</span></div>
<div style="position:absolute;left:124.80px;top:471.46px" class="cls_008"><span class="cls_008">will conduct three different experiments using four different anomaly detection</span></div>
<div style="position:absolute;left:124.80px;top:483.41px" class="cls_008"><span class="cls_008">algorithms.  The deployed algorithms will hopefully discover outliers currently</span></div>
<div style="position:absolute;left:124.80px;top:495.37px" class="cls_008"><span class="cls_008">unknown to the NTA that might be anomalies. We will bring the results to the</span></div>
<div style="position:absolute;left:124.80px;top:507.32px" class="cls_008"><span class="cls_008">NTA and have their domain experts evaluate them.</span></div>
<div style="position:absolute;left:294.17px;top:740.60px" class="cls_008"><span class="cls_008">7</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:8510px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background011.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:120.52px" class="cls_010"><span class="cls_010">1.6</span></div>
<div style="position:absolute;left:161.56px;top:120.52px" class="cls_010"><span class="cls_010">Contract</span></div>
<div style="position:absolute;left:116.16px;top:148.95px" class="cls_012"><span class="cls_012">Anomaly detection of production data</span></div>
<div style="position:absolute;left:116.16px;top:176.70px" class="cls_014"><span class="cls_014">Norwegian Tax Administration (Skatteetaten) is one of the largest IT-environments of</span></div>
<div style="position:absolute;left:116.16px;top:187.45px" class="cls_014"><span class="cls_014">Norway.  Skatteetaten processes daily huge amount of data.  Our modernized platform has adopted</span></div>
<div style="position:absolute;left:116.16px;top:198.20px" class="cls_014"><span class="cls_014">Event Driven Architecture.  Phenomena which have occurred inside or outside of Skatteetaten are</span></div>
<div style="position:absolute;left:116.16px;top:208.96px" class="cls_014"><span class="cls_014">modeled as "events".  Events are then queued as data streams. Each process reads and processes</span></div>
<div style="position:absolute;left:116.16px;top:219.61px" class="cls_014"><span class="cls_014">events from data (event) streams.  Having processes an event, the output is a new event which is</span></div>
<div style="position:absolute;left:116.16px;top:229.60px" class="cls_014"><span class="cls_014">written to another data (event) stream.</span></div>
<div style="position:absolute;left:116.16px;top:251.10px" class="cls_014"><span class="cls_014">Data streams are often chained like Unix pipe command.</span></div>
<div style="position:absolute;left:116.16px;top:273.37px" class="cls_014"><span class="cls_014">Using the above, Skatteetaten is able to quickly process huge data.  The processing time could be</span></div>
<div style="position:absolute;left:116.16px;top:283.36px" class="cls_014"><span class="cls_014">down to few seconds.</span></div>
<div style="position:absolute;left:116.16px;top:305.66px" class="cls_014"><span class="cls_014">If there is some error in the data in one part of the "chain", the error rapidly propagates to the next</span></div>
<div style="position:absolute;left:116.16px;top:316.41px" class="cls_014"><span class="cls_014">parts of the chain.  In worst case scenario, an error may negatively affect many other systems in few</span></div>
<div style="position:absolute;left:116.16px;top:327.07px" class="cls_014"><span class="cls_014">seconds.  To counteract such error propagation, we would like to be assisted by computers to</span></div>
<div style="position:absolute;left:116.16px;top:337.05px" class="cls_014"><span class="cls_014">analyze "data" for potential errors.</span></div>
<div style="position:absolute;left:116.16px;top:359.32px" class="cls_014"><span class="cls_014">We would like to use Machine Learning to analyze structured data (e.g. XML or JSON) to detect</span></div>
<div style="position:absolute;left:116.16px;top:369.31px" class="cls_014"><span class="cls_014">potential anomalies.</span></div>
<div style="position:absolute;left:116.16px;top:415.20px" class="cls_014"><span class="cls_014">Contact persons:</span></div>
<div style="position:absolute;left:116.16px;top:425.95px" class="cls_014"><span class="cls_014">Aeinehchi, Nader, </span><span class="cls_027">Nader.Aeinehchi@skatteetaten.no</span></div>
<div style="position:absolute;left:116.16px;top:448.42px" class="cls_014"><span class="cls_014">Stefano Nichelle, </span><span class="cls_027">stenic@oslomet.no</span></div>
<div style="position:absolute;left:116.16px;top:470.90px" class="cls_014"><span class="cls_014">Anis Yazidi, </span><span class="cls_027">anisy@oslomet.no</span></div>
<div style="position:absolute;left:294.17px;top:740.60px" class="cls_008"><span class="cls_008">8</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:9361px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background012.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:188.93px" class="cls_011"><span class="cls_011">Chapter 2</span></div>
<div style="position:absolute;left:124.80px;top:234.62px" class="cls_009"><span class="cls_009">Work Process and</span></div>
<div style="position:absolute;left:124.80px;top:264.50px" class="cls_009"><span class="cls_009">Methodology</span></div>
<div style="position:absolute;left:124.80px;top:331.14px" class="cls_008"><span class="cls_008">In this chapter we will talk about how we planned and carried out the project.</span></div>
<div style="position:absolute;left:124.80px;top:343.09px" class="cls_008"><span class="cls_008">We will also detail some of the methods and tools we used.</span></div>
<div style="position:absolute;left:124.80px;top:371.65px" class="cls_010"><span class="cls_010">2.1</span></div>
<div style="position:absolute;left:161.56px;top:371.65px" class="cls_010"><span class="cls_010">Initial project planning</span></div>
<div style="position:absolute;left:124.80px;top:397.86px" class="cls_008"><span class="cls_008">Our plan was to apply various ML algorithms for detecting anomalies in the</span></div>
<div style="position:absolute;left:124.80px;top:409.81px" class="cls_008"><span class="cls_008">data we received from the NTA. The A-melding data is confidential and the</span></div>
<div style="position:absolute;left:124.80px;top:421.77px" class="cls_008"><span class="cls_008">NTA has provided us an anonymous dataset.  Figure 2.1 illustrates how we</span></div>
<div style="position:absolute;left:124.80px;top:433.72px" class="cls_008"><span class="cls_008">planned to distribute the phases over the course of the semester.  There were</span></div>
<div style="position:absolute;left:124.80px;top:445.68px" class="cls_008"><span class="cls_008">some deviations from this plan.</span></div>
<div style="position:absolute;left:203.53px;top:595.72px" class="cls_008"><span class="cls_008">Figure 2.1: Gantt chart of project timeline</span></div>
<div style="position:absolute;left:139.75px;top:633.18px" class="cls_008"><span class="cls_008">The data we received consisted of approximately 240 GB of XML files. These</span></div>
<div style="position:absolute;left:124.80px;top:645.14px" class="cls_008"><span class="cls_008">files are encoded with base64 in order to ensure that the data remains unmodified</span></div>
<div style="position:absolute;left:124.80px;top:657.09px" class="cls_008"><span class="cls_008">during transportation to the server. The specifications of server we used will be</span></div>
<div style="position:absolute;left:124.80px;top:669.05px" class="cls_008"><span class="cls_008">discussed briefly in 3.8.6.</span></div>
<div style="position:absolute;left:139.75px;top:692.96px" class="cls_008"><span class="cls_008">At this point we did not know anything about the data, except that it was</span></div>
<div style="position:absolute;left:124.80px;top:704.91px" class="cls_008"><span class="cls_008">highly confidential and it had been anonymized once for internal use and then</span></div>
<div style="position:absolute;left:294.17px;top:740.60px" class="cls_008"><span class="cls_008">9</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:10212px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background013.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">again for external use. In order to create suitable solutions for this project, we</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">split the project into several phases.  These phases included, as shown in the</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">Gantt diagram (figure 2.1): Startup, Data Analysis, Development, Analysis and</span></div>
<div style="position:absolute;left:124.80px;top:160.77px" class="cls_008"><span class="cls_008">evaluation, and Project Completion. In the next few sections these phases will</span></div>
<div style="position:absolute;left:124.80px;top:172.73px" class="cls_008"><span class="cls_008">be discussed in more detail.</span></div>
<div style="position:absolute;left:124.80px;top:198.62px" class="cls_017"><span class="cls_017">2.1.1</span></div>
<div style="position:absolute;left:165.90px;top:198.62px" class="cls_017"><span class="cls_017">Startup phase</span></div>
<div style="position:absolute;left:124.80px;top:219.01px" class="cls_008"><span class="cls_008">During this phase we wrote all the required preliminary reports; the status</span></div>
<div style="position:absolute;left:124.80px;top:230.96px" class="cls_008"><span class="cls_008">report, a project outline and the pre-project. These documents can be found on</span></div>
<div style="position:absolute;left:124.80px;top:242.92px" class="cls_008"><span class="cls_008">our home area:</span></div>
<div style="position:absolute;left:181.59px;top:266.44px" class="cls_008"><span class="cls_008"> </span><A HREF="http://student.cs.hioa.no/~s315278/bachelor/">http://student.cs.hioa.no/~s315278/bachelor/</A> </div>
<div style="position:absolute;left:139.75px;top:289.97px" class="cls_008"><span class="cls_008">We were presented with a virtual machine set up in cooperation with the</span></div>
<div style="position:absolute;left:124.80px;top:301.92px" class="cls_008"><span class="cls_008">NTA, containing all the encoded XML files.  We spent some time getting to</span></div>
<div style="position:absolute;left:124.80px;top:313.88px" class="cls_008"><span class="cls_008">know the data in order to establish a more concrete approach to the problem at</span></div>
<div style="position:absolute;left:124.80px;top:325.83px" class="cls_008"><span class="cls_008">hand. We soon discovered that the data demanded an unsupervised (see section</span></div>
<div style="position:absolute;left:124.80px;top:337.79px" class="cls_008"><span class="cls_008">3.1.3) approach. In this phase we also decided to do our code work in Jupyter</span></div>
<div style="position:absolute;left:124.80px;top:349.74px" class="cls_008"><span class="cls_008">Notebook (see 3.8.8), and write our thesis in Overleaf which is an online L</span><span class="cls_018">A</span><span class="cls_008">TEX</span></div>
<div style="position:absolute;left:124.80px;top:361.70px" class="cls_008"><span class="cls_008">editor.</span></div>
<div style="position:absolute;left:124.80px;top:387.59px" class="cls_017"><span class="cls_017">2.1.2</span></div>
<div style="position:absolute;left:165.90px;top:387.59px" class="cls_017"><span class="cls_017">Data Analysis phase</span></div>
<div style="position:absolute;left:124.80px;top:407.98px" class="cls_008"><span class="cls_008">The goal of this phase was to establish an understanding of the data and it’s</span></div>
<div style="position:absolute;left:124.80px;top:419.93px" class="cls_008"><span class="cls_008">structure.  The A-melding data we were given was stored as structured XML</span></div>
<div style="position:absolute;left:124.80px;top:431.89px" class="cls_008"><span class="cls_008">files. This phase includes working "hands-on" with the data, getting an overview</span></div>
<div style="position:absolute;left:124.80px;top:443.84px" class="cls_008"><span class="cls_008">of the distribution and of the features in the data. We transformed the data from</span></div>
<div style="position:absolute;left:124.80px;top:455.80px" class="cls_008"><span class="cls_008">XML to the significantly smaller file type CSV, without changing the integrity</span></div>
<div style="position:absolute;left:124.80px;top:467.75px" class="cls_008"><span class="cls_008">of the data.  Furthermore, unnecessary data was filtered out based on input</span></div>
<div style="position:absolute;left:124.80px;top:479.71px" class="cls_008"><span class="cls_008">from the domain experts at the NTA. This is further discussed in chapter 4.</span></div>
<div style="position:absolute;left:124.80px;top:505.60px" class="cls_017"><span class="cls_017">2.1.3</span></div>
<div style="position:absolute;left:165.90px;top:505.60px" class="cls_017"><span class="cls_017">Development phase</span></div>
<div style="position:absolute;left:124.80px;top:525.99px" class="cls_008"><span class="cls_008">During the development phase we researched what algorithms that are currently</span></div>
<div style="position:absolute;left:124.80px;top:537.94px" class="cls_008"><span class="cls_008">being used in these types of problems. As part of our contract (see section 1.5),</span></div>
<div style="position:absolute;left:124.80px;top:549.90px" class="cls_008"><span class="cls_008">the NTA wants to use ML to analyze structured data to find potential errors.</span></div>
<div style="position:absolute;left:124.80px;top:561.85px" class="cls_008"><span class="cls_008">In order to achieve this we decided upon using four well-renowned algorithms,</span></div>
<div style="position:absolute;left:124.80px;top:573.81px" class="cls_008"><span class="cls_008">namely K-means clustering, density-based spatial clustering of applications with</span></div>
<div style="position:absolute;left:124.80px;top:585.76px" class="cls_008"><span class="cls_008">noise (DBSCAN), Local Outlier Factor (LOF) and AprioriRare.  These algo-</span></div>
<div style="position:absolute;left:124.80px;top:597.72px" class="cls_008"><span class="cls_008">rithms all have different strengths and weaknesses in regards to finding outliers.</span></div>
<div style="position:absolute;left:124.80px;top:609.67px" class="cls_008"><span class="cls_008">These algorithms will be discussed later in chapter 6.  A reprocessing of data</span></div>
<div style="position:absolute;left:124.80px;top:621.63px" class="cls_008"><span class="cls_008">and extraction of additional features will also be included in this phase.</span></div>
<div style="position:absolute;left:124.80px;top:647.52px" class="cls_017"><span class="cls_017">2.1.4</span></div>
<div style="position:absolute;left:165.90px;top:647.52px" class="cls_017"><span class="cls_017">Analysis and Evaluation phase</span></div>
<div style="position:absolute;left:124.80px;top:667.90px" class="cls_008"><span class="cls_008">This phase contains a discussion about the results of each algorithm.  These</span></div>
<div style="position:absolute;left:124.80px;top:679.86px" class="cls_008"><span class="cls_008">results is then compared to the other algorithms. Hopefully, the algorithms will</span></div>
<div style="position:absolute;left:124.80px;top:691.81px" class="cls_008"><span class="cls_008">discover similar outliers as this will improve the confidence as to whether an</span></div>
<div style="position:absolute;left:124.80px;top:703.77px" class="cls_008"><span class="cls_008">outlier is an anomaly or not. See discussion in chapter 6.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">10</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:11063px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background014.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:122.92px" class="cls_017"><span class="cls_017">2.1.5</span></div>
<div style="position:absolute;left:165.90px;top:122.92px" class="cls_017"><span class="cls_017">Project Completion phase</span></div>
<div style="position:absolute;left:124.80px;top:143.30px" class="cls_008"><span class="cls_008">In the last phase the focus mainly consisted of finalizing all the chapters and</span></div>
<div style="position:absolute;left:124.80px;top:155.25px" class="cls_008"><span class="cls_008">individual sections, and doing some minor adjustments to the structure of the</span></div>
<div style="position:absolute;left:124.80px;top:167.21px" class="cls_008"><span class="cls_008">report. Then we had some proof-readings before a final grammatical refresh.</span></div>
<div style="position:absolute;left:124.80px;top:195.77px" class="cls_010"><span class="cls_010">2.2</span></div>
<div style="position:absolute;left:161.56px;top:195.77px" class="cls_010"><span class="cls_010">Project Management</span></div>
<div style="position:absolute;left:124.80px;top:221.97px" class="cls_017"><span class="cls_017">2.2.1</span></div>
<div style="position:absolute;left:165.90px;top:221.97px" class="cls_017"><span class="cls_017">Meetings with the NTA</span></div>
<div style="position:absolute;left:124.80px;top:242.36px" class="cls_008"><span class="cls_008">During our first meeting with the NTA we agreed upon the way the NTA would</span></div>
<div style="position:absolute;left:124.80px;top:254.31px" class="cls_008"><span class="cls_008">be involved and how they could support us. The NTA has A-melding experts</span></div>
<div style="position:absolute;left:124.80px;top:266.27px" class="cls_008"><span class="cls_008">that would help us a lot when reviewing the results. We also agreed upon having</span></div>
<div style="position:absolute;left:124.80px;top:278.22px" class="cls_008"><span class="cls_008">one physical meeting every week at the NTA. The goal for these meetings was</span></div>
<div style="position:absolute;left:124.80px;top:290.18px" class="cls_008"><span class="cls_008">to give the NTA an update on how we were progressing with the project and to</span></div>
<div style="position:absolute;left:124.80px;top:302.13px" class="cls_008"><span class="cls_008">bring them the output from our algorithms for them to inspect. The meetings</span></div>
<div style="position:absolute;left:124.80px;top:314.09px" class="cls_008"><span class="cls_008">lasted one hour and was very valuable for us during the first few months of the</span></div>
<div style="position:absolute;left:124.80px;top:326.04px" class="cls_008"><span class="cls_008">semester.  As the deadline for the thesis approached the meetings were ended</span></div>
<div style="position:absolute;left:124.80px;top:338.00px" class="cls_008"><span class="cls_008">and communication with the domain experts proceeded through e-mail.  We</span></div>
<div style="position:absolute;left:124.80px;top:349.95px" class="cls_008"><span class="cls_008">also decided upon two Skype meetings every week, Mondays and Thursdays at</span></div>
<div style="position:absolute;left:124.80px;top:361.91px" class="cls_008"><span class="cls_008">8:30.</span></div>
<div style="position:absolute;left:124.80px;top:387.80px" class="cls_017"><span class="cls_017">2.2.2</span></div>
<div style="position:absolute;left:165.90px;top:387.80px" class="cls_017"><span class="cls_017">Meetings with supervisors</span></div>
<div style="position:absolute;left:124.80px;top:408.19px" class="cls_008"><span class="cls_008">In addition to the meetings with the NTA, we also had weekly meetings with</span></div>
<div style="position:absolute;left:124.80px;top:420.14px" class="cls_008"><span class="cls_008">our supervisors, where we discussed more practical issues regarding our work.</span></div>
<div style="position:absolute;left:124.80px;top:432.10px" class="cls_008"><span class="cls_008">The group met consistently three times a week to work on the thesis. We used a</span></div>
<div style="position:absolute;left:124.80px;top:444.05px" class="cls_008"><span class="cls_008">meeting room at the AI lab at Pilestredet 52 as our main work space. We wrote</span></div>
<div style="position:absolute;left:124.80px;top:456.01px" class="cls_008"><span class="cls_008">meeting minutes from our meetings with supervisors in order to keep track of</span></div>
<div style="position:absolute;left:124.80px;top:467.96px" class="cls_008"><span class="cls_008">progress and to have an overview of the action points and plans for upcoming</span></div>
<div style="position:absolute;left:124.80px;top:479.92px" class="cls_008"><span class="cls_008">week.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">11</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:11914px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background015.jpg" width=595 height=841></div>
<div style="position:absolute;left:162.63px;top:685.52px" class="cls_008"><span class="cls_008">Figure 2.2: Example from one of the earlier meeting minutes.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">12</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:12765px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background016.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:122.92px" class="cls_017"><span class="cls_017">2.2.3</span></div>
<div style="position:absolute;left:165.90px;top:122.92px" class="cls_017"><span class="cls_017">Dividing Tasks</span></div>
<div style="position:absolute;left:124.80px;top:143.30px" class="cls_008"><span class="cls_008">Trello is a web-based visual application for organizing work.  We chose Trello</span></div>
<div style="position:absolute;left:124.80px;top:155.25px" class="cls_008"><span class="cls_008">simply because it is free and easy to use. It contains all the necessary functions</span></div>
<div style="position:absolute;left:124.80px;top:167.21px" class="cls_008"><span class="cls_008">to divide the tasks.  We worked in one-week sprints where we by the end of</span></div>
<div style="position:absolute;left:124.80px;top:179.16px" class="cls_008"><span class="cls_008">each week created a new set of tasks to add to the backlog. This ensured that</span></div>
<div style="position:absolute;left:124.80px;top:191.12px" class="cls_008"><span class="cls_008">we always had tasks to work on.  We did not follow any specific development</span></div>
<div style="position:absolute;left:124.80px;top:203.07px" class="cls_008"><span class="cls_008">methodologies, but we had the most similarities to the agile framework Scrum.</span></div>
<div style="position:absolute;left:124.80px;top:215.03px" class="cls_008"><span class="cls_008">We held standup meetings with the NTA twice a week, and we worked in one</span></div>
<div style="position:absolute;left:124.80px;top:226.98px" class="cls_008"><span class="cls_008">week long sprints where we completed the backlog before creating new tasks.</span></div>
<div style="position:absolute;left:190.46px;top:534.63px" class="cls_008"><span class="cls_008">Figure 2.3: Screenshot of the ’Backlog’ in Trello.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">13</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:13616px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background017.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:188.93px" class="cls_011"><span class="cls_011">Chapter 3</span></div>
<div style="position:absolute;left:124.80px;top:234.62px" class="cls_009"><span class="cls_009">Theory</span></div>
<div style="position:absolute;left:124.80px;top:301.25px" class="cls_008"><span class="cls_008">This chapter contains the theory of the different algorithms we applied to the</span></div>
<div style="position:absolute;left:124.80px;top:313.20px" class="cls_008"><span class="cls_008">data. Other relevant sub-fields of machine learning that are mentioned in this</span></div>
<div style="position:absolute;left:124.80px;top:325.16px" class="cls_008"><span class="cls_008">thesis are also presented in short.</span></div>
<div style="position:absolute;left:124.80px;top:353.72px" class="cls_010"><span class="cls_010">3.1</span></div>
<div style="position:absolute;left:161.56px;top:353.72px" class="cls_010"><span class="cls_010">Machine Learning</span></div>
<div style="position:absolute;left:124.80px;top:379.92px" class="cls_008"><span class="cls_008">Machine Learning (ML) aims to create systems that can learn a generalized</span></div>
<div style="position:absolute;left:124.80px;top:391.88px" class="cls_008"><span class="cls_008">solution to a problem without being explicitly programmed to do so.  It uses</span></div>
<div style="position:absolute;left:124.80px;top:403.83px" class="cls_008"><span class="cls_008">statistics and mathematics to look for patterns in the data.  Then it adjusts</span></div>
<div style="position:absolute;left:124.80px;top:415.79px" class="cls_008"><span class="cls_008">its parameters according to the patterns it deems useful. There are three main</span></div>
<div style="position:absolute;left:124.80px;top:427.74px" class="cls_008"><span class="cls_008">paradigms of machine learning, namely supervised, unsupervised and Reinforce-</span></div>
<div style="position:absolute;left:124.80px;top:439.70px" class="cls_008"><span class="cls_008">ment Learning. The different sub fields all depend upon the data you have.</span></div>
<div style="position:absolute;left:124.80px;top:465.60px" class="cls_017"><span class="cls_017">3.1.1</span></div>
<div style="position:absolute;left:165.90px;top:465.60px" class="cls_017"><span class="cls_017">Features</span></div>
<div style="position:absolute;left:124.80px;top:485.98px" class="cls_008"><span class="cls_008">In ML a feature can be described as an individual characteristic of a phenomenon</span></div>
<div style="position:absolute;left:124.80px;top:497.93px" class="cls_008"><span class="cls_008">being observed[3]. They are represented as a column of data given as the input</span></div>
<div style="position:absolute;left:124.80px;top:509.89px" class="cls_008"><span class="cls_008">to an algorithm or model.  During this thesis they are referred to as either</span></div>
<div style="position:absolute;left:124.80px;top:521.84px" class="cls_008"><span class="cls_008">features or dimensions.</span></div>
<div style="position:absolute;left:152.96px;top:681.23px" class="cls_008"><span class="cls_008">Figure 3.1: Feature engineering in the machine learning workflow.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">14</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:14467px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background018.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:122.92px" class="cls_017"><span class="cls_017">3.1.2</span></div>
<div style="position:absolute;left:165.90px;top:122.92px" class="cls_017"><span class="cls_017">Supervised Learning</span></div>
<div style="position:absolute;left:124.80px;top:143.30px" class="cls_008"><span class="cls_008">In supervised learning, the output for a given input value is predicted based on</span></div>
<div style="position:absolute;left:124.80px;top:155.25px" class="cls_008"><span class="cls_008">the training data.  The training data is data with ‘ground truth’ labels, that</span></div>
<div style="position:absolute;left:124.80px;top:167.21px" class="cls_008"><span class="cls_008">help tweak the parameters of the model until the desired output is achieved.</span></div>
<div style="position:absolute;left:124.80px;top:179.16px" class="cls_008"><span class="cls_008">Supervised techniques helps the model to correct its output and predict what</span></div>
<div style="position:absolute;left:124.80px;top:191.12px" class="cls_008"><span class="cls_008">comes next based on its training data. This can in some ways be seen as a form</span></div>
<div style="position:absolute;left:124.80px;top:203.07px" class="cls_008"><span class="cls_008">of qualified guesswork, as the algorithm tries to group the input into a category</span></div>
<div style="position:absolute;left:124.80px;top:215.03px" class="cls_008"><span class="cls_008">it knows already, and not as a measure of ’intelligence’ per se.</span></div>
<div style="position:absolute;left:124.80px;top:240.92px" class="cls_017"><span class="cls_017">3.1.3</span></div>
<div style="position:absolute;left:165.90px;top:240.92px" class="cls_017"><span class="cls_017">Unsupervised Learning</span></div>
<div style="position:absolute;left:124.80px;top:261.31px" class="cls_008"><span class="cls_008">Data mining is a sub-field of ML and it revolves around exploring the data</span></div>
<div style="position:absolute;left:124.80px;top:273.26px" class="cls_008"><span class="cls_008">through unsupervised algorithms. Unsupervised techniques takes unlabeled in-</span></div>
<div style="position:absolute;left:124.80px;top:285.22px" class="cls_008"><span class="cls_008">puts, which means that the algorithm has to try to classify the data on their</span></div>
<div style="position:absolute;left:124.80px;top:297.17px" class="cls_008"><span class="cls_008">own merit. The most common method as of right now is clustering algorithms</span></div>
<div style="position:absolute;left:124.80px;top:309.13px" class="cls_008"><span class="cls_008">(explained below in section 3.3).</span></div>
<div style="position:absolute;left:124.80px;top:337.69px" class="cls_010"><span class="cls_010">3.2</span></div>
<div style="position:absolute;left:161.56px;top:337.69px" class="cls_010"><span class="cls_010">Anomaly Detection</span></div>
<div style="position:absolute;left:124.80px;top:363.89px" class="cls_008"><span class="cls_008">Anomaly detection revolves around finding data points that do not conform</span></div>
<div style="position:absolute;left:124.80px;top:375.85px" class="cls_008"><span class="cls_008">with the rest of the dataset. An anomaly is a data point which is different from</span></div>
<div style="position:absolute;left:124.80px;top:387.80px" class="cls_008"><span class="cls_008">the norm with respect to the features of that point. In the context of the NTA</span></div>
<div style="position:absolute;left:124.80px;top:399.76px" class="cls_008"><span class="cls_008">data, an anomaly might be a person working 2500 hours per month.  There</span></div>
<div style="position:absolute;left:124.80px;top:411.71px" class="cls_008"><span class="cls_008">are several difficulties to overcome when working with anomaly detection. One</span></div>
<div style="position:absolute;left:124.80px;top:423.67px" class="cls_008"><span class="cls_008">of the major problems is that there is a lot of noise in the dataset which can</span></div>
<div style="position:absolute;left:124.80px;top:435.62px" class="cls_008"><span class="cls_008">be misinterpreted as abnormal behavior. We have used four different anomaly</span></div>
<div style="position:absolute;left:124.80px;top:447.58px" class="cls_008"><span class="cls_008">detection techniques, each with their own pros and cons. They will be presented</span></div>
<div style="position:absolute;left:124.80px;top:459.54px" class="cls_008"><span class="cls_008">later in this chapter.</span></div>
<div style="position:absolute;left:124.80px;top:488.10px" class="cls_010"><span class="cls_010">3.3</span></div>
<div style="position:absolute;left:161.56px;top:488.10px" class="cls_010"><span class="cls_010">Clustering</span></div>
<div style="position:absolute;left:124.80px;top:514.30px" class="cls_008"><span class="cls_008">The purpose of clustering is to arrange a collection of data into groups (clusters),</span></div>
<div style="position:absolute;left:124.80px;top:526.26px" class="cls_008"><span class="cls_008">where items within the same cluster are similar to each other in terms of their</span></div>
<div style="position:absolute;left:124.80px;top:538.21px" class="cls_008"><span class="cls_008">properties and/or features.  Clustering algorithms are used when there are no</span></div>
<div style="position:absolute;left:124.80px;top:550.17px" class="cls_008"><span class="cls_008">labels or classifiers. It is a common technique for statistical data analysis across</span></div>
<div style="position:absolute;left:124.80px;top:562.12px" class="cls_008"><span class="cls_008">many fields [8].</span></div>
<div style="position:absolute;left:124.80px;top:588.02px" class="cls_017"><span class="cls_017">3.3.1</span></div>
<div style="position:absolute;left:165.90px;top:588.02px" class="cls_017"><span class="cls_017">K-means Clustering</span></div>
<div style="position:absolute;left:124.80px;top:608.40px" class="cls_008"><span class="cls_008">Originally proposed by Stuart Lloyd in 1982 as a method for pulse-code mod-</span></div>
<div style="position:absolute;left:124.80px;top:620.35px" class="cls_008"><span class="cls_008">ulation in signal processing [11], K-means clustering is now one of the most</span></div>
<div style="position:absolute;left:124.80px;top:632.31px" class="cls_008"><span class="cls_008">popular ML algorithms for analyzing clusters in data mining.  Used as an un-</span></div>
<div style="position:absolute;left:124.80px;top:644.27px" class="cls_008"><span class="cls_008">supervised learning algorithm it performs computations on the actual dataset</span></div>
<div style="position:absolute;left:124.80px;top:656.22px" class="cls_008"><span class="cls_008">without prediction and with no need for labeled training data.</span></div>
<div style="position:absolute;left:139.75px;top:668.18px" class="cls_008"><span class="cls_008">The aim of the algorithm is to group n similar data points in a unlabeled,</span></div>
<div style="position:absolute;left:124.80px;top:680.13px" class="cls_008"><span class="cls_008">multidimensional dataset into k predetermined clusters.  Each cluster centroid</span></div>
<div style="position:absolute;left:124.80px;top:692.09px" class="cls_008"><span class="cls_008">is the arithmetic mean of all data points belonging to that cluster, and each</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">15</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:15318px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background019.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">point is closer to its own centroid than to another centroid.  This results in a</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">partitioning of the data space into Voronoi cells.</span></div>
<div style="position:absolute;left:139.75px;top:148.82px" class="cls_008"><span class="cls_008">To achieve this, K-means employs an iterative refinement technique similar</span></div>
<div style="position:absolute;left:124.80px;top:160.77px" class="cls_008"><span class="cls_008">to the Expectation-maximization algorithm that is used a lot in data science.</span></div>
<div style="position:absolute;left:124.80px;top:172.73px" class="cls_008"><span class="cls_008">Although some computer scientists refer to the algorithm as Lloyd’s algorithm,</span></div>
<div style="position:absolute;left:124.80px;top:184.68px" class="cls_008"><span class="cls_008">it differs slightly from Lloyd’s in that it’s input is a discrete set of points and</span></div>
<div style="position:absolute;left:124.80px;top:196.64px" class="cls_008"><span class="cls_008">not a continuous geometric region. Instead the “K-means algorithm” should be</span></div>
<div style="position:absolute;left:124.80px;top:208.59px" class="cls_008"><span class="cls_008">used when referring to it.</span></div>
<div style="position:absolute;left:139.75px;top:220.55px" class="cls_008"><span class="cls_008">The standard algorithm works as follows:</span></div>
<div style="position:absolute;left:161.00px;top:416.39px" class="cls_008"><span class="cls_008">Figure 3.2: Example of randomly placed centroids with k = 2.</span></div>
<div style="position:absolute;left:139.75px;top:453.68px" class="cls_008"><span class="cls_008">Firstly, based on the k number of clusters input, the algorithm guesses k</span></div>
<div style="position:absolute;left:124.80px;top:465.63px" class="cls_008"><span class="cls_008">instances of centroids randomly (Figure 3.2) which are then used as a starting</span></div>
<div style="position:absolute;left:124.80px;top:477.59px" class="cls_008"><span class="cls_008">point for calculating the clusters.</span></div>
<div style="position:absolute;left:124.80px;top:673.42px" class="cls_008"><span class="cls_008">Figure 3.3: Each data point is assigned a cluster based on it’s nearest centroid.</span></div>
<div style="position:absolute;left:139.75px;top:710.71px" class="cls_008"><span class="cls_008">The algorithm then proceeds with the</span><span class="cls_007"> assignment step</span><span class="cls_008"> (Figure 3.3). Here</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">16</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:16169px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background020.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">each data point is assigned to the cluster of its nearest centroid. This is done by</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">calculating the least squared Euclidean Distance (see 3.13) from the data points</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">to the centroids using the formula:</span></div>
<div style="position:absolute;left:202.31px;top:165.35px" class="cls_008"><span class="cls_008">{</span></div>
<div style="position:absolute;left:226.73px;top:164.95px" class="cls_008"><span class="cls_008"></span></div>
<div style="position:absolute;left:273.22px;top:164.95px" class="cls_008"><span class="cls_008"></span></div>
<div style="position:absolute;left:343.00px;top:164.95px" class="cls_008"><span class="cls_008"></span></div>
<div style="position:absolute;left:172.61px;top:171.24px" class="cls_008"><span class="cls_008">S</span><span class="cls_018"><sup>(t)</sup></span></div>
<div style="position:absolute;left:191.80px;top:173.42px" class="cls_008"><span class="cls_008">=</span></div>
<div style="position:absolute;left:208.12px;top:173.42px" class="cls_008"><span class="cls_008">x</span><span class="cls_018"><sub>p</sub></span><span class="cls_008"> :</span></div>
<div style="position:absolute;left:226.73px;top:170.93px" class="cls_008"><span class="cls_008">x</span><span class="cls_018">p</span><span class="cls_008"> − m</span><span class="cls_018"><sup>(t)</sup></span></div>
<div style="position:absolute;left:273.22px;top:164.95px" class="cls_008"><span class="cls_008"></span><span class="cls_018"><sup>2</sup></span><span class="cls_008"> ≤</span></div>
<div style="position:absolute;left:302.04px;top:171.24px" class="cls_008"><span class="cls_008">x</span><span class="cls_018"><sub>p</sub></span><span class="cls_008"> − m</span><span class="cls_018"><sup>(t)</sup></span></div>
<div style="position:absolute;left:343.00px;top:165.35px" class="cls_008"><span class="cls_008"></span><span class="cls_018"><sup>2</sup></span><span class="cls_008"> ∀j,1 ≤ j ≤ k},</span></div>
<div style="position:absolute;left:178.72px;top:179.19px" class="cls_018"><span class="cls_018">i</span></div>
<div style="position:absolute;left:263.48px;top:179.19px" class="cls_018"><span class="cls_018">i</span></div>
<div style="position:absolute;left:333.26px;top:179.19px" class="cls_018"><span class="cls_018">j</span></div>
<div style="position:absolute;left:139.75px;top:192.75px" class="cls_008"><span class="cls_008">where each x</span><span class="cls_018"><sub>p</sub></span><span class="cls_008"> is assigned to exactly one S</span><span class="cls_018"><sup>(t)</sup></span><span class="cls_008">, even if it could be assigned to</span></div>
<div style="position:absolute;left:124.80px;top:205.33px" class="cls_008"><span class="cls_008">two or more of them. [27]</span></div>
<div style="position:absolute;left:154.32px;top:401.89px" class="cls_008"><span class="cls_008">Figure 3.4: The centroids are updated based on the new clusters.</span></div>
<div style="position:absolute;left:139.75px;top:439.35px" class="cls_008"><span class="cls_008">Next, in the</span><span class="cls_007"> update step</span><span class="cls_008"> (Figure 3.4) the algorithm calculates and updates</span></div>
<div style="position:absolute;left:124.80px;top:451.31px" class="cls_008"><span class="cls_008">the centroids using the formula:</span></div>
<div style="position:absolute;left:318.17px;top:467.75px" class="cls_008"><span class="cls_008">∑</span></div>
<div style="position:absolute;left:294.70px;top:470.48px" class="cls_008"><span class="cls_008">1</span></div>
<div style="position:absolute;left:242.61px;top:475.03px" class="cls_008"><span class="cls_008">m</span><span class="cls_018"><sup>(t+1)</sup></span></div>
<div style="position:absolute;left:273.94px;top:477.22px" class="cls_008"><span class="cls_008">=</span></div>
<div style="position:absolute;left:285.66px;top:476.12px" class="cls_008"><span class="cls_008"></span></div>
<div style="position:absolute;left:305.39px;top:476.12px" class="cls_008"><span class="cls_008"></span></div>
<div style="position:absolute;left:340.82px;top:477.22px" class="cls_008"><span class="cls_008">x</span><span class="cls_018"><sub>j</sub></span></div>
<div style="position:absolute;left:251.35px;top:482.98px" class="cls_018"><span class="cls_018">i</span></div>
<div style="position:absolute;left:285.66px;top:482.10px" class="cls_008"><span class="cls_008"></span></div>
<div style="position:absolute;left:298.77px;top:485.39px" class="cls_018"><span class="cls_018">t)</span></div>
<div style="position:absolute;left:305.39px;top:482.10px" class="cls_008"><span class="cls_008"></span></div>
<div style="position:absolute;left:285.66px;top:485.39px" class="cls_008"><span class="cls_008">S</span><span class="cls_018"><sup>(</sup></span></div>
<div style="position:absolute;left:295.09px;top:493.34px" class="cls_018"><span class="cls_018">i</span></div>
<div style="position:absolute;left:305.39px;top:488.08px" class="cls_008"><span class="cls_008"></span><span class="cls_018"> x</span><span class="cls_019">j</span><span class="cls_018"> ∈S</span><span class="cls_019"><sup>(t)</sup></span></div>
<div style="position:absolute;left:330.07px;top:499.23px" class="cls_019"><span class="cls_019">i</span></div>
<div style="position:absolute;left:124.80px;top:513.07px" class="cls_008"><span class="cls_008">Simply explained, this calculates the average location of all the data point in a</span></div>
<div style="position:absolute;left:124.80px;top:525.03px" class="cls_008"><span class="cls_008">cluster and then moves the centroid to that location.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">17</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:17020px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background021.jpg" width=595 height=841></div>
<div style="position:absolute;left:178.38px;top:296.07px" class="cls_008"><span class="cls_008">Figure 3.5: The data points are assigned new clusters.</span></div>
<div style="position:absolute;left:139.75px;top:333.47px" class="cls_008"><span class="cls_008">Then it proceeds by alternating between the</span><span class="cls_007"> assignment step</span><span class="cls_008"> and the</span></div>
<div style="position:absolute;left:124.80px;top:345.42px" class="cls_007"><span class="cls_007">update step</span><span class="cls_008"> repeatedly.  Each of these repetitions should, under normal cir-</span></div>
<div style="position:absolute;left:124.80px;top:357.38px" class="cls_008"><span class="cls_008">cumstances, always result in a better estimation of the cluster characteristics.</span></div>
<div style="position:absolute;left:218.46px;top:553.33px" class="cls_008"><span class="cls_008">Figure 3.6: K-means has converged.</span></div>
<div style="position:absolute;left:139.75px;top:590.74px" class="cls_008"><span class="cls_008">The algorithm finally converges (Figure 3.6) when the</span><span class="cls_007"> assignment step</span></div>
<div style="position:absolute;left:124.80px;top:602.69px" class="cls_008"><span class="cls_008">no longer changes any data points to new clusters.  Although the algorithm</span></div>
<div style="position:absolute;left:124.80px;top:614.65px" class="cls_008"><span class="cls_008">is guaranteed to converge [20] , there is no guarantee of finding the optimal</span></div>
<div style="position:absolute;left:124.80px;top:626.60px" class="cls_008"><span class="cls_008">clusters.</span></div>
<div style="position:absolute;left:124.80px;top:652.47px" class="cls_017"><span class="cls_017">3.3.2</span></div>
<div style="position:absolute;left:165.90px;top:652.47px" class="cls_017"><span class="cls_017">Density-Based Spatial Clustering of Applications with</span></div>
<div style="position:absolute;left:165.90px;top:666.42px" class="cls_017"><span class="cls_017">Noise</span></div>
<div style="position:absolute;left:124.80px;top:686.80px" class="cls_008"><span class="cls_008">DBSCAN was first introduced by Martin Ester, et al.[6], in 1996 and is a com-</span></div>
<div style="position:absolute;left:124.80px;top:698.76px" class="cls_008"><span class="cls_008">mon clustering algorithm in unsupervised machine learning.  DBSCAN is a</span></div>
<div style="position:absolute;left:124.80px;top:710.71px" class="cls_008"><span class="cls_008">density-based algorithm in which the goal is to identify dense regions of data</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">18</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:17871px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background022.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">separated by areas of low density, often labeled as noise. In other words, data</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">within dense regions are considered as part of a cluster while data outside clus-</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">ters is considered as noise.  Unlike other cluster algorithms such as K-means</span></div>
<div style="position:absolute;left:124.80px;top:160.77px" class="cls_008"><span class="cls_008">(see 3.3.1), DBSCAN is designed to discover an arbitrary number of clusters of</span></div>
<div style="position:absolute;left:124.80px;top:172.73px" class="cls_008"><span class="cls_008">spacial data with arbitrary shapes or forms, as-well as noise It does this without</span></div>
<div style="position:absolute;left:124.80px;top:184.68px" class="cls_008"><span class="cls_008">having to define a number of clusters prior. The illustrations in figure 3.7 shows</span></div>
<div style="position:absolute;left:124.80px;top:196.64px" class="cls_008"><span class="cls_008">how DBSCAN can discover clusters of different sizes and shapes. We also notice</span></div>
<div style="position:absolute;left:124.80px;top:208.59px" class="cls_008"><span class="cls_008">that the points along the edge of the image are not part of any clusters, meaning</span></div>
<div style="position:absolute;left:124.80px;top:220.55px" class="cls_008"><span class="cls_008">that they are likely to be labeled as outliers.</span></div>
<div style="position:absolute;left:124.80px;top:365.17px" class="cls_008"><span class="cls_008">Figure 3.7:  Traditional clustering method such as K-means would struggle to</span></div>
<div style="position:absolute;left:124.80px;top:377.12px" class="cls_008"><span class="cls_008">differentiate the clusters. The image on the right visualize how DBSCAN could</span></div>
<div style="position:absolute;left:124.80px;top:389.08px" class="cls_008"><span class="cls_008">have clustered the data. Image taken from [12].</span></div>
<div style="position:absolute;left:124.80px;top:428.52px" class="cls_007"><span class="cls_007">The Algorithm</span></div>
<div style="position:absolute;left:124.80px;top:446.91px" class="cls_008"><span class="cls_008">To explain the algorithm, we start by defining the two most important parame-</span></div>
<div style="position:absolute;left:124.80px;top:458.87px" class="cls_008"><span class="cls_008">ters required to be initialized, namely eps and M inP ts. An intuitive definition</span></div>
<div style="position:absolute;left:124.80px;top:470.82px" class="cls_008"><span class="cls_008">for these parameters is the following:  eps is a value which represents a fixed</span></div>
<div style="position:absolute;left:124.80px;top:482.78px" class="cls_008"><span class="cls_008">radius from a arbitrary data point.  M inP ts is a value which defines a re-</span></div>
<div style="position:absolute;left:124.80px;top:494.73px" class="cls_008"><span class="cls_008">quired amount of nearby points to a selected data point, to form a cluster.</span></div>
<div style="position:absolute;left:124.80px;top:506.69px" class="cls_008"><span class="cls_008">The algorithm starts by selecting an arbitrary data-point p, and calculates how</span></div>
<div style="position:absolute;left:124.80px;top:518.64px" class="cls_008"><span class="cls_008">many neighbouring data points there exists within eps radius. If there exists an</span></div>
<div style="position:absolute;left:124.80px;top:530.60px" class="cls_008"><span class="cls_008">amount k ≥ M inP ts within eps radius of the point p, a cluster will be formed.</span></div>
<div style="position:absolute;left:124.80px;top:542.55px" class="cls_008"><span class="cls_008">Conversly, if this criteria is not met, the algorithm selects a new point and re-</span></div>
<div style="position:absolute;left:124.80px;top:554.51px" class="cls_008"><span class="cls_008">calculates for that particular data point.  By traversing through all the points</span></div>
<div style="position:absolute;left:124.80px;top:566.46px" class="cls_008"><span class="cls_008">in a dataset, data-points will be labeled as part of a specific cluster, or as noise</span></div>
<div style="position:absolute;left:124.80px;top:578.42px" class="cls_008"><span class="cls_008">("Outlier").</span></div>
<div style="position:absolute;left:139.75px;top:590.37px" class="cls_008"><span class="cls_008">There are three types of data points in the DBSCAN algorithm. Their type</span></div>
<div style="position:absolute;left:124.80px;top:602.33px" class="cls_008"><span class="cls_008">is determined by the number of neighbours within a radius of eps.  The first</span></div>
<div style="position:absolute;left:124.80px;top:614.28px" class="cls_008"><span class="cls_008">one is called a core point. A point is ’core’ if the number of neighbours within</span></div>
<div style="position:absolute;left:124.80px;top:626.24px" class="cls_008"><span class="cls_008">eps radius are greater than or equal to the M inP ts value. Usually, most points</span></div>
<div style="position:absolute;left:124.80px;top:638.20px" class="cls_008"><span class="cls_008">within a cluster are core points. The second type is called border points. These</span></div>
<div style="position:absolute;left:124.80px;top:650.15px" class="cls_008"><span class="cls_008">are points that lie on the border of a cluster. These are determined by checking</span></div>
<div style="position:absolute;left:124.80px;top:662.11px" class="cls_008"><span class="cls_008">if there exists another core data point within eps radius. This means that the</span></div>
<div style="position:absolute;left:124.80px;top:674.06px" class="cls_008"><span class="cls_008">data point in question does not require a number of M inP ts within eps radius</span></div>
<div style="position:absolute;left:124.80px;top:686.02px" class="cls_008"><span class="cls_008">to form a cluster, simply a core point is needed. The last type of points is often</span></div>
<div style="position:absolute;left:124.80px;top:697.97px" class="cls_008"><span class="cls_008">referred to as noise or outliers. These are points that do not meet the criteria</span></div>
<div style="position:absolute;left:124.80px;top:709.93px" class="cls_008"><span class="cls_008">of M inP ts within eps radius, and are also not attached to a ’core’ point.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">19</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:18722px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background023.jpg" width=595 height=841></div>
<div style="position:absolute;left:139.75px;top:124.91px" class="cls_008"><span class="cls_008">Inspecting figure 3.8 below, we observe that the core point does meet the</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">criteria of M inP ts = 3 within eps radius, illustrated as the dotted line.  The</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">border point does not meet the core point criteria, but is ’attached’ to a core</span></div>
<div style="position:absolute;left:124.80px;top:160.77px" class="cls_008"><span class="cls_008">point, making it a part of that cluster. The outlier points has no neighbouring</span></div>
<div style="position:absolute;left:124.80px;top:172.73px" class="cls_008"><span class="cls_008">corepoint within eps radius and is therefore labeled as an outlier.</span></div>
<div style="position:absolute;left:179.57px;top:343.85px" class="cls_008"><span class="cls_008">Figure 3.8: Illustration of the different type of points.</span></div>
<div style="position:absolute;left:139.75px;top:381.31px" class="cls_008"><span class="cls_008">Referring to the original DBSCAN paper [6], we will introduce some sim-</span></div>
<div style="position:absolute;left:124.80px;top:393.27px" class="cls_008"><span class="cls_008">plified definitions that will illustrate some of the important aspects of the al-</span></div>
<div style="position:absolute;left:124.80px;top:405.22px" class="cls_008"><span class="cls_008">gorithm in more depth. These aspects define some traits that DBSCAN holds,</span></div>
<div style="position:absolute;left:124.80px;top:417.18px" class="cls_008"><span class="cls_008">e.g. detecting clusters of arbitrary shapes and sizes as shown in figure 3.7.</span></div>
<div style="position:absolute;left:124.80px;top:441.09px" class="cls_007"><span class="cls_007">Definition 1 - (Epsilon of a point)</span></div>
<div style="position:absolute;left:124.80px;top:460.24px" class="cls_008"><span class="cls_008">The epsilon value is defined as the radius of a point p. A point q lies within the</span></div>
<div style="position:absolute;left:124.80px;top:472.20px" class="cls_008"><span class="cls_008">epsilon of point p if</span></div>
<div style="position:absolute;left:263.42px;top:484.15px" class="cls_008"><span class="cls_008">dist(q, p) ≤ eps</span></div>
<div style="position:absolute;left:124.80px;top:502.09px" class="cls_008"><span class="cls_008">where dist(q,p) is the distance metric.</span></div>
<div style="position:absolute;left:124.80px;top:526.00px" class="cls_007"><span class="cls_007">Definition 2 - (Directly density-reachable)</span></div>
<div style="position:absolute;left:124.80px;top:545.15px" class="cls_008"><span class="cls_008">A point p is directly density-reachable to point q if</span></div>
<div style="position:absolute;left:263.42px;top:567.07px" class="cls_008"><span class="cls_008">dist(q, p) ≤ eps</span></div>
<div style="position:absolute;left:124.80px;top:588.99px" class="cls_008"><span class="cls_008">and</span></div>
<div style="position:absolute;left:255.46px;top:600.94px" class="cls_008"><span class="cls_008">N</span><span class="cls_018"><sub>eps</sub></span><span class="cls_008">(p) ≥ MinPts</span></div>
<div style="position:absolute;left:124.80px;top:618.87px" class="cls_008"><span class="cls_008">where the latter is defined as; The number of neighbouring points within eps is</span></div>
<div style="position:absolute;left:124.80px;top:630.83px" class="cls_008"><span class="cls_008">greater or equal to parameter MinPts. This implies that point p is a core point.</span></div>
<div style="position:absolute;left:124.80px;top:666.70px" class="cls_007"><span class="cls_007">Definition 3 - (Density-reachable)</span></div>
<div style="position:absolute;left:124.80px;top:685.85px" class="cls_008"><span class="cls_008">A point p is density-reachable from point q, if there exists points p</span><span class="cls_018"><sub>1</sub></span><span class="cls_008">,p</span><span class="cls_018"><sub>2</sub></span><span class="cls_008">...p</span><span class="cls_018"><sub>i</sub></span></div>
<div style="position:absolute;left:124.80px;top:697.81px" class="cls_008"><span class="cls_008">in which fulfills definition 2 (directly density-reachable).  Thus a point p can</span></div>
<div style="position:absolute;left:124.80px;top:709.76px" class="cls_008"><span class="cls_008">possibly be density-reachable to q, by chained data points.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">20</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:19573px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background024.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_007"><span class="cls_007">Definition 4 - (Density-connected)</span></div>
<div style="position:absolute;left:124.80px;top:144.06px" class="cls_008"><span class="cls_008">A point p is density-connected to point q, if both p and q are density-reachable</span></div>
<div style="position:absolute;left:124.80px;top:156.02px" class="cls_008"><span class="cls_008">from a third point o with respect to M inP ts and eps.</span></div>
<div style="position:absolute;left:124.80px;top:179.93px" class="cls_007"><span class="cls_007">Definition 5</span><span class="cls_008"> (Cluster)</span></div>
<div style="position:absolute;left:124.80px;top:199.09px" class="cls_008"><span class="cls_008">A cluster in a dataset, d, is a non-empty subset of that dataset and satisfies</span></div>
<div style="position:absolute;left:124.80px;top:211.04px" class="cls_008"><span class="cls_008">the following conditions:  All points inside the cluster are mutually density-</span></div>
<div style="position:absolute;left:124.80px;top:223.00px" class="cls_008"><span class="cls_008">connected (def. 4). If a point is density-reachable (border point), it is part of</span></div>
<div style="position:absolute;left:124.80px;top:234.95px" class="cls_008"><span class="cls_008">the cluster.</span></div>
<div style="position:absolute;left:124.80px;top:263.51px" class="cls_010"><span class="cls_010">3.4</span></div>
<div style="position:absolute;left:161.56px;top:263.51px" class="cls_010"><span class="cls_010">Local Outlier Factor</span></div>
<div style="position:absolute;left:124.80px;top:289.72px" class="cls_008"><span class="cls_008">Local Outlier Factor is an unsupervised density-based algorithm developed by</span></div>
<div style="position:absolute;left:124.80px;top:301.67px" class="cls_008"><span class="cls_008">Breunig et al.</span></div>
<div style="position:absolute;left:194.54px;top:301.67px" class="cls_008"><span class="cls_008">[4] in 2000.  The algorithm proposes a degree of ’outlierness’</span></div>
<div style="position:absolute;left:124.80px;top:313.63px" class="cls_008"><span class="cls_008">of a point, as an alternative to binary outlier detection models. Each point of</span></div>
<div style="position:absolute;left:124.80px;top:325.58px" class="cls_008"><span class="cls_008">a data-set is assigned a degree, which represents the local outlier factor with</span></div>
<div style="position:absolute;left:124.80px;top:337.54px" class="cls_008"><span class="cls_008">respect to its k-nearest-neighbours.  This k-nearest-neighbours variable is set</span></div>
<div style="position:absolute;left:124.80px;top:349.49px" class="cls_008"><span class="cls_008">prior to applying the algorithm, to define the amount of neighbouring points in</span></div>
<div style="position:absolute;left:124.80px;top:361.45px" class="cls_008"><span class="cls_008">which to compare the local densities with.</span></div>
<div style="position:absolute;left:139.75px;top:373.40px" class="cls_008"><span class="cls_008">In order to describe this algorithm more thoroughly, we will introduce two</span></div>
<div style="position:absolute;left:124.80px;top:385.36px" class="cls_008"><span class="cls_008">formulas. Reachability-distance (reach-dist) and local reachability density (lrd).</span></div>
<div style="position:absolute;left:124.80px;top:397.31px" class="cls_008"><span class="cls_008">Also a third notation k-distance is explained below.</span></div>
<div style="position:absolute;left:124.80px;top:423.21px" class="cls_007"><span class="cls_007">The Algorithm</span></div>
<div style="position:absolute;left:124.80px;top:441.60px" class="cls_007"><span class="cls_007">K-distance</span></div>
<div style="position:absolute;left:139.75px;top:453.55px" class="cls_008"><span class="cls_008">The k-distance of a point is merely the distance from a point p, to the k-th</span></div>
<div style="position:absolute;left:124.80px;top:465.51px" class="cls_008"><span class="cls_008">nearest neighbour.  I.e.  k = 5, k-distance is the distance from point p, to its</span></div>
<div style="position:absolute;left:124.80px;top:477.46px" class="cls_008"><span class="cls_008">fifth nearest neighbour.</span></div>
<div style="position:absolute;left:124.80px;top:501.37px" class="cls_007"><span class="cls_007">Reachability-distance</span></div>
<div style="position:absolute;left:191.84px;top:525.29px" class="cls_008"><span class="cls_008">reach-dist(q, p) = max(k-distance(p), dist(q, p))</span></div>
<div style="position:absolute;left:139.75px;top:543.22px" class="cls_008"><span class="cls_008">The reachability-distance between two points, is the maximum of the k-</span></div>
<div style="position:absolute;left:124.80px;top:555.17px" class="cls_008"><span class="cls_008">distance, and the distance between the points.</span></div>
<div style="position:absolute;left:124.80px;top:579.08px" class="cls_007"><span class="cls_007">Lrd</span></div>
<div style="position:absolute;left:362.33px;top:595.19px" class="cls_008"><span class="cls_008">)</span></div>
<div style="position:absolute;left:274.17px;top:595.19px" class="cls_008"><span class="cls_008">(Σ</span><span class="cls_018"><sub>x</sub></span><span class="cls_008">reach-dist(q,x)</span></div>
<div style="position:absolute;left:225.04px;top:606.25px" class="cls_008"><span class="cls_008">lrd(p) = 1/</span></div>
<div style="position:absolute;left:304.39px;top:613.08px" class="cls_008"><span class="cls_008">|N</span><span class="cls_018"><sub>k</sub></span><span class="cls_008"> (A)|</span></div>
<div style="position:absolute;left:139.75px;top:629.41px" class="cls_008"><span class="cls_008">The local-reachability-density takes all the reachability-distances from a spa-</span></div>
<div style="position:absolute;left:124.80px;top:641.36px" class="cls_008"><span class="cls_008">cial point to its k-nearest-neighbours, and calculates the average distance to</span></div>
<div style="position:absolute;left:124.80px;top:653.32px" class="cls_008"><span class="cls_008">these points.</span></div>
<div style="position:absolute;left:139.75px;top:677.23px" class="cls_008"><span class="cls_008">The k-distance is used to calculate the reachability-distance which measures</span></div>
<div style="position:absolute;left:124.80px;top:689.18px" class="cls_008"><span class="cls_008">distance between two points. For a point p, we calculate this k-distance to all</span></div>
<div style="position:absolute;left:124.80px;top:701.14px" class="cls_008"><span class="cls_008">the k-nearest-neighbors.  Now that we have the distances to all the k points</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">21</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:20424px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background025.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">closest to p, we can calculate the local reachability density (lrd) of that point.</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">The lrd is basically the average distance from p, to all the k-nearest points.</span></div>
<div style="position:absolute;left:139.75px;top:148.82px" class="cls_008"><span class="cls_008">After this is done for all points in the dataset, we can then compare the lrd</span></div>
<div style="position:absolute;left:124.80px;top:160.77px" class="cls_008"><span class="cls_008">of point p, with the average lrd of its k-nearest points.  This is simply a ratio</span></div>
<div style="position:absolute;left:124.80px;top:172.73px" class="cls_008"><span class="cls_008">calculation which tells us whether this point p has a higher lrd distance than</span></div>
<div style="position:absolute;left:124.80px;top:184.68px" class="cls_008"><span class="cls_008">the average of its k-nearest points. In short, if this ration r > 1 of a point p, the</span></div>
<div style="position:absolute;left:124.80px;top:196.64px" class="cls_008"><span class="cls_008">point has a greater local outlier factor score (LOF score) than its k-neighbors.</span></div>
<div style="position:absolute;left:139.75px;top:208.59px" class="cls_008"><span class="cls_008">In contrast to DBSCAN, the only hyper-parameter required for LOF is n-</span></div>
<div style="position:absolute;left:124.80px;top:220.55px" class="cls_008"><span class="cls_008">neighbours often denoted as k-nearest-neighbour or k.  As stated earlier, this</span></div>
<div style="position:absolute;left:124.80px;top:232.51px" class="cls_008"><span class="cls_008">variable defines the amount of neighbouring points of a point p, to compare the</span></div>
<div style="position:absolute;left:124.80px;top:244.46px" class="cls_008"><span class="cls_008">local density with.  A second valuable parameter is contamination.  In short,</span></div>
<div style="position:absolute;left:124.80px;top:256.42px" class="cls_008"><span class="cls_008">when we have calculated the local outlier factor of each point, these values are</span></div>
<div style="position:absolute;left:124.80px;top:268.37px" class="cls_008"><span class="cls_008">sorted in ascending order. The contamination variables defines the percentage of</span></div>
<div style="position:absolute;left:124.80px;top:280.33px" class="cls_008"><span class="cls_008">these outlier factors we would like to define as outliers. If we set contamination</span></div>
<div style="position:absolute;left:124.80px;top:292.28px" class="cls_008"><span class="cls_008">to 0.5, 5 percent of our data will be labeled as outliers.</span></div>
<div style="position:absolute;left:139.75px;top:304.24px" class="cls_008"><span class="cls_008">Shown in the image, k is set to 3.  The circle around the points illustrates</span></div>
<div style="position:absolute;left:124.80px;top:316.19px" class="cls_008"><span class="cls_008">the distance to the k-th point. We can easily see that point o, has a larger lrd</span></div>
<div style="position:absolute;left:124.80px;top:328.15px" class="cls_008"><span class="cls_008">than its k-neighbor points, thus its local outlier factor will be higher than 1 with</span></div>
<div style="position:absolute;left:124.80px;top:340.10px" class="cls_008"><span class="cls_008">respect to the k-neighbouring points.</span></div>
<div style="position:absolute;left:239.84px;top:522.92px" class="cls_008"><span class="cls_008">Figure 3.9: LOF k = 3 [6]</span></div>
<div style="position:absolute;left:124.80px;top:565.03px" class="cls_010"><span class="cls_010">3.5</span></div>
<div style="position:absolute;left:161.56px;top:565.03px" class="cls_010"><span class="cls_010">Pattern Mining</span></div>
<div style="position:absolute;left:124.80px;top:591.24px" class="cls_008"><span class="cls_008">Pattern Mining is a subfield of data mining that consists of several data mining</span></div>
<div style="position:absolute;left:124.80px;top:603.19px" class="cls_008"><span class="cls_008">algorithms for discovering unknown patterns in a transactional database. These</span></div>
<div style="position:absolute;left:124.80px;top:615.15px" class="cls_008"><span class="cls_008">relationships or unknown patterns can be defined as association rules if their</span></div>
<div style="position:absolute;left:124.80px;top:627.10px" class="cls_008"><span class="cls_008">occurrence is higher than some confidence level. Originally, pattern mining was</span></div>
<div style="position:absolute;left:124.80px;top:639.06px" class="cls_008"><span class="cls_008">used in Market Basket Analysis (MBA) [25].  MBA is a modelling technique</span></div>
<div style="position:absolute;left:124.80px;top:651.01px" class="cls_008"><span class="cls_008">based on the theory that if a consumer purchases a certain group of items</span></div>
<div style="position:absolute;left:124.80px;top:662.97px" class="cls_008"><span class="cls_008">(an itemset), they are more/less likely to get another particular itemset. This</span></div>
<div style="position:absolute;left:124.80px;top:674.92px" class="cls_008"><span class="cls_008">knowledge can then be utilized to enable marketers to develop and implement</span></div>
<div style="position:absolute;left:124.80px;top:686.88px" class="cls_008"><span class="cls_008">customized marketing strategies like store coupons, the placing of items in their</span></div>
<div style="position:absolute;left:124.80px;top:698.83px" class="cls_008"><span class="cls_008">stores, and cross-selling items.  In this section we will discuss the basic idea</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">22</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:21275px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background026.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">behind pattern mining and introduce unsupervised Rare Pattern Mining and</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">AprioriRare, which is the algorithm we used for mining minimal rare itemset.</span></div>
<div style="position:absolute;left:124.80px;top:162.76px" class="cls_017"><span class="cls_017">3.5.1</span></div>
<div style="position:absolute;left:165.90px;top:162.76px" class="cls_017"><span class="cls_017">Frequent Pattern Mining</span></div>
<div style="position:absolute;left:124.80px;top:183.14px" class="cls_008"><span class="cls_008">Frequent Pattern Mining was first proposed by Agrawal et al.[1] and the mo-</span></div>
<div style="position:absolute;left:124.80px;top:195.10px" class="cls_008"><span class="cls_008">tivation was to find correlations and association rules between transactions in</span></div>
<div style="position:absolute;left:124.80px;top:207.05px" class="cls_008"><span class="cls_008">a large transaction database. The idea behind frequent pattern mining is that</span></div>
<div style="position:absolute;left:124.80px;top:219.01px" class="cls_008"><span class="cls_008">there are hidden ’rules’ between transactions that can be found by looking at</span></div>
<div style="position:absolute;left:124.80px;top:230.96px" class="cls_008"><span class="cls_008">collections of items that are frequently bought together.  An association rule</span></div>
<div style="position:absolute;left:124.80px;top:242.92px" class="cls_008"><span class="cls_008">can be represented as A, B ⇒ C, meaning that item C is likely to be bought if</span></div>
<div style="position:absolute;left:124.80px;top:254.87px" class="cls_008"><span class="cls_008">the consumer also purchases A and B.</span></div>
<div style="position:absolute;left:139.75px;top:266.83px" class="cls_008"><span class="cls_008">Initially, identifying frequent patterns were the only interest for the pattern</span></div>
<div style="position:absolute;left:124.80px;top:278.78px" class="cls_008"><span class="cls_008">mining community.  The rare patterns were considered unimportant because</span></div>
<div style="position:absolute;left:124.80px;top:290.74px" class="cls_008"><span class="cls_008">they did not adequately reflect the global trends and characteristics of the data.</span></div>
<div style="position:absolute;left:124.80px;top:302.69px" class="cls_008"><span class="cls_008">The frequent patterns on the other hand, could be used for both modelling</span></div>
<div style="position:absolute;left:124.80px;top:314.65px" class="cls_008"><span class="cls_008">and prediction, as well as provide valuable information about the consumer be-</span></div>
<div style="position:absolute;left:124.80px;top:326.60px" class="cls_008"><span class="cls_008">haviour [23].  However, since the early 2000s the popularity of Rare Itemset</span></div>
<div style="position:absolute;left:124.80px;top:338.56px" class="cls_008"><span class="cls_008">Mining (RIM) has risen as researchers have experienced an increase in the de-</span></div>
<div style="position:absolute;left:124.80px;top:350.51px" class="cls_008"><span class="cls_008">mand for anomaly detection applications.  Discovering infrequent patterns is</span></div>
<div style="position:absolute;left:124.80px;top:362.47px" class="cls_008"><span class="cls_008">very valuable in fields like medicine, genetics and network security as they can</span></div>
<div style="position:absolute;left:124.80px;top:374.42px" class="cls_008"><span class="cls_008">cause harm if they go undiscovered. Many businesses can benefit from knowing</span></div>
<div style="position:absolute;left:124.80px;top:386.38px" class="cls_008"><span class="cls_008">about frequent patterns in their data, but one can harvest a lot of valuable</span></div>
<div style="position:absolute;left:124.80px;top:398.33px" class="cls_008"><span class="cls_008">information by instead looking for rare patterns, or anomalies. These patterns</span></div>
<div style="position:absolute;left:124.80px;top:410.29px" class="cls_008"><span class="cls_008">could represent previously unknown or unforeseen relationships. The rare pat-</span></div>
<div style="position:absolute;left:124.80px;top:422.24px" class="cls_008"><span class="cls_008">terns can then be manually reviewed by domain experts to determine credibility</span></div>
<div style="position:absolute;left:124.80px;top:434.20px" class="cls_008"><span class="cls_008">and usefulness.</span></div>
<div style="position:absolute;left:124.80px;top:460.10px" class="cls_017"><span class="cls_017">3.5.2</span></div>
<div style="position:absolute;left:165.90px;top:460.10px" class="cls_017"><span class="cls_017">Rare itemset Mining</span></div>
<div style="position:absolute;left:124.80px;top:480.48px" class="cls_008"><span class="cls_008">Rare itemset mining is similar to frequent pattern mining, except that instead</span></div>
<div style="position:absolute;left:124.80px;top:492.43px" class="cls_008"><span class="cls_008">of looking for the frequent patterns in the data, it looks for the anomalies. In</span></div>
<div style="position:absolute;left:124.80px;top:504.39px" class="cls_008"><span class="cls_008">this section we will introduce two terms which one should be familiar with in</span></div>
<div style="position:absolute;left:124.80px;top:516.34px" class="cls_008"><span class="cls_008">order to follow along, namely support and minimal rare itemset.  Support is</span></div>
<div style="position:absolute;left:124.80px;top:528.30px" class="cls_008"><span class="cls_008">the threshold that decides whether or not an itemset is labeled frequent.  The</span></div>
<div style="position:absolute;left:124.80px;top:540.25px" class="cls_008"><span class="cls_008">support of an itemset X is defined as:</span></div>
<div style="position:absolute;left:295.22px;top:560.68px" class="cls_008"><span class="cls_008">σ(X)</span></div>
<div style="position:absolute;left:274.06px;top:567.42px" class="cls_008"><span class="cls_008">S =</span></div>
<div style="position:absolute;left:300.27px;top:574.25px" class="cls_008"><span class="cls_008">|T |</span></div>
<div style="position:absolute;left:139.75px;top:591.19px" class="cls_008"><span class="cls_008">This means that an itemset X = {x</span><span class="cls_018"><sub>1</sub></span><span class="cls_008">, x</span><span class="cls_018"><sub>2</sub></span><span class="cls_008">, x</span><span class="cls_018"><sub>n</sub></span><span class="cls_008">, ...} is frequent only if the equa-</span></div>
<div style="position:absolute;left:124.80px;top:603.14px" class="cls_008"><span class="cls_008">tion below is true.</span></div>
<div style="position:absolute;left:258.00px;top:615.10px" class="cls_008"><span class="cls_008">S(X) ≥ minSupp</span></div>
<div style="position:absolute;left:139.75px;top:633.03px" class="cls_008"><span class="cls_008">But if the equation is not true, it does not mean that the itemset automat-</span></div>
<div style="position:absolute;left:124.80px;top:644.99px" class="cls_008"><span class="cls_008">ically is a minimal rare itemset (mRI ). A mRI is an itemset where the whole</span></div>
<div style="position:absolute;left:124.80px;top:656.94px" class="cls_008"><span class="cls_008">set combined is rare/infrequent, but all its subset are frequent. As an example</span></div>
<div style="position:absolute;left:124.80px;top:668.90px" class="cls_008"><span class="cls_008">consider the following transactions with support threshold S</span><span class="cls_018"><sub>t</sub></span><span class="cls_008"> = 3:</span></div>
<div style="position:absolute;left:139.75px;top:680.85px" class="cls_008"><span class="cls_008">Each transaction consists of an itemset with 2-4 different items and no single</span></div>
<div style="position:absolute;left:124.80px;top:692.81px" class="cls_008"><span class="cls_008">item appear more than once in every transaction/itemset.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">23</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:22126px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background027.jpg" width=595 height=841></div>
<div style="position:absolute;left:231.66px;top:135.88px" class="cls_008"><span class="cls_008">Transaction</span></div>
<div style="position:absolute;left:306.08px;top:135.88px" class="cls_008"><span class="cls_008">Itemset</span></div>
<div style="position:absolute;left:252.16px;top:147.84px" class="cls_008"><span class="cls_008">T</span><span class="cls_018"><sub>1</sub></span></div>
<div style="position:absolute;left:294.90px;top:147.84px" class="cls_008"><span class="cls_008">{ 1, 2, 3, 5 }</span></div>
<div style="position:absolute;left:252.16px;top:159.79px" class="cls_008"><span class="cls_008">T</span><span class="cls_018"><sub>2</sub></span></div>
<div style="position:absolute;left:295.17px;top:159.79px" class="cls_008"><span class="cls_008">{</span></div>
<div style="position:absolute;left:313.99px;top:159.79px" class="cls_008"><span class="cls_008">2, 3, 5 }</span></div>
<div style="position:absolute;left:252.16px;top:171.75px" class="cls_008"><span class="cls_008">T</span><span class="cls_018"><sub>3</sub></span></div>
<div style="position:absolute;left:294.90px;top:171.75px" class="cls_008"><span class="cls_008">{ 1, 2, 4, 5 }</span></div>
<div style="position:absolute;left:252.16px;top:183.70px" class="cls_008"><span class="cls_008">T</span><span class="cls_018"><sub>4</sub></span></div>
<div style="position:absolute;left:294.90px;top:183.70px" class="cls_008"><span class="cls_008">{ 1, 2, 3, 5 }</span></div>
<div style="position:absolute;left:252.16px;top:195.66px" class="cls_008"><span class="cls_008">T</span><span class="cls_018"><sub>5</sub></span></div>
<div style="position:absolute;left:295.17px;top:195.66px" class="cls_008"><span class="cls_008">{</span></div>
<div style="position:absolute;left:325.07px;top:195.66px" class="cls_008"><span class="cls_008">1, 3 }</span></div>
<div style="position:absolute;left:161.95px;top:217.57px" class="cls_008"><span class="cls_008">Figure 3.10: Transaction example with support threshold = 3</span></div>
<div style="position:absolute;left:139.75px;top:253.04px" class="cls_008"><span class="cls_008">The support of an itemset is determined by the frequency of the set across</span></div>
<div style="position:absolute;left:124.80px;top:265.00px" class="cls_008"><span class="cls_008">all sets and subsets.  In Figure 3.10 the support threshold is set to 3.  This</span></div>
<div style="position:absolute;left:124.80px;top:276.95px" class="cls_008"><span class="cls_008">means that every set and subset with a support greater than or equal to 3 is</span></div>
<div style="position:absolute;left:124.80px;top:288.91px" class="cls_008"><span class="cls_008">considered frequent. The subset t</span><span class="cls_018"><sub>s</sub></span><span class="cls_008"> = {1, 2, 3} has a support of 2 because there</span></div>
<div style="position:absolute;left:124.80px;top:300.86px" class="cls_008"><span class="cls_008">are two sets or subsets containing all three items, namely T</span><span class="cls_018"><sub>1</sub></span><span class="cls_008"> and T</span><span class="cls_018"><sub>4</sub></span><span class="cls_008">. But is the</span></div>
<div style="position:absolute;left:124.80px;top:312.82px" class="cls_008"><span class="cls_008">set a minimal rare itemset? Yes, all the subsets of t</span><span class="cls_018"><sub>s</sub></span><span class="cls_008"> are frequent because their</span></div>
<div style="position:absolute;left:124.80px;top:324.77px" class="cls_008"><span class="cls_008">support is greater than or equal to 3.  This means that t</span><span class="cls_018"><sub>s</sub></span><span class="cls_008">  is a mRI and will</span></div>
<div style="position:absolute;left:124.80px;top:336.73px" class="cls_008"><span class="cls_008">be flagged as an outlier. In figure 3.11 on the next page one can see a visual</span></div>
<div style="position:absolute;left:124.80px;top:348.68px" class="cls_008"><span class="cls_008">representation of the algorithm with the same transactions as in figure 3.10.</span></div>
<div style="position:absolute;left:124.80px;top:655.43px" class="cls_008"><span class="cls_008">Figure 3.11:  Overview of Minimal Rare itemset.  The support of each set is</span></div>
<div style="position:absolute;left:124.80px;top:667.38px" class="cls_008"><span class="cls_008">represented with roman numerals in the top left corner of every box.</span></div>
<div style="position:absolute;left:139.75px;top:704.84px" class="cls_008"><span class="cls_008">We implemented an algorithm called AprioriRare. This is a RIM algorithm</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">24</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:22977px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background028.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">which finds mRI s. The algorithm is a modified version of the Apriori algorithm</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">[7], illustrated in figure 3.12. Apriori is a frequent pattern miner, but it also finds</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">mRI as a byproduct. AprioriRare saves these instead of the frequent itemsets.</span></div>
<div style="position:absolute;left:124.80px;top:160.77px" class="cls_008"><span class="cls_008">Details about the implementation of the algorithm will be discussed in chapter</span></div>
<div style="position:absolute;left:124.80px;top:172.73px" class="cls_008"><span class="cls_008">2 and results and analysis will be presented in chapter 6.</span></div>
<div style="position:absolute;left:186.53px;top:429.99px" class="cls_008"><span class="cls_008">Figure 3.12: Pseudo code of the Apriori algorithm</span></div>
<div style="position:absolute;left:124.80px;top:472.10px" class="cls_010"><span class="cls_010">3.6</span></div>
<div style="position:absolute;left:161.56px;top:472.10px" class="cls_010"><span class="cls_010">Euclidean metric</span></div>
<div style="position:absolute;left:124.80px;top:498.31px" class="cls_008"><span class="cls_008">The euclidean metric, often referred to as the L2-norm in mathematics, is a</span></div>
<div style="position:absolute;left:124.80px;top:510.26px" class="cls_008"><span class="cls_008">distance function often applied to machine learning algorithms. It measures the</span></div>
<div style="position:absolute;left:124.80px;top:522.22px" class="cls_008"><span class="cls_008">distance between two points in n-dimensional space in a "straight-line" manner.</span></div>
<div style="position:absolute;left:294.80px;top:538.26px" class="cls_008"><span class="cls_008">√</span></div>
<div style="position:absolute;left:254.34px;top:547.26px" class="cls_008"><span class="cls_008">d(q, p) =</span></div>
<div style="position:absolute;left:304.76px;top:547.26px" class="cls_008"><span class="cls_008">(q − p)</span><span class="cls_018"><sup>2</sup></span></div>
<div style="position:absolute;left:139.75px;top:576.02px" class="cls_008"><span class="cls_008">The formula shows the euclidean distance between two points in 1-dimensional</span></div>
<div style="position:absolute;left:124.80px;top:587.97px" class="cls_008"><span class="cls_008">space. This can easily be extended to n-dimensional space.</span></div>
<div style="position:absolute;left:230.44px;top:604.01px" class="cls_008"><span class="cls_008">√</span></div>
<div style="position:absolute;left:189.97px;top:613.02px" class="cls_008"><span class="cls_008">d(q, p) =</span></div>
<div style="position:absolute;left:240.40px;top:613.02px" class="cls_008"><span class="cls_008">(q</span><span class="cls_018"><sub>1</sub></span><span class="cls_008"> − p</span><span class="cls_018"><sub>1</sub></span><span class="cls_008">)</span><span class="cls_018"><sup>2</sup></span><span class="cls_008"> + (q</span><span class="cls_018"><sub>2</sub></span><span class="cls_008"> − p</span><span class="cls_018"><sub>2</sub></span><span class="cls_008">)</span><span class="cls_018"><sup>2</sup></span><span class="cls_008"> + ...(q</span><span class="cls_018"><sub>n</sub></span><span class="cls_008"> − p</span><span class="cls_018"><sub>n</sub></span><span class="cls_008">)</span><span class="cls_018"><sup>2</sup></span></div>
<div style="position:absolute;left:139.75px;top:641.77px" class="cls_008"><span class="cls_008">As illustrated in Figure 3.13, we want to determine the euclidean distance</span></div>
<div style="position:absolute;left:124.80px;top:653.73px" class="cls_008"><span class="cls_008">between two points, p and q in 2-dimensional space.</span></div>
<div style="position:absolute;left:308.92px;top:667.48px" class="cls_008"><span class="cls_008">√</span></div>
<div style="position:absolute;left:193.54px;top:676.48px" class="cls_008"><span class="cls_008">d(q, p) = d((6, 4), (2, 1)) =</span></div>
<div style="position:absolute;left:318.89px;top:676.48px" class="cls_008"><span class="cls_008">(6 − 2)</span><span class="cls_018"><sup>2</sup></span><span class="cls_008"> + (4 − 1)</span><span class="cls_018"><sup>2</sup></span></div>
<div style="position:absolute;left:193.54px;top:691.42px" class="cls_008"><span class="cls_008">d(q, p) = 5</span></div>
<div style="position:absolute;left:139.75px;top:709.46px" class="cls_008"><span class="cls_008">The euclidean distance between p and q (the hypotenuse in this case), is 5.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">25</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:23828px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background029.jpg" width=595 height=841></div>
<div style="position:absolute;left:177.01px;top:334.08px" class="cls_008"><span class="cls_008">Figure 3.13: Euclidean distance in 2-dimensional space</span></div>
<div style="position:absolute;left:124.80px;top:376.19px" class="cls_010"><span class="cls_010">3.7</span></div>
<div style="position:absolute;left:161.56px;top:376.19px" class="cls_010"><span class="cls_010">Principal Component Analysis</span></div>
<div style="position:absolute;left:124.80px;top:402.39px" class="cls_008"><span class="cls_008">Principal component analysis (PCA) is probably the best known and most</span></div>
<div style="position:absolute;left:124.80px;top:414.35px" class="cls_008"><span class="cls_008">widely used dimension-reduction tool [9]. It is a mathematical procedure that</span></div>
<div style="position:absolute;left:124.80px;top:426.30px" class="cls_008"><span class="cls_008">uses the eigenvectors and eigenvalues of the data to transform sets of possibly</span></div>
<div style="position:absolute;left:124.80px;top:438.26px" class="cls_008"><span class="cls_008">correlated variables into smaller sets of linearly uncorrelated variables called</span></div>
<div style="position:absolute;left:124.80px;top:450.21px" class="cls_008"><span class="cls_008">principal components.  These principal components can then be used as a</span></div>
<div style="position:absolute;left:124.80px;top:462.17px" class="cls_008"><span class="cls_008">dimension-reduction tool that can reduce the number of dimensions in a data</span></div>
<div style="position:absolute;left:124.80px;top:474.12px" class="cls_008"><span class="cls_008">set while still retaining most of the information.</span></div>
<div style="position:absolute;left:124.80px;top:502.69px" class="cls_010"><span class="cls_010">3.8</span></div>
<div style="position:absolute;left:161.56px;top:502.69px" class="cls_010"><span class="cls_010">Packages and Tools</span></div>
<div style="position:absolute;left:124.80px;top:528.89px" class="cls_017"><span class="cls_017">3.8.1</span></div>
<div style="position:absolute;left:165.90px;top:528.89px" class="cls_017"><span class="cls_017">Python</span></div>
<div style="position:absolute;left:124.80px;top:549.27px" class="cls_008"><span class="cls_008">Python is a widely used programming language for Machine Learning.  The</span></div>
<div style="position:absolute;left:124.80px;top:561.23px" class="cls_008"><span class="cls_008">language itself is easy to pick up due to its syntax and consistency. Consequently,</span></div>
<div style="position:absolute;left:124.80px;top:573.18px" class="cls_008"><span class="cls_008">the community is large and the libraries are many.  Python has libraries for</span></div>
<div style="position:absolute;left:124.80px;top:585.14px" class="cls_008"><span class="cls_008">Visualization, Statistics, Natural Language Processing (NLP) and Data analysis</span></div>
<div style="position:absolute;left:124.80px;top:597.09px" class="cls_008"><span class="cls_008">among others.  One can also interact directly with the code through Jupyter</span></div>
<div style="position:absolute;left:124.80px;top:609.05px" class="cls_008"><span class="cls_008">Notebook (3.8.8) or the terminal.  We chose python because it is the leading</span></div>
<div style="position:absolute;left:124.80px;top:621.00px" class="cls_008"><span class="cls_008">programming language when it comes to Machine Learning, and we had some</span></div>
<div style="position:absolute;left:124.80px;top:632.96px" class="cls_008"><span class="cls_008">experience with it from previous courses.</span></div>
<div style="position:absolute;left:124.80px;top:658.85px" class="cls_017"><span class="cls_017">3.8.2</span></div>
<div style="position:absolute;left:165.90px;top:658.85px" class="cls_017"><span class="cls_017">Pandas</span></div>
<div style="position:absolute;left:124.80px;top:679.24px" class="cls_008"><span class="cls_008">Pandas is a popular open source Python package for data science. It provides</span></div>
<div style="position:absolute;left:124.80px;top:691.19px" class="cls_008"><span class="cls_008">multiple powerful, easy-to-use tools and structures for data analysis and manip-</span></div>
<div style="position:absolute;left:124.80px;top:703.15px" class="cls_008"><span class="cls_008">ulation. From Pandas we have mainly used the DataFrame, the most commonly</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">26</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:24679px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background030.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">used pandas object, in our project.</span></div>
<div style="position:absolute;left:139.75px;top:136.86px" class="cls_008"><span class="cls_008">The Pandas documentation defines the DataFrame as "a 2-dimensional la-</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">beled data structure with columns of potentially different types." [1] This means</span></div>
<div style="position:absolute;left:124.80px;top:160.77px" class="cls_008"><span class="cls_008">that it stores data in rectangular grids in a similar style to spreadsheets or SQL</span></div>
<div style="position:absolute;left:124.80px;top:172.73px" class="cls_008"><span class="cls_008">tables. Each row of these grids holds the different values of an instance, while</span></div>
<div style="position:absolute;left:124.80px;top:184.68px" class="cls_008"><span class="cls_008">each column is a vector containing data for a specific variable. The rows of the</span></div>
<div style="position:absolute;left:124.80px;top:196.64px" class="cls_008"><span class="cls_008">DataFrame can contain different types of values; such as numerical, characters,</span></div>
<div style="position:absolute;left:124.80px;top:208.59px" class="cls_008"><span class="cls_008">objects, etc.</span></div>
<div style="position:absolute;left:124.80px;top:234.49px" class="cls_017"><span class="cls_017">3.8.3</span></div>
<div style="position:absolute;left:165.90px;top:234.49px" class="cls_017"><span class="cls_017">Scikit-learn</span></div>
<div style="position:absolute;left:124.80px;top:254.87px" class="cls_008"><span class="cls_008">Scikit-learn is an open source machine-learning library for Python. It incorpo-</span></div>
<div style="position:absolute;left:124.80px;top:266.83px" class="cls_008"><span class="cls_008">rates a wide range of different ML-algorithms, within regression, classification</span></div>
<div style="position:absolute;left:124.80px;top:278.78px" class="cls_008"><span class="cls_008">and clustering. With its well documented and easy to use interface, it enables</span></div>
<div style="position:absolute;left:124.80px;top:290.74px" class="cls_008"><span class="cls_008">beginners to easily start experimenting with machine learning. In our case, we</span></div>
<div style="position:absolute;left:124.80px;top:302.69px" class="cls_008"><span class="cls_008">implemented several algorithms such as PCA, DBSCAN, LOF, K-means among</span></div>
<div style="position:absolute;left:124.80px;top:314.65px" class="cls_008"><span class="cls_008">and other utility functions such as OneHotEncoding for categorical data.</span></div>
<div style="position:absolute;left:124.80px;top:340.54px" class="cls_017"><span class="cls_017">3.8.4</span></div>
<div style="position:absolute;left:165.90px;top:340.54px" class="cls_017"><span class="cls_017">Matplotlib</span></div>
<div style="position:absolute;left:124.80px;top:360.93px" class="cls_008"><span class="cls_008">For visualization purposes we implemented a well-known and widely used vi-</span></div>
<div style="position:absolute;left:124.80px;top:372.88px" class="cls_008"><span class="cls_008">sualization package, matplotlib. The library provides a wide range of different</span></div>
<div style="position:absolute;left:124.80px;top:384.84px" class="cls_008"><span class="cls_008">tools for both 2D- and 3D-graphs and plots.  In addition to using matplotlib</span></div>
<div style="position:absolute;left:124.80px;top:396.79px" class="cls_008"><span class="cls_008">for visualization, we also used Pandas which also incorporates some easy-to-use</span></div>
<div style="position:absolute;left:124.80px;top:408.75px" class="cls_008"><span class="cls_008">tools for histograms, scatter-plots and box-plots.</span></div>
<div style="position:absolute;left:124.80px;top:434.64px" class="cls_017"><span class="cls_017">3.8.5</span></div>
<div style="position:absolute;left:165.90px;top:434.64px" class="cls_017"><span class="cls_017">Numpy</span></div>
<div style="position:absolute;left:124.80px;top:455.02px" class="cls_008"><span class="cls_008">Numpy is another well-known Python package used for numerical computa-</span></div>
<div style="position:absolute;left:124.80px;top:466.98px" class="cls_008"><span class="cls_008">tions.  It supports a variety of mathematical functions along with array and</span></div>
<div style="position:absolute;left:124.80px;top:478.93px" class="cls_008"><span class="cls_008">matrix operations. A large number of other packages uses Numpy for efficient</span></div>
<div style="position:absolute;left:124.80px;top:490.89px" class="cls_008"><span class="cls_008">mathematical computations.</span></div>
<div style="position:absolute;left:124.80px;top:516.78px" class="cls_017"><span class="cls_017">3.8.6</span></div>
<div style="position:absolute;left:165.90px;top:516.78px" class="cls_017"><span class="cls_017">Server</span></div>
<div style="position:absolute;left:124.80px;top:537.17px" class="cls_008"><span class="cls_008">The virtual machine we got from the NTA is a Compute Engine instance on the</span></div>
<div style="position:absolute;left:124.80px;top:549.12px" class="cls_008"><span class="cls_008">Google Cloud Platform. It is based on the Intel Sandy Bridge CPU platform,</span></div>
<div style="position:absolute;left:124.80px;top:561.08px" class="cls_008"><span class="cls_008">with 6 vCPUs and 32GB of memory, and a 2TB persistent disk for storage.</span></div>
<div style="position:absolute;left:124.80px;top:573.03px" class="cls_008"><span class="cls_008">The operating system is Ubuntu 18.04.1 LTS (Bionic Beaver).  When working</span></div>
<div style="position:absolute;left:124.80px;top:584.99px" class="cls_008"><span class="cls_008">with data provided by the NTA there were many security measures to consider.</span></div>
<div style="position:absolute;left:124.80px;top:596.94px" class="cls_008"><span class="cls_008">Although the data has been anonymized two times, we could not store anything</span></div>
<div style="position:absolute;left:124.80px;top:608.90px" class="cls_008"><span class="cls_008">locally.  More about steps we took in relation to security will be discussed in</span></div>
<div style="position:absolute;left:124.80px;top:620.85px" class="cls_008"><span class="cls_008">3.8.7.</span></div>
<div style="position:absolute;left:124.80px;top:646.75px" class="cls_017"><span class="cls_017">3.8.7</span></div>
<div style="position:absolute;left:165.90px;top:646.75px" class="cls_017"><span class="cls_017">SSH</span></div>
<div style="position:absolute;left:124.80px;top:667.13px" class="cls_008"><span class="cls_008">Our guidelines mandated that we were not allowed to work with the given</span></div>
<div style="position:absolute;left:124.80px;top:679.09px" class="cls_008"><span class="cls_008">data locally, the data could not leave the virtual machine set up by the NTA.</span></div>
<div style="position:absolute;left:124.80px;top:691.04px" class="cls_008"><span class="cls_008">This necessitated the use of a secure connection, which we solved with the SSH</span></div>
<div style="position:absolute;left:124.80px;top:703.00px" class="cls_008"><span class="cls_008">protocol. SSH uses public key cryptography to create a private/public key pair,</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">27</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:25530px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background031.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">authenticating the host with the server, and enabling us to work securely and</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">easily on the VM without requiring a password.  We set up SSH tunnels from</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">our browser to Jupyter 3.8.8 on the VM to further secure our work environment,</span></div>
<div style="position:absolute;left:124.80px;top:160.77px" class="cls_008"><span class="cls_008">connecting a given port on the VM to a corresponding port on the localhost.</span></div>
<div style="position:absolute;left:124.80px;top:186.67px" class="cls_017"><span class="cls_017">3.8.8</span></div>
<div style="position:absolute;left:165.90px;top:186.67px" class="cls_017"><span class="cls_017">Jupyter Notebook</span></div>
<div style="position:absolute;left:124.80px;top:207.05px" class="cls_008"><span class="cls_008">Jupyter Notebook is a web application which extends the console to a more</span></div>
<div style="position:absolute;left:124.80px;top:219.01px" class="cls_008"><span class="cls_008">interactive and graphically enhanced environment.  In Jupyter Notebook you</span></div>
<div style="position:absolute;left:124.80px;top:230.96px" class="cls_008"><span class="cls_008">can write, document and execute your code, display output in rich formats,</span></div>
<div style="position:absolute;left:124.80px;top:242.92px" class="cls_008"><span class="cls_008">and save and share your results with markup functionality and L</span><span class="cls_018">A</span><span class="cls_008">TEX support.</span></div>
<div style="position:absolute;left:124.80px;top:254.87px" class="cls_008"><span class="cls_008">Notebooks are saved as JSON (JavaScript Object Notation) files, and they run</span></div>
<div style="position:absolute;left:124.80px;top:266.83px" class="cls_008"><span class="cls_008">on a kernel in a prespecified language, in our case Python 3.  The kernel is</span></div>
<div style="position:absolute;left:124.80px;top:278.78px" class="cls_008"><span class="cls_008">responsible for executing the code in the notebook cells.  Figure 3.14 is an</span></div>
<div style="position:absolute;left:124.80px;top:290.74px" class="cls_008"><span class="cls_008">example of the layout:</span></div>
<div style="position:absolute;left:200.79px;top:582.17px" class="cls_008"><span class="cls_008">Figure 3.14: The basic layout of a notebook</span></div>
<div style="position:absolute;left:139.75px;top:619.63px" class="cls_008"><span class="cls_008">We used Jupyter Notebook extensively for all our programming needs; cre-</span></div>
<div style="position:absolute;left:124.80px;top:631.58px" class="cls_008"><span class="cls_008">ating and running the scripts for decoding and extracting, running the ML</span></div>
<div style="position:absolute;left:124.80px;top:643.54px" class="cls_008"><span class="cls_008">algorithms and displaying the results.  Jupyter Notebook gave us a powerful</span></div>
<div style="position:absolute;left:124.80px;top:655.49px" class="cls_008"><span class="cls_008">graphical environment that enabled us to work with the data directly on the</span></div>
<div style="position:absolute;left:124.80px;top:667.45px" class="cls_008"><span class="cls_008">server. This way we could see each others work and easily share knowledge and</span></div>
<div style="position:absolute;left:124.80px;top:679.40px" class="cls_008"><span class="cls_008">code between group members in real time.</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:26381px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background032.jpg" width=595 height=841></div>
<div style="position:absolute;left:261.72px;top:244.46px" class="cls_007"><span class="cls_007">Related Work</span></div>
<div style="position:absolute;left:139.75px;top:266.38px" class="cls_008"><span class="cls_008">There are lots of reviews discussing how to approach anomaly detection</span></div>
<div style="position:absolute;left:124.80px;top:278.33px" class="cls_008"><span class="cls_008">problems. Schubert et al. recently provided a review of the DBSCAN algorithm</span></div>
<div style="position:absolute;left:124.80px;top:290.29px" class="cls_008"><span class="cls_008">and its persistent relevancy to clustering and unsupervised learning [19].</span></div>
<div style="position:absolute;left:139.75px;top:314.20px" class="cls_008"><span class="cls_008">Generative Adversarial Networks (GANs) can model complex high-dimensional</span></div>
<div style="position:absolute;left:124.80px;top:326.15px" class="cls_008"><span class="cls_008">real-world data. Liu et al. proposes a Single-Objective Generative Adversarial</span></div>
<div style="position:absolute;left:124.80px;top:338.11px" class="cls_008"><span class="cls_008">Active Learning (SO-GAAL) method for outlier detection, which can gener-</span></div>
<div style="position:absolute;left:124.80px;top:350.06px" class="cls_008"><span class="cls_008">ate potential anomalies based on a mini-max game between a generator and a</span></div>
<div style="position:absolute;left:124.80px;top:362.02px" class="cls_008"><span class="cls_008">discriminator [10].</span></div>
<div style="position:absolute;left:139.75px;top:385.93px" class="cls_008"><span class="cls_008">In Fast Memory Efficient Local Outlier Detection in Data Streams [17],</span></div>
<div style="position:absolute;left:124.80px;top:397.89px" class="cls_008"><span class="cls_008">Salehi et al.  proposes a memory efficient incremental local outlier detection</span></div>
<div style="position:absolute;left:124.80px;top:409.84px" class="cls_008"><span class="cls_008">algorithm (MiLOF) that yields better memory and time complexity then LOF,</span></div>
<div style="position:absolute;left:124.80px;top:421.80px" class="cls_008"><span class="cls_008">while maintaing a comparable accuracy.</span></div>
<div style="position:absolute;left:139.75px;top:445.71px" class="cls_008"><span class="cls_008">In the article Towards Rare Itemset Mining [24], Szathmary et al. propose</span></div>
<div style="position:absolute;left:124.80px;top:457.66px" class="cls_008"><span class="cls_008">different optimized algorithms for mining rare itemsets.</span></div>
<div style="position:absolute;left:139.75px;top:481.57px" class="cls_008"><span class="cls_008">Scalable Kernel K-Means Clustering with Nyström Approximation: Relative-</span></div>
<div style="position:absolute;left:124.80px;top:493.53px" class="cls_008"><span class="cls_008">Error explores the K-means algorithm using kernel approximation (Nyström</span></div>
<div style="position:absolute;left:124.80px;top:505.48px" class="cls_008"><span class="cls_008">approximation) as the distance metric, and not Euclidean distance. The algo-</span></div>
<div style="position:absolute;left:124.80px;top:517.44px" class="cls_008"><span class="cls_008">rithm proposed is able to identify non-linear structures with reduced complexity</span></div>
<div style="position:absolute;left:124.80px;top:529.39px" class="cls_008"><span class="cls_008">compared to previous attempts.</span></div>
<div style="position:absolute;left:139.75px;top:553.30px" class="cls_008"><span class="cls_008">Applying multiple algorithms to a dataset might be yield a greater precision</span></div>
<div style="position:absolute;left:124.80px;top:565.26px" class="cls_008"><span class="cls_008">for predicting potential anomalies in a dataset.  Dimble et al.  propose, in the</span></div>
<div style="position:absolute;left:124.80px;top:577.21px" class="cls_008"><span class="cls_008">study called "A Framework for Outlier Detection in Geographical Spatial Data"</span></div>
<div style="position:absolute;left:124.80px;top:589.17px" class="cls_008"><span class="cls_008">[13], a method using DBSCAN to remove noise from a geographical spacial</span></div>
<div style="position:absolute;left:124.80px;top:601.12px" class="cls_008"><span class="cls_008">dataset and apply LOF to obtain possible anomalies in the resulting data.</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:27232px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background033.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:188.93px" class="cls_011"><span class="cls_011">Chapter 4</span></div>
<div style="position:absolute;left:124.80px;top:234.62px" class="cls_009"><span class="cls_009">Data Analysis</span></div>
<div style="position:absolute;left:124.80px;top:301.25px" class="cls_008"><span class="cls_008">This chapter contains the steps we went through when preprocessing the data</span></div>
<div style="position:absolute;left:124.80px;top:313.20px" class="cls_008"><span class="cls_008">we got from the NTA. We spent a lot of time getting to know the data and</span></div>
<div style="position:absolute;left:124.80px;top:325.16px" class="cls_008"><span class="cls_008">transforming it to formats we needed.  We will also present measures of cen-</span></div>
<div style="position:absolute;left:124.80px;top:337.11px" class="cls_008"><span class="cls_008">tral tendency of the features we used, and lastly, some visualizations of the</span></div>
<div style="position:absolute;left:124.80px;top:349.07px" class="cls_008"><span class="cls_008">distribution and correlation between the features.</span></div>
<div style="position:absolute;left:124.80px;top:377.63px" class="cls_010"><span class="cls_010">4.1</span></div>
<div style="position:absolute;left:161.56px;top:377.63px" class="cls_010"><span class="cls_010">Data Structure</span></div>
<div style="position:absolute;left:124.80px;top:403.83px" class="cls_008"><span class="cls_008">We received 240 GB of unprocessed and encoded data from the NTA at the end</span></div>
<div style="position:absolute;left:124.80px;top:415.79px" class="cls_008"><span class="cls_008">of January 2019. This amounts to roughly 1% of one years worth of data that</span></div>
<div style="position:absolute;left:124.80px;top:427.74px" class="cls_008"><span class="cls_008">the NTA receives through the A-Ordning system. The data extracted dates back</span></div>
<div style="position:absolute;left:124.80px;top:439.70px" class="cls_008"><span class="cls_008">to 2016 and up until 2018. It has been chosen randomly, but the distribution is</span></div>
<div style="position:absolute;left:124.80px;top:451.66px" class="cls_008"><span class="cls_008">evenly split among the three years period. The data had then been randomized</span></div>
<div style="position:absolute;left:124.80px;top:463.61px" class="cls_008"><span class="cls_008">once for internal usage, and then another randomization was done to allow us</span></div>
<div style="position:absolute;left:124.80px;top:475.57px" class="cls_008"><span class="cls_008">to use it externally. All information that could be used to identify people were</span></div>
<div style="position:absolute;left:124.80px;top:487.52px" class="cls_008"><span class="cls_008">encrypted. The only information we thought would be interesting to know was</span></div>
<div style="position:absolute;left:124.80px;top:499.48px" class="cls_008"><span class="cls_008">the occupation of each person. This information could have been used to further</span></div>
<div style="position:absolute;left:124.80px;top:511.43px" class="cls_008"><span class="cls_008">explain outliers we discovered.</span></div>
<div style="position:absolute;left:139.75px;top:523.39px" class="cls_008"><span class="cls_008">The structure of the data was XML files, and the information we needed was</span></div>
<div style="position:absolute;left:124.80px;top:535.34px" class="cls_008"><span class="cls_008">stored inside tags. We used a Python library called ElementTree, which parses</span></div>
<div style="position:absolute;left:124.80px;top:547.30px" class="cls_008"><span class="cls_008">the XML file to an iterable tree structure where each end tag is an object. This</span></div>
<div style="position:absolute;left:124.80px;top:559.25px" class="cls_008"><span class="cls_008">enabled us to easily search for the tags we need and extract their values. With</span></div>
<div style="position:absolute;left:124.80px;top:571.21px" class="cls_008"><span class="cls_008">the XML files being as complex and unwieldy as they are, and the number of</span></div>
<div style="position:absolute;left:124.80px;top:583.16px" class="cls_008"><span class="cls_008">differently organized tags, the ElementTree library allowed us to narrow in our</span></div>
<div style="position:absolute;left:124.80px;top:595.12px" class="cls_008"><span class="cls_008">search as we went, and loop through subtrees instead of moving through the</span></div>
<div style="position:absolute;left:124.80px;top:607.07px" class="cls_008"><span class="cls_008">entire file every time.</span></div>
<div style="position:absolute;left:139.75px;top:619.03px" class="cls_008"><span class="cls_008">Figure 4.2 illustrates the tree structure of the XML documents we were</span></div>
<div style="position:absolute;left:124.80px;top:630.98px" class="cls_008"><span class="cls_008">provided with. The boxes marked in red are the message-id and replacement-id</span></div>
<div style="position:absolute;left:124.80px;top:642.94px" class="cls_008"><span class="cls_008">which will be discussed in section 4.3. The green ones are the most noticeable</span></div>
<div style="position:absolute;left:124.80px;top:654.89px" class="cls_008"><span class="cls_008">tags and the ones that contained the information we extracted.</span></div>
<div style="position:absolute;left:139.75px;top:666.85px" class="cls_008"><span class="cls_008">After building our selected fields, we parsed the results to a CSV file. CSV</span></div>
<div style="position:absolute;left:124.80px;top:678.80px" class="cls_008"><span class="cls_008">stands for comma separated values and are easy to use together with libraries</span></div>
<div style="position:absolute;left:124.80px;top:690.76px" class="cls_008"><span class="cls_008">such as Numpy and Pandas. The final CSV file had 7.967.200 lines and was 2.38</span></div>
<div style="position:absolute;left:124.80px;top:702.71px" class="cls_008"><span class="cls_008">GB, where each line represents information about one employee for one month.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">30</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:28083px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background034.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">Unfortunately, this was still too large as we got memory-errors when running</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">LOF and DBSCAN. These two algorithms are computationally very expensive</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">and require a lot of memory. In order to counteract this we took a sample of the</span></div>
<div style="position:absolute;left:124.80px;top:160.77px" class="cls_008"><span class="cls_008">first 100.000 data points from the CSV file and used them for our experiments.</span></div>
<div style="position:absolute;left:139.75px;top:184.68px" class="cls_008"><span class="cls_008">The following sections describe the preprocessing we did to make the data</span></div>
<div style="position:absolute;left:124.80px;top:196.64px" class="cls_008"><span class="cls_008">usable for the algorithms in our experiments. Figure 4.1 gives a birds eye view</span></div>
<div style="position:absolute;left:124.80px;top:208.59px" class="cls_008"><span class="cls_008">of the process.</span></div>
<div style="position:absolute;left:174.31px;top:610.21px" class="cls_008"><span class="cls_008">Figure 4.1: A step-by-step data Preprocessing Overview</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">31</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:28934px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background035.jpg" width=595 height=841></div>
<div style="position:absolute;left:191.41px;top:618.78px" class="cls_008"><span class="cls_008">Figure 4.2: Metaview of the XML tree structure</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">32</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:29785px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background036.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:290.09px" class="cls_010"><span class="cls_010">4.2</span></div>
<div style="position:absolute;left:161.56px;top:290.09px" class="cls_010"><span class="cls_010">Structural errors</span></div>
<div style="position:absolute;left:124.80px;top:316.30px" class="cls_008"><span class="cls_008">There were many XML files that were from a previous system, and in order</span></div>
<div style="position:absolute;left:124.80px;top:328.25px" class="cls_008"><span class="cls_008">to catch these instances we had to create some additional if-statements. These</span></div>
<div style="position:absolute;left:124.80px;top:340.21px" class="cls_008"><span class="cls_008">issues caused a lot of headache in the beginning as we were not aware that there</span></div>
<div style="position:absolute;left:124.80px;top:352.16px" class="cls_008"><span class="cls_008">were as much as four different formats on the XML documents. Luckily about</span></div>
<div style="position:absolute;left:124.80px;top:364.12px" class="cls_008"><span class="cls_008">99 percent of the data were on the new standard format. However, most of the</span></div>
<div style="position:absolute;left:124.80px;top:376.07px" class="cls_008"><span class="cls_008">input fields in the A-melding are not mandatory, and a lot of them have few to</span></div>
<div style="position:absolute;left:124.80px;top:388.03px" class="cls_008"><span class="cls_008">no restrictions on their content, so making sure everything is correct proved to</span></div>
<div style="position:absolute;left:124.80px;top:399.98px" class="cls_008"><span class="cls_008">be a difficult task. We have tried our best to extract the correct values, but as</span></div>
<div style="position:absolute;left:124.80px;top:411.94px" class="cls_008"><span class="cls_008">it is very hard to account for every fringe case, some of the anomalies we find</span></div>
<div style="position:absolute;left:124.80px;top:423.89px" class="cls_008"><span class="cls_008">will possibly be due to unforeseeable oversights on our behalf.</span></div>
<div style="position:absolute;left:124.80px;top:452.45px" class="cls_010"><span class="cls_010">4.3</span></div>
<div style="position:absolute;left:161.56px;top:452.45px" class="cls_010"><span class="cls_010">Correcting Errors in the A-melding</span></div>
<div style="position:absolute;left:124.80px;top:478.66px" class="cls_008"><span class="cls_008">The A-melding often contains errors because they are reported manually and</span></div>
<div style="position:absolute;left:124.80px;top:490.61px" class="cls_008"><span class="cls_008">humans make mistakes.  Skatteetaten deals with these errors in two different</span></div>
<div style="position:absolute;left:124.80px;top:502.57px" class="cls_008"><span class="cls_008">ways, namely through replacement-Id and correction-message.</span></div>
<div style="position:absolute;left:166.70px;top:696.18px" class="cls_008"><span class="cls_008">Figure 4.3: Screenshot taken from the NTA’s webpage. [21]</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">33</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:30636px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background037.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:122.92px" class="cls_017"><span class="cls_017">4.3.1</span></div>
<div style="position:absolute;left:165.90px;top:122.92px" class="cls_017"><span class="cls_017">Replacement ID</span></div>
<div style="position:absolute;left:124.80px;top:143.30px" class="cls_008"><span class="cls_008">The A-Ordning system is set up so that if an employer submits an erroneously</span></div>
<div style="position:absolute;left:124.80px;top:155.25px" class="cls_008"><span class="cls_008">A-melding, he or she can send a new A-melding containing a replacement-Id</span></div>
<div style="position:absolute;left:124.80px;top:167.21px" class="cls_008"><span class="cls_008">tag.  This meant that a lot of the files we received were no longer valid and</span></div>
<div style="position:absolute;left:124.80px;top:179.16px" class="cls_008"><span class="cls_008">needed to be removed in order to prevent clutter and invalid data points. Inside</span></div>
<div style="position:absolute;left:124.80px;top:191.12px" class="cls_008"><span class="cls_008">these replacement-Id tag there will be an identification number which refers to a</span></div>
<div style="position:absolute;left:124.80px;top:203.07px" class="cls_008"><span class="cls_008">previously sent A-melding. In figure 4.4 the XML-file contains the replacement-</span></div>
<div style="position:absolute;left:124.80px;top:215.03px" class="cls_008"><span class="cls_008">Id tag with the value ’ER3166914’, meaning that it is replacing a previously</span></div>
<div style="position:absolute;left:124.80px;top:226.98px" class="cls_008"><span class="cls_008">sent A-melding which had a message-Id tag with the value ’ER3166914’.  In</span></div>
<div style="position:absolute;left:124.80px;top:238.94px" class="cls_008"><span class="cls_008">order to maintain the integrity of the files, we had to be careful with the order</span></div>
<div style="position:absolute;left:124.80px;top:250.89px" class="cls_008"><span class="cls_008">of operations in the script that handled the replacement-ids.</span></div>
<div style="position:absolute;left:160.71px;top:357.78px" class="cls_008"><span class="cls_008">Figure 4.4: Screenshot of an XML-file with a replacement-tag.</span></div>
<div style="position:absolute;left:139.75px;top:394.83px" class="cls_008"><span class="cls_008">After running the script that dealt with the replacement tags, the amount</span></div>
<div style="position:absolute;left:124.80px;top:406.78px" class="cls_008"><span class="cls_008">of data was reduced significantly.  From 240 GB to approximately 170 GB,</span></div>
<div style="position:absolute;left:124.80px;top:418.74px" class="cls_008"><span class="cls_008">meaning that the size of the dataset dropped to about 70 percent of its original</span></div>
<div style="position:absolute;left:124.80px;top:430.69px" class="cls_008"><span class="cls_008">size. One business can send everything from one to twenty different A-meldings</span></div>
<div style="position:absolute;left:124.80px;top:442.65px" class="cls_008"><span class="cls_008">which all represent the same month and should overwrite the previous one. To</span></div>
<div style="position:absolute;left:124.80px;top:454.61px" class="cls_008"><span class="cls_008">get the correct A-melding we had to follow the replacement-Id chain all the way</span></div>
<div style="position:absolute;left:124.80px;top:466.56px" class="cls_008"><span class="cls_008">to the root.</span></div>
<div style="position:absolute;left:124.80px;top:492.28px" class="cls_017"><span class="cls_017">4.3.2</span></div>
<div style="position:absolute;left:165.90px;top:492.28px" class="cls_017"><span class="cls_017">Correction Messages</span></div>
<div style="position:absolute;left:124.80px;top:512.66px" class="cls_008"><span class="cls_008">Correction messages are not labeled and does not have a replacement-Id. Instead</span></div>
<div style="position:absolute;left:124.80px;top:524.62px" class="cls_008"><span class="cls_008">of replacing an existing A-melding, the correction messages overwrites some</span></div>
<div style="position:absolute;left:124.80px;top:536.57px" class="cls_008"><span class="cls_008">parts of a previously sent A-melding.  In order to identify which A-melding it</span></div>
<div style="position:absolute;left:124.80px;top:548.53px" class="cls_008"><span class="cls_008">should overwrite, one has to look at the tags for employment start and end dates.</span></div>
<div style="position:absolute;left:124.80px;top:560.48px" class="cls_008"><span class="cls_008">If these are the same date and the FTE percentage is set to 0 we are dealing with</span></div>
<div style="position:absolute;left:124.80px;top:572.44px" class="cls_008"><span class="cls_008">a correction message. We noticed quite early that this ’rule’ was not necessarily</span></div>
<div style="position:absolute;left:124.80px;top:584.39px" class="cls_008"><span class="cls_008">strictly followed by the people that submitted A-meldings. After consolidating</span></div>
<div style="position:absolute;left:124.80px;top:596.35px" class="cls_008"><span class="cls_008">with the domain experts at the NTA, we concluded that the amount of correction</span></div>
<div style="position:absolute;left:124.80px;top:608.30px" class="cls_008"><span class="cls_008">messages was probably not high enough to make a large impact on the dataset,</span></div>
<div style="position:absolute;left:124.80px;top:620.26px" class="cls_008"><span class="cls_008">and thus we ignored all the potential correction messages.</span></div>
<div style="position:absolute;left:124.80px;top:648.64px" class="cls_010"><span class="cls_010">4.4</span></div>
<div style="position:absolute;left:161.56px;top:648.64px" class="cls_010"><span class="cls_010">Decoding</span></div>
<div style="position:absolute;left:124.80px;top:674.85px" class="cls_008"><span class="cls_008">The files we were given from the NTA were partially encoded in base64.  The</span></div>
<div style="position:absolute;left:124.80px;top:686.80px" class="cls_008"><span class="cls_008">XML files had metadata in a header tag, and the actual A-melding was encoded</span></div>
<div style="position:absolute;left:124.80px;top:698.76px" class="cls_008"><span class="cls_008">within an &lt;Attachment> tag.  The decoded string was a separate XML file</span></div>
<div style="position:absolute;left:124.80px;top:710.71px" class="cls_008"><span class="cls_008">within the XML file, so we also had to remove the opening &lt;?xml version="1.0"</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">34</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:31487px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background038.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">encoding="UTF-8"?> tag in the attachment to be able to read the files.  The</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">decoded files did not have the correct escape characters for the tags, so we made</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">a function to go through every file and replace every instance of &lt; and &gt;</span></div>
<div style="position:absolute;left:124.80px;top:160.77px" class="cls_008"><span class="cls_008">with &lt; and >.</span></div>
<div style="position:absolute;left:180.07px;top:450.60px" class="cls_008"><span class="cls_008">Figure 4.5: Screenshot of a base64 encoded XML-file.</span></div>
<div style="position:absolute;left:124.80px;top:492.71px" class="cls_010"><span class="cls_010">4.5</span></div>
<div style="position:absolute;left:161.56px;top:492.71px" class="cls_010"><span class="cls_010">Feature Extraction</span></div>
<div style="position:absolute;left:124.80px;top:518.91px" class="cls_008"><span class="cls_008">In Machine Learning, the concept of feature extraction consists of selecting sub-</span></div>
<div style="position:absolute;left:124.80px;top:530.87px" class="cls_008"><span class="cls_008">sets of data to use in algorithms. The domain experts at the NTA suggested that</span></div>
<div style="position:absolute;left:124.80px;top:542.82px" class="cls_008"><span class="cls_008">we start with the features:  Total income, FTE percentage and hours worked.</span></div>
<div style="position:absolute;left:124.80px;top:554.78px" class="cls_008"><span class="cls_008">The nature of these features are quite obvious as one would assume that the</span></div>
<div style="position:absolute;left:124.80px;top:566.73px" class="cls_008"><span class="cls_008">higher percentage of employment an employee has, the higher the salary. Using</span></div>
<div style="position:absolute;left:124.80px;top:578.69px" class="cls_008"><span class="cls_008">the results we got was a good indication that these methods could be used on</span></div>
<div style="position:absolute;left:124.80px;top:590.64px" class="cls_008"><span class="cls_008">further and more obscure features that did not have blatantly obvious relation-</span></div>
<div style="position:absolute;left:124.80px;top:602.60px" class="cls_008"><span class="cls_008">ships. It also gave us some other interesting insight into what anomalies could</span></div>
<div style="position:absolute;left:124.80px;top:614.56px" class="cls_008"><span class="cls_008">look like.</span></div>
<div style="position:absolute;left:124.80px;top:643.12px" class="cls_010"><span class="cls_010">4.6</span></div>
<div style="position:absolute;left:161.56px;top:643.12px" class="cls_010"><span class="cls_010">Missing values</span></div>
<div style="position:absolute;left:124.80px;top:669.32px" class="cls_008"><span class="cls_008">Because of null values in the XML documents, our feature extraction script</span></div>
<div style="position:absolute;left:124.80px;top:681.28px" class="cls_008"><span class="cls_008">needed a lot of field validation checks.  Due to the design of ElementTree we</span></div>
<div style="position:absolute;left:124.80px;top:693.23px" class="cls_008"><span class="cls_008">could not enter null values during extraction to CSV. In these cases we had to</span></div>
<div style="position:absolute;left:124.80px;top:705.19px" class="cls_008"><span class="cls_008">decide what value we should replace the null value with.  We ended up with</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">35</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:32338px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background039.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">inserting 0.0 into the numerical nodes and then used Pandas to handle them</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">later on. If we found a categorical feature with a null value it meant that the</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">XML-tag existed, but the child-tag with the information about the feature type</span></div>
<div style="position:absolute;left:124.80px;top:160.77px" class="cls_008"><span class="cls_008">was not present.  In these cases we dropped the whole tag as there was no</span></div>
<div style="position:absolute;left:124.80px;top:172.73px" class="cls_008"><span class="cls_008">necessary information.  Many values also had "TODO" which seemingly was</span></div>
<div style="position:absolute;left:124.80px;top:184.68px" class="cls_008"><span class="cls_008">something the employers/accountants had inserted as a temporary value, but</span></div>
<div style="position:absolute;left:124.80px;top:196.64px" class="cls_008"><span class="cls_008">had then forgotten to actually fill in. We decided to drop these as well.</span></div>
<div style="position:absolute;left:139.75px;top:208.59px" class="cls_008"><span class="cls_008">In figure 4.6 below we see the sub-features of ’Inntekt’ and their correspond-</span></div>
<div style="position:absolute;left:124.80px;top:220.55px" class="cls_008"><span class="cls_008">ing ratio of null values. The information is taken from the 100.000 data points</span></div>
<div style="position:absolute;left:124.80px;top:232.51px" class="cls_008"><span class="cls_008">we used in the algorithms and does not represent the whole dataset.  Even</span></div>
<div style="position:absolute;left:124.80px;top:244.46px" class="cls_008"><span class="cls_008">though it is not the complete dataset it gives an inclination of how the data</span></div>
<div style="position:absolute;left:124.80px;top:256.42px" class="cls_008"><span class="cls_008">is partitioned.  Many of the features, like ’Smusstillegg’ and ’Bonus’ are very</span></div>
<div style="position:absolute;left:124.80px;top:268.37px" class="cls_008"><span class="cls_008">rare but informative as they have a great impact on the salary of an employee.</span></div>
<div style="position:absolute;left:124.80px;top:280.33px" class="cls_008"><span class="cls_008">Therefore we decided to create a new column called ’Totalinntekt’. This is the</span></div>
<div style="position:absolute;left:124.80px;top:292.28px" class="cls_008"><span class="cls_008">total income for each person containing the sum of all XML-tags named ’In-</span></div>
<div style="position:absolute;left:124.80px;top:304.24px" class="cls_008"><span class="cls_008">ntekt’.  This is good indicator of how much a person actually earns and the</span></div>
<div style="position:absolute;left:124.80px;top:316.19px" class="cls_008"><span class="cls_008">feature we used for income.</span></div>
<div style="position:absolute;left:124.80px;top:510.64px" class="cls_008"><span class="cls_008">Figure 4.6:  List of the different sub-features of income and their ratio of null</span></div>
<div style="position:absolute;left:124.80px;top:522.60px" class="cls_008"><span class="cls_008">values.</span></div>
<div style="position:absolute;left:124.80px;top:564.71px" class="cls_010"><span class="cls_010">4.7</span></div>
<div style="position:absolute;left:161.56px;top:564.71px" class="cls_010"><span class="cls_010">Normalization</span></div>
<div style="position:absolute;left:124.80px;top:590.91px" class="cls_008"><span class="cls_008">Normalization is a technique that prepares the data before passing it through</span></div>
<div style="position:absolute;left:124.80px;top:602.87px" class="cls_008"><span class="cls_008">a machine learning model or algorithm. Normalization is applied to numerical</span></div>
<div style="position:absolute;left:124.80px;top:614.82px" class="cls_008"><span class="cls_008">data to make the different features impact equally, but without changing the</span></div>
<div style="position:absolute;left:124.80px;top:626.78px" class="cls_008"><span class="cls_008">differences in the ranges of values each feature may have. For example, in our</span></div>
<div style="position:absolute;left:124.80px;top:638.73px" class="cls_008"><span class="cls_008">data set we have features that represent a persons income per month and number</span></div>
<div style="position:absolute;left:124.80px;top:650.69px" class="cls_008"><span class="cls_008">of hours worked per month. The incomes ranges from negative values to several</span></div>
<div style="position:absolute;left:124.80px;top:662.65px" class="cls_008"><span class="cls_008">millions, while the number of hours worked rarely exceeds 165-170. The range</span></div>
<div style="position:absolute;left:124.80px;top:674.60px" class="cls_008"><span class="cls_008">difference of the these two features are huge, and the income will naturally have</span></div>
<div style="position:absolute;left:124.80px;top:686.56px" class="cls_008"><span class="cls_008">a greater impact as a predictor. To counteract this behaviour, normalization is</span></div>
<div style="position:absolute;left:124.80px;top:698.51px" class="cls_008"><span class="cls_008">used. Through normalization all the numerical features are weighted equally.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">36</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:33189px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background040.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:120.52px" class="cls_010"><span class="cls_010">4.8</span></div>
<div style="position:absolute;left:161.56px;top:120.52px" class="cls_010"><span class="cls_010">Visualizing the distribution of the dataset</span></div>
<div style="position:absolute;left:124.80px;top:146.73px" class="cls_008"><span class="cls_008">On figure 4.7 below we see a heat-map of all the features we investigated during</span></div>
<div style="position:absolute;left:124.80px;top:158.68px" class="cls_008"><span class="cls_008">this project. Most of the features in the first heatmap is part of the new feature</span></div>
<div style="position:absolute;left:124.80px;top:170.64px" class="cls_008"><span class="cls_008">we call Total income. The heat-map show the correlation between the features.</span></div>
<div style="position:absolute;left:124.80px;top:182.59px" class="cls_008"><span class="cls_008">The further away from zero, the bigger the correlation. A correlation coefficient</span></div>
<div style="position:absolute;left:124.80px;top:194.55px" class="cls_008"><span class="cls_008">of 1 or -1 (100% or -100%) means that the relationship is linear.  To find the</span></div>
<div style="position:absolute;left:124.80px;top:206.51px" class="cls_008"><span class="cls_008">correlation coefficient ρ between two columns in a dataset one has to first find</span></div>
<div style="position:absolute;left:124.80px;top:218.46px" class="cls_008"><span class="cls_008">the mean </span><span class="cls_028">x</span><span class="cls_008"> and </span><span class="cls_028">y</span><span class="cls_008"> of the two columns.  Then subtract the mean </span><span class="cls_028">x</span><span class="cls_008"> from each</span></div>
<div style="position:absolute;left:124.80px;top:229.79px" class="cls_008"><span class="cls_008">individual point x</span><span class="cls_018"><sub>i</sub></span><span class="cls_008">. Let a = </span><span class="cls_028">x</span><span class="cls_008"> − x</span><span class="cls_018"><sub>i</sub></span><span class="cls_008">  and b = </span><span class="cls_028">y</span><span class="cls_008"> − y</span><span class="cls_018"><sub>i</sub></span><span class="cls_008">. Calculate a</span><span class="cls_018"><sup>2</sup></span><span class="cls_008">, b</span><span class="cls_018"><sup>2</sup></span><span class="cls_008">  and a · b.</span></div>
<div style="position:absolute;left:124.80px;top:241.74px" class="cls_008"><span class="cls_008">Divide the sum a · b by the square root of a</span><span class="cls_018"><sup>2</sup></span><span class="cls_008"> · b</span><span class="cls_018"><sup>2</sup></span><span class="cls_008"> for every point x</span><span class="cls_018"><sub>i</sub></span><span class="cls_008"> and y</span><span class="cls_018"><sub>i</sub></span><span class="cls_008">.</span></div>
<div style="position:absolute;left:264.57px;top:255.86px" class="cls_008"><span class="cls_008">∑</span><span class="cls_018"><sub>n</sub></span></div>
<div style="position:absolute;left:275.08px;top:263.33px" class="cls_018"><span class="cls_018">i=1</span><span class="cls_008">(x</span><span class="cls_018">i</span><span class="cls_008"> −x)(y</span><span class="cls_018">i</span><span class="cls_008"> −y)</span></div>
<div style="position:absolute;left:213.39px;top:270.21px" class="cls_008"><span class="cls_008">ρ</span><span class="cls_018"><sub>xy</sub></span><span class="cls_008"> =</span></div>
<div style="position:absolute;left:242.33px;top:269.91px" class="cls_008"><span class="cls_008">√∑</span><span class="cls_018">n</span></div>
<div style="position:absolute;left:316.97px;top:270.98px" class="cls_008"><span class="cls_008">∑</span><span class="cls_018"><sub>n</sub></span></div>
<div style="position:absolute;left:262.81px;top:278.45px" class="cls_018"><span class="cls_018">i=1</span><span class="cls_008">(x</span><span class="cls_018">i</span><span class="cls_008"> −x)</span><span class="cls_018">2</span></div>
<div style="position:absolute;left:327.49px;top:278.45px" class="cls_018"><span class="cls_018">i=1</span><span class="cls_008">(y</span><span class="cls_018">i</span><span class="cls_008"> −y)</span><span class="cls_018">2</span></div>
<div style="position:absolute;left:214.88px;top:531.24px" class="cls_008"><span class="cls_008">Figure 4.7: Heatmap over all features</span></div>
<div style="position:absolute;left:139.75px;top:568.70px" class="cls_008"><span class="cls_008">Figure 4.8 is a heatmap of the four main features we used.  Total income</span></div>
<div style="position:absolute;left:124.80px;top:580.66px" class="cls_008"><span class="cls_008">now includes many of the previous features in heatmap 4.7.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">37</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:34040px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background041.jpg" width=595 height=841></div>
<div style="position:absolute;left:211.41px;top:252.61px" class="cls_008"><span class="cls_008">Figure 4.8: Heatmap over four features</span></div>
<div style="position:absolute;left:139.75px;top:290.07px" class="cls_008"><span class="cls_008">The next few figures contains more information about the dataset we used.</span></div>
<div style="position:absolute;left:124.80px;top:302.02px" class="cls_008"><span class="cls_008">It will revolve around the five features we focused on. These are as mentioned</span></div>
<div style="position:absolute;left:124.80px;top:313.98px" class="cls_008"><span class="cls_008">earlier, full time equivalent (FTE), prepayment deductions (PPD), total income,</span></div>
<div style="position:absolute;left:124.80px;top:325.93px" class="cls_008"><span class="cls_008">hours worked and working time arrangement (WTA).</span></div>
<div style="position:absolute;left:136.98px;top:345.86px" class="cls_008"><span class="cls_008">1.</span><span class="cls_007"> PPD:</span><span class="cls_008"> As an employer, you are obliged to deduct withholding tax from</span></div>
<div style="position:absolute;left:149.71px;top:357.81px" class="cls_008"><span class="cls_008">the salary you pay to employees and pay this to the tax collector.</span></div>
<div style="position:absolute;left:136.98px;top:377.74px" class="cls_008"><span class="cls_008">2.</span><span class="cls_007"> FTE:</span><span class="cls_008"> State the FTE percentage which is stated in the employee’s em-</span></div>
<div style="position:absolute;left:149.71px;top:389.69px" class="cls_008"><span class="cls_008">ployment contract.</span></div>
<div style="position:absolute;left:136.98px;top:409.62px" class="cls_008"><span class="cls_008">3.</span><span class="cls_007"> Hours worked:</span><span class="cls_008"> Simply the number of hours a person has worked in one</span></div>
<div style="position:absolute;left:149.71px;top:421.57px" class="cls_008"><span class="cls_008">month.</span></div>
<div style="position:absolute;left:136.98px;top:441.50px" class="cls_008"><span class="cls_008">4.</span><span class="cls_007"> Total income:</span><span class="cls_008"> The total income is the sum of everything a person re-</span></div>
<div style="position:absolute;left:149.71px;top:453.45px" class="cls_008"><span class="cls_008">ceives in one month. This includes all types of benefits including additional</span></div>
<div style="position:absolute;left:149.71px;top:465.41px" class="cls_008"><span class="cls_008">charge for ’Smusstillegg’ and bonuses.</span></div>
<div style="position:absolute;left:136.98px;top:485.34px" class="cls_008"><span class="cls_008">5.</span><span class="cls_007"> WTA:</span><span class="cls_008"> The WTA is an agreement concerning when in the day the work</span></div>
<div style="position:absolute;left:149.71px;top:497.29px" class="cls_008"><span class="cls_008">will be performed and any variations in this arrangement over a period of</span></div>
<div style="position:absolute;left:149.71px;top:509.25px" class="cls_008"><span class="cls_008">time.</span></div>
<div style="position:absolute;left:168.64px;top:666.23px" class="cls_008"><span class="cls_008">Figure 4.9: Screenshot taken from the NTA’s webpage [22]</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">38</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:34891px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background042.jpg" width=595 height=841></div>
<div style="position:absolute;left:161.55px;top:132.68px" class="cls_008"><span class="cls_008">WTA</span></div>
<div style="position:absolute;left:233.68px;top:132.68px" class="cls_008"><span class="cls_008">Median   Mean   Mode</span></div>
<div style="position:absolute;left:359.48px;top:132.68px" class="cls_008"><span class="cls_008">Max</span></div>
<div style="position:absolute;left:406.44px;top:132.68px" class="cls_008"><span class="cls_008">Min</span></div>
<div style="position:absolute;left:161.55px;top:145.03px" class="cls_008"><span class="cls_008">ikkeSkift</span></div>
<div style="position:absolute;left:237.41px;top:145.03px" class="cls_008"><span class="cls_008">48404</span></div>
<div style="position:absolute;left:278.01px;top:145.03px" class="cls_008"><span class="cls_008">41572</span></div>
<div style="position:absolute;left:319.85px;top:145.03px" class="cls_008"><span class="cls_008">104</span></div>
<div style="position:absolute;left:351.73px;top:145.03px" class="cls_008"><span class="cls_008">6627727</span></div>
<div style="position:absolute;left:398.56px;top:145.03px" class="cls_008"><span class="cls_008">-123652</span></div>
<div style="position:absolute;left:161.55px;top:156.99px" class="cls_008"><span class="cls_008">skift365</span></div>
<div style="position:absolute;left:237.41px;top:156.99px" class="cls_008"><span class="cls_008">38058</span></div>
<div style="position:absolute;left:278.01px;top:156.99px" class="cls_008"><span class="cls_008">40765</span></div>
<div style="position:absolute;left:314.87px;top:156.99px" class="cls_008"><span class="cls_008">26554</span></div>
<div style="position:absolute;left:354.22px;top:156.99px" class="cls_008"><span class="cls_008">120635</span></div>
<div style="position:absolute;left:406.03px;top:156.99px" class="cls_008"><span class="cls_008">-140</span></div>
<div style="position:absolute;left:161.55px;top:168.94px" class="cls_008"><span class="cls_008">offshore336</span></div>
<div style="position:absolute;left:237.41px;top:168.94px" class="cls_008"><span class="cls_008">74765</span></div>
<div style="position:absolute;left:278.01px;top:168.94px" class="cls_008"><span class="cls_008">67201</span></div>
<div style="position:absolute;left:314.87px;top:168.94px" class="cls_008"><span class="cls_008">52830</span></div>
<div style="position:absolute;left:354.22px;top:168.94px" class="cls_008"><span class="cls_008">417661</span></div>
<div style="position:absolute;left:401.05px;top:168.94px" class="cls_008"><span class="cls_008">-34521</span></div>
<div style="position:absolute;left:161.55px;top:180.90px" class="cls_008"><span class="cls_008">doegnkont355</span></div>
<div style="position:absolute;left:237.41px;top:180.90px" class="cls_008"><span class="cls_008">35811</span></div>
<div style="position:absolute;left:278.01px;top:180.90px" class="cls_008"><span class="cls_008">36861</span></div>
<div style="position:absolute;left:322.34px;top:180.90px" class="cls_008"><span class="cls_008">17</span></div>
<div style="position:absolute;left:354.22px;top:180.90px" class="cls_008"><span class="cls_008">293346</span></div>
<div style="position:absolute;left:401.05px;top:180.90px" class="cls_008"><span class="cls_008">-48579</span></div>
<div style="position:absolute;left:161.55px;top:192.85px" class="cls_008"><span class="cls_008">helkont336</span></div>
<div style="position:absolute;left:237.41px;top:192.85px" class="cls_008"><span class="cls_008">51270</span></div>
<div style="position:absolute;left:278.01px;top:192.85px" class="cls_008"><span class="cls_008">51667</span></div>
<div style="position:absolute;left:314.87px;top:192.85px" class="cls_008"><span class="cls_008">38814</span></div>
<div style="position:absolute;left:354.22px;top:192.85px" class="cls_008"><span class="cls_008">171229</span></div>
<div style="position:absolute;left:412.68px;top:192.85px" class="cls_008"><span class="cls_008">0</span></div>
<div style="position:absolute;left:171.68px;top:215.17px" class="cls_008"><span class="cls_008">Figure 4.10: Measures of central tendency - Total income</span></div>
<div style="position:absolute;left:162.65px;top:269.37px" class="cls_008"><span class="cls_008">WTA</span></div>
<div style="position:absolute;left:234.78px;top:269.37px" class="cls_008"><span class="cls_008">Median   Mean   Mode    Max</span></div>
<div style="position:absolute;left:406.44px;top:269.37px" class="cls_008"><span class="cls_008">Min</span></div>
<div style="position:absolute;left:162.65px;top:281.72px" class="cls_008"><span class="cls_008">ikkeSkift</span></div>
<div style="position:absolute;left:237.14px;top:281.72px" class="cls_008"><span class="cls_008">162.38</span></div>
<div style="position:absolute;left:279.12px;top:281.72px" class="cls_008"><span class="cls_008">131.59</span></div>
<div style="position:absolute;left:323.45px;top:281.72px" class="cls_008"><span class="cls_008">162</span></div>
<div style="position:absolute;left:355.06px;top:281.72px" class="cls_008"><span class="cls_008">4156.80</span></div>
<div style="position:absolute;left:399.67px;top:281.72px" class="cls_008"><span class="cls_008">-486.50</span></div>
<div style="position:absolute;left:162.65px;top:293.68px" class="cls_008"><span class="cls_008">skift365</span></div>
<div style="position:absolute;left:237.14px;top:293.68px" class="cls_008"><span class="cls_008">158.05</span></div>
<div style="position:absolute;left:279.12px;top:293.68px" class="cls_008"><span class="cls_008">142.82</span></div>
<div style="position:absolute;left:323.45px;top:293.68px" class="cls_008"><span class="cls_008">158</span></div>
<div style="position:absolute;left:363.92px;top:293.68px" class="cls_008"><span class="cls_008">326</span></div>
<div style="position:absolute;left:404.64px;top:293.68px" class="cls_008"><span class="cls_008">-0.04</span></div>
<div style="position:absolute;left:162.65px;top:305.63px" class="cls_008"><span class="cls_008">offshore336</span></div>
<div style="position:absolute;left:237.14px;top:305.63px" class="cls_008"><span class="cls_008">134.23</span></div>
<div style="position:absolute;left:279.12px;top:305.63px" class="cls_008"><span class="cls_008">134.52</span></div>
<div style="position:absolute;left:323.45px;top:305.63px" class="cls_008"><span class="cls_008">134</span></div>
<div style="position:absolute;left:363.92px;top:305.63px" class="cls_008"><span class="cls_008">168</span></div>
<div style="position:absolute;left:407.13px;top:305.63px" class="cls_008"><span class="cls_008">-2.5</span></div>
<div style="position:absolute;left:162.65px;top:317.59px" class="cls_008"><span class="cls_008">doegnkont355</span></div>
<div style="position:absolute;left:237.14px;top:317.59px" class="cls_008"><span class="cls_008">153.72</span></div>
<div style="position:absolute;left:279.12px;top:317.59px" class="cls_008"><span class="cls_008">110.95</span></div>
<div style="position:absolute;left:323.45px;top:317.59px" class="cls_008"><span class="cls_008">153</span></div>
<div style="position:absolute;left:363.92px;top:317.59px" class="cls_008"><span class="cls_008">307</span></div>
<div style="position:absolute;left:408.52px;top:317.59px" class="cls_008"><span class="cls_008">-31</span></div>
<div style="position:absolute;left:162.65px;top:329.54px" class="cls_008"><span class="cls_008">helkont336</span></div>
<div style="position:absolute;left:237.14px;top:329.54px" class="cls_008"><span class="cls_008">145.49</span></div>
<div style="position:absolute;left:279.12px;top:329.54px" class="cls_008"><span class="cls_008">132.60</span></div>
<div style="position:absolute;left:323.45px;top:329.54px" class="cls_008"><span class="cls_008">145</span></div>
<div style="position:absolute;left:357.55px;top:329.54px" class="cls_008"><span class="cls_008">272.79</span></div>
<div style="position:absolute;left:412.67px;top:329.54px" class="cls_008"><span class="cls_008">0</span></div>
<div style="position:absolute;left:170.10px;top:351.86px" class="cls_008"><span class="cls_008">Figure 4.11: Measures of central tendency - Hours worked</span></div>
<div style="position:absolute;left:177.60px;top:406.05px" class="cls_008"><span class="cls_008">WTA</span></div>
<div style="position:absolute;left:249.73px;top:406.05px" class="cls_008"><span class="cls_008">Median   Mean   Mode   Max   Min</span></div>
<div style="position:absolute;left:177.60px;top:418.41px" class="cls_008"><span class="cls_008">ikkeSkift</span></div>
<div style="position:absolute;left:258.45px;top:418.41px" class="cls_008"><span class="cls_008">100</span></div>
<div style="position:absolute;left:294.75px;top:418.41px" class="cls_008"><span class="cls_008">82.35</span></div>
<div style="position:absolute;left:334.80px;top:418.41px" class="cls_008"><span class="cls_008">100</span></div>
<div style="position:absolute;left:366.40px;top:418.41px" class="cls_008"><span class="cls_008">2560</span></div>
<div style="position:absolute;left:404.50px;top:418.41px" class="cls_008"><span class="cls_008">0</span></div>
<div style="position:absolute;left:177.60px;top:430.36px" class="cls_008"><span class="cls_008">skift365</span></div>
<div style="position:absolute;left:258.45px;top:430.36px" class="cls_008"><span class="cls_008">100</span></div>
<div style="position:absolute;left:294.75px;top:430.36px" class="cls_008"><span class="cls_008">97.03</span></div>
<div style="position:absolute;left:334.80px;top:430.36px" class="cls_008"><span class="cls_008">100</span></div>
<div style="position:absolute;left:368.89px;top:430.36px" class="cls_008"><span class="cls_008">100</span></div>
<div style="position:absolute;left:404.50px;top:430.36px" class="cls_008"><span class="cls_008">0</span></div>
<div style="position:absolute;left:177.60px;top:442.32px" class="cls_008"><span class="cls_008">offshore336</span></div>
<div style="position:absolute;left:258.45px;top:442.32px" class="cls_008"><span class="cls_008">100</span></div>
<div style="position:absolute;left:294.75px;top:442.32px" class="cls_008"><span class="cls_008">98.92</span></div>
<div style="position:absolute;left:334.80px;top:442.32px" class="cls_008"><span class="cls_008">100</span></div>
<div style="position:absolute;left:368.89px;top:442.32px" class="cls_008"><span class="cls_008">100</span></div>
<div style="position:absolute;left:402.01px;top:442.32px" class="cls_008"><span class="cls_008">50</span></div>
<div style="position:absolute;left:177.60px;top:454.27px" class="cls_008"><span class="cls_008">doegnkont355</span></div>
<div style="position:absolute;left:258.45px;top:454.27px" class="cls_008"><span class="cls_008">100</span></div>
<div style="position:absolute;left:294.75px;top:454.27px" class="cls_008"><span class="cls_008">75.91</span></div>
<div style="position:absolute;left:334.80px;top:454.27px" class="cls_008"><span class="cls_008">100</span></div>
<div style="position:absolute;left:368.89px;top:454.27px" class="cls_008"><span class="cls_008">100</span></div>
<div style="position:absolute;left:404.50px;top:454.27px" class="cls_008"><span class="cls_008">0</span></div>
<div style="position:absolute;left:177.60px;top:466.23px" class="cls_008"><span class="cls_008">helkont336</span></div>
<div style="position:absolute;left:258.45px;top:466.23px" class="cls_008"><span class="cls_008">100</span></div>
<div style="position:absolute;left:294.75px;top:466.23px" class="cls_008"><span class="cls_008">91.57</span></div>
<div style="position:absolute;left:334.80px;top:466.23px" class="cls_008"><span class="cls_008">100</span></div>
<div style="position:absolute;left:368.89px;top:466.23px" class="cls_008"><span class="cls_008">100</span></div>
<div style="position:absolute;left:404.50px;top:466.23px" class="cls_008"><span class="cls_008">0</span></div>
<div style="position:absolute;left:124.80px;top:488.54px" class="cls_008"><span class="cls_008">Figure 4.12:  Measures of central tendency - Full time equivalent percentage</span></div>
<div style="position:absolute;left:124.80px;top:500.50px" class="cls_008"><span class="cls_008">(FTE)</span></div>
<div style="position:absolute;left:162.65px;top:554.70px" class="cls_008"><span class="cls_008">WTA</span></div>
<div style="position:absolute;left:234.78px;top:554.70px" class="cls_008"><span class="cls_008">Median   Mean   Mode   Max</span></div>
<div style="position:absolute;left:402.85px;top:554.70px" class="cls_008"><span class="cls_008">Min</span></div>
<div style="position:absolute;left:162.65px;top:567.05px" class="cls_008"><span class="cls_008">ikkeSkift</span></div>
<div style="position:absolute;left:236.86px;top:567.05px" class="cls_008"><span class="cls_008">-11528</span></div>
<div style="position:absolute;left:279.11px;top:567.05px" class="cls_008"><span class="cls_008">-15353</span></div>
<div style="position:absolute;left:328.99px;top:567.05px" class="cls_008"><span class="cls_008">0</span></div>
<div style="position:absolute;left:355.61px;top:567.05px" class="cls_008"><span class="cls_008">39332</span></div>
<div style="position:absolute;left:392.47px;top:567.05px" class="cls_008"><span class="cls_008">-2783645</span></div>
<div style="position:absolute;left:162.65px;top:579.01px" class="cls_008"><span class="cls_008">skift365</span></div>
<div style="position:absolute;left:236.86px;top:579.01px" class="cls_008"><span class="cls_008">-10144</span></div>
<div style="position:absolute;left:279.11px;top:579.01px" class="cls_008"><span class="cls_008">-10086</span></div>
<div style="position:absolute;left:328.99px;top:579.01px" class="cls_008"><span class="cls_008">0</span></div>
<div style="position:absolute;left:363.08px;top:579.01px" class="cls_008"><span class="cls_008">91</span></div>
<div style="position:absolute;left:397.45px;top:579.01px" class="cls_008"><span class="cls_008">-40010</span></div>
<div style="position:absolute;left:162.65px;top:590.96px" class="cls_008"><span class="cls_008">offshore336</span></div>
<div style="position:absolute;left:236.86px;top:590.96px" class="cls_008"><span class="cls_008">-24347</span></div>
<div style="position:absolute;left:279.11px;top:590.96px" class="cls_008"><span class="cls_008">-28245</span></div>
<div style="position:absolute;left:328.99px;top:590.96px" class="cls_008"><span class="cls_008">0</span></div>
<div style="position:absolute;left:355.61px;top:590.96px" class="cls_008"><span class="cls_008">12306</span></div>
<div style="position:absolute;left:394.96px;top:590.96px" class="cls_008"><span class="cls_008">-112216</span></div>
<div style="position:absolute;left:162.65px;top:602.92px" class="cls_008"><span class="cls_008">doegnkont355</span></div>
<div style="position:absolute;left:236.86px;top:602.92px" class="cls_008"><span class="cls_008">-10051</span></div>
<div style="position:absolute;left:279.11px;top:602.92px" class="cls_008"><span class="cls_008">-10352</span></div>
<div style="position:absolute;left:328.99px;top:602.92px" class="cls_008"><span class="cls_008">0</span></div>
<div style="position:absolute;left:365.57px;top:602.92px" class="cls_008"><span class="cls_008">0</span></div>
<div style="position:absolute;left:394.96px;top:602.92px" class="cls_008"><span class="cls_008">-146062</span></div>
<div style="position:absolute;left:162.65px;top:614.87px" class="cls_008"><span class="cls_008">helkont336</span></div>
<div style="position:absolute;left:236.86px;top:614.87px" class="cls_008"><span class="cls_008">-16710</span></div>
<div style="position:absolute;left:279.11px;top:614.87px" class="cls_008"><span class="cls_008">-17035</span></div>
<div style="position:absolute;left:328.99px;top:614.87px" class="cls_008"><span class="cls_008">0</span></div>
<div style="position:absolute;left:365.57px;top:614.87px" class="cls_008"><span class="cls_008">0</span></div>
<div style="position:absolute;left:397.45px;top:614.87px" class="cls_008"><span class="cls_008">-78486</span></div>
<div style="position:absolute;left:134.42px;top:637.19px" class="cls_008"><span class="cls_008">Figure 4.13: Measures of central tendency - Prepayment deductions(PPD)</span></div>
<div style="position:absolute;left:139.75px;top:672.65px" class="cls_008"><span class="cls_008">The following few graphs shows the four features distributed over WTA in</span></div>
<div style="position:absolute;left:124.80px;top:684.61px" class="cls_008"><span class="cls_008">the form of whisker plots (box plots).</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">39</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:35742px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background043.jpg" width=595 height=841></div>
<div style="position:absolute;left:200.31px;top:255.61px" class="cls_008"><span class="cls_008">Figure 4.14: How to interpret Whisker plots</span></div>
<div style="position:absolute;left:207.01px;top:504.45px" class="cls_008"><span class="cls_008">Figure 4.15: Whisker plot - Total income</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">40</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:36593px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background044.jpg" width=595 height=841></div>
<div style="position:absolute;left:224.79px;top:324.93px" class="cls_008"><span class="cls_008">Figure 4.16: Whisker plot - PPD</span></div>
<div style="position:absolute;left:225.13px;top:577.19px" class="cls_008"><span class="cls_008">Figure 4.17: Whisker plot - FTE</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">41</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:37444px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background045.jpg" width=595 height=841></div>
<div style="position:absolute;left:205.43px;top:328.75px" class="cls_008"><span class="cls_008">Figure 4.18: Whisker plot - Hours worked</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">42</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:38295px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background046.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:188.93px" class="cls_011"><span class="cls_011">Chapter 5</span></div>
<div style="position:absolute;left:124.80px;top:234.62px" class="cls_009"><span class="cls_009">Implementing the</span></div>
<div style="position:absolute;left:124.80px;top:264.50px" class="cls_009"><span class="cls_009">algorithms</span></div>
<div style="position:absolute;left:124.80px;top:331.14px" class="cls_008"><span class="cls_008">This chapter details the implementation of the four different algorithms:  K-</span></div>
<div style="position:absolute;left:124.80px;top:343.09px" class="cls_008"><span class="cls_008">means, DBSCAN, LOF and AprioriRare.  We chose these algorithms because</span></div>
<div style="position:absolute;left:124.80px;top:355.05px" class="cls_008"><span class="cls_008">they are all well renowned and well documented, and as they all work in different</span></div>
<div style="position:absolute;left:124.80px;top:367.00px" class="cls_008"><span class="cls_008">manners, we hoped they would find different sets of outliers.</span></div>
<div style="position:absolute;left:124.80px;top:395.56px" class="cls_010"><span class="cls_010">5.1</span></div>
<div style="position:absolute;left:161.56px;top:395.56px" class="cls_010"><span class="cls_010">Feature selection</span></div>
<div style="position:absolute;left:124.80px;top:421.77px" class="cls_008"><span class="cls_008">The first thing we had to do when implementing our algorithms was to load</span></div>
<div style="position:absolute;left:124.80px;top:433.72px" class="cls_008"><span class="cls_008">in the CSV previously made of all the extracted data that seemed useful from</span></div>
<div style="position:absolute;left:124.80px;top:445.68px" class="cls_008"><span class="cls_008">A-meldingen. With the use of Pandas, the CSV was loaded into the memory as</span></div>
<div style="position:absolute;left:124.80px;top:457.63px" class="cls_008"><span class="cls_008">a DataFrame-object (Figure 5.1).</span></div>
<div style="position:absolute;left:164.68px;top:588.20px" class="cls_008"><span class="cls_008">Figure 5.1: Snippet of the DataFrame from the loaded CSV.</span></div>
<div style="position:absolute;left:139.75px;top:625.66px" class="cls_008"><span class="cls_008">Since we had decided to use only the first 100.000 data points, as some of our</span></div>
<div style="position:absolute;left:124.80px;top:637.62px" class="cls_008"><span class="cls_008">algorithms were poorly optimized and struggled with using the whole dataset,</span></div>
<div style="position:absolute;left:124.80px;top:649.57px" class="cls_008"><span class="cls_008">we created a copy of the DataFrame with only the first 100.000 points with the</span></div>
<div style="position:absolute;left:124.80px;top:661.53px" class="cls_008"><span class="cls_008">df.head()-command. In this copy we also specified which columns we wanted as</span></div>
<div style="position:absolute;left:124.80px;top:673.48px" class="cls_008"><span class="cls_008">we had decided which features we were going to use. When using three features</span></div>
<div style="position:absolute;left:124.80px;top:685.44px" class="cls_008"><span class="cls_008">we specified total income, FTE percentage and hours worked. For four features</span></div>
<div style="position:absolute;left:124.80px;top:697.39px" class="cls_008"><span class="cls_008">we used the previous three in addition to prepayment deductions. And for five</span></div>
<div style="position:absolute;left:124.80px;top:709.35px" class="cls_008"><span class="cls_008">features we included working time arrangement as well (Figure 5.2).</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">43</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:39146px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background047.jpg" width=595 height=841></div>
<div style="position:absolute;left:190.55px;top:245.07px" class="cls_008"><span class="cls_008">Figure 5.2: Snippet of the extracted DataFrame.</span></div>
<div style="position:absolute;left:139.75px;top:282.53px" class="cls_008"><span class="cls_008">The following was done when implementing K-means, DBSCAN and Local</span></div>
<div style="position:absolute;left:124.80px;top:294.49px" class="cls_008"><span class="cls_008">Outlier Factor:</span></div>
<div style="position:absolute;left:124.80px;top:320.38px" class="cls_017"><span class="cls_017">5.1.1</span></div>
<div style="position:absolute;left:165.90px;top:320.38px" class="cls_017"><span class="cls_017">Categorical data</span></div>
<div style="position:absolute;left:124.80px;top:340.77px" class="cls_008"><span class="cls_008">For the DataFrame copy with five features, the feature called working hours</span></div>
<div style="position:absolute;left:124.80px;top:352.72px" class="cls_008"><span class="cls_008">arrangement (WTA) was categorical with five different possible values in text</span></div>
<div style="position:absolute;left:124.80px;top:364.68px" class="cls_008"><span class="cls_008">form (figure 5.3).</span></div>
<div style="position:absolute;left:198.01px;top:542.75px" class="cls_008"><span class="cls_008">Figure 5.3: The five different values of WTA.</span></div>
<div style="position:absolute;left:139.75px;top:580.21px" class="cls_008"><span class="cls_008">Since the algorithms had no way of interpreting text and need their features</span></div>
<div style="position:absolute;left:124.80px;top:592.16px" class="cls_008"><span class="cls_008">to be in a numerical format we had to convert this to a numerical representation.</span></div>
<div style="position:absolute;left:124.80px;top:604.12px" class="cls_008"><span class="cls_008">To do this we used the Pandas .get_dummies()-method for one hot encoding</span></div>
<div style="position:absolute;left:124.80px;top:616.07px" class="cls_008"><span class="cls_008">the values.  This resulted in the WTA feature being converted into five new</span></div>
<div style="position:absolute;left:124.80px;top:628.03px" class="cls_008"><span class="cls_008">features which could either be 0 or 1 (figure 5.4). In practice this left us with 9</span></div>
<div style="position:absolute;left:124.80px;top:639.98px" class="cls_008"><span class="cls_008">features in total for our data.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">44</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:39997px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background048.jpg" width=595 height=841></div>
<div style="position:absolute;left:170.34px;top:203.38px" class="cls_008"><span class="cls_008">Figure 5.4: Working time arrangement - one hot encoded.</span></div>
<div style="position:absolute;left:124.80px;top:242.82px" class="cls_017"><span class="cls_017">5.1.2</span></div>
<div style="position:absolute;left:165.90px;top:242.82px" class="cls_017"><span class="cls_017">Scaling the data</span></div>
<div style="position:absolute;left:124.80px;top:263.20px" class="cls_008"><span class="cls_008">In the extracted data we used, some of our features were in low ranges such</span></div>
<div style="position:absolute;left:124.80px;top:275.16px" class="cls_008"><span class="cls_008">as either a 0 or a 1, while others ranged from negative values up to a couple</span></div>
<div style="position:absolute;left:124.80px;top:287.11px" class="cls_008"><span class="cls_008">of million.  Because of this, to prevent a very skewed view of the data for our</span></div>
<div style="position:absolute;left:124.80px;top:299.07px" class="cls_008"><span class="cls_008">algorithm, we needed to normalize the data into ranges between -1 and 1. To</span></div>
<div style="position:absolute;left:124.80px;top:311.02px" class="cls_008"><span class="cls_008">do this we used Scikit-learn’s StandardScaler to standardize the features by</span></div>
<div style="position:absolute;left:124.80px;top:322.98px" class="cls_008"><span class="cls_008">removing the mean and scaling to unit variance (figure 5.5) [15].</span></div>
<div style="position:absolute;left:183.44px;top:413.80px" class="cls_008"><span class="cls_008">Figure 5.5: The DataFrame after scaling the values.</span></div>
<div style="position:absolute;left:124.80px;top:453.24px" class="cls_017"><span class="cls_017">5.1.3</span></div>
<div style="position:absolute;left:165.90px;top:453.24px" class="cls_017"><span class="cls_017">Principal Component Analysis</span></div>
<div style="position:absolute;left:124.80px;top:473.62px" class="cls_008"><span class="cls_008">When using more than three features for our data we might start to suffer</span></div>
<div style="position:absolute;left:124.80px;top:485.58px" class="cls_008"><span class="cls_008">from the curse of dimensionality [26].  I.e.  the more features used the sparser</span></div>
<div style="position:absolute;left:124.80px;top:497.54px" class="cls_008"><span class="cls_008">the feature space becomes.  In addition, visualizing the data for humans also</span></div>
<div style="position:absolute;left:124.80px;top:509.49px" class="cls_008"><span class="cls_008">becomes problematic when we reach dimensions higher than three. To combat</span></div>
<div style="position:absolute;left:124.80px;top:521.45px" class="cls_008"><span class="cls_008">this we employed Scikit-learn’s Principal Component Analysis for dimension</span></div>
<div style="position:absolute;left:124.80px;top:533.40px" class="cls_008"><span class="cls_008">reduction on our data when using four or more features.</span></div>
<div style="position:absolute;left:179.69px;top:671.82px" class="cls_008"><span class="cls_008">Figure 5.6: The DataFrame after implementing PCA.</span></div>
<div style="position:absolute;left:139.75px;top:709.28px" class="cls_008"><span class="cls_008">The downside to using PCA is that the we can no longer see directly what</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">45</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:40848px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background049.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">each value represents for which feature. Instead they are represented as an x, y</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">and z feature (figure 5.6) which can’t be related directly back to the data. Since</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">Pandas retains the indexes of each data point in the CSVs we can compare these</span></div>
<div style="position:absolute;left:124.80px;top:160.77px" class="cls_008"><span class="cls_008">later and find the original feature values.</span></div>
<div style="position:absolute;left:124.80px;top:189.34px" class="cls_010"><span class="cls_010">5.2</span></div>
<div style="position:absolute;left:161.56px;top:189.34px" class="cls_010"><span class="cls_010">Implementation of K-means</span></div>
<div style="position:absolute;left:124.80px;top:215.54px" class="cls_008"><span class="cls_008">For the implementation of K-means in our project we first had to import the</span></div>
<div style="position:absolute;left:124.80px;top:227.50px" class="cls_008"><span class="cls_008">kmeans package from Scikit-learn’s clustering library. We then used this to set</span></div>
<div style="position:absolute;left:124.80px;top:239.45px" class="cls_008"><span class="cls_008">up a method called doKmeans (Figure 5.7) which we could use for running the</span></div>
<div style="position:absolute;left:124.80px;top:251.41px" class="cls_008"><span class="cls_008">K-means algorithm on the dataset.</span></div>
<div style="position:absolute;left:216.98px;top:370.31px" class="cls_008"><span class="cls_008">Figure 5.7: The doKmeans-method.</span></div>
<div style="position:absolute;left:139.75px;top:407.77px" class="cls_008"><span class="cls_008">This method takes two parameters; X, which is the DataFrame-object we</span></div>
<div style="position:absolute;left:124.80px;top:419.72px" class="cls_008"><span class="cls_008">are going to run K-means on; and nclust which is the k number of clusters we</span></div>
<div style="position:absolute;left:124.80px;top:431.68px" class="cls_008"><span class="cls_008">want. We also had to specify which algorithm to use. The choice of algorithms</span></div>
<div style="position:absolute;left:124.80px;top:443.63px" class="cls_008"><span class="cls_008">is between the classical EM-style algorithm referred to as “full” or the “elkan”</span></div>
<div style="position:absolute;left:124.80px;top:455.59px" class="cls_008"><span class="cls_008">variation, which is more efficient by using the triangle inequality, but currently</span></div>
<div style="position:absolute;left:124.80px;top:467.54px" class="cls_008"><span class="cls_008">doesn’t support sparse data [15]. We chose to use the “auto” option as this lets</span></div>
<div style="position:absolute;left:124.80px;top:479.50px" class="cls_008"><span class="cls_008">the algorithm decide which one it finds more fitting for the data.</span></div>
<div style="position:absolute;left:139.75px;top:491.45px" class="cls_008"><span class="cls_008">When running the method it returns two arrays. The first one is clust_labels,</span></div>
<div style="position:absolute;left:124.80px;top:503.41px" class="cls_008"><span class="cls_008">containing a numerical label for each data point detailing which cluster it belongs</span></div>
<div style="position:absolute;left:124.80px;top:515.36px" class="cls_008"><span class="cls_008">to in the range from 0 to k.  The second one is cent, each clusters centroids</span></div>
<div style="position:absolute;left:124.80px;top:527.32px" class="cls_008"><span class="cls_008">position as an x-, y- and z-coordinate.</span></div>
<div style="position:absolute;left:124.80px;top:553.21px" class="cls_017"><span class="cls_017">5.2.1</span></div>
<div style="position:absolute;left:165.90px;top:553.21px" class="cls_017"><span class="cls_017">Elbow Method</span></div>
<div style="position:absolute;left:124.80px;top:573.60px" class="cls_008"><span class="cls_008">Determining the optimal number of clusters k to use in K-means is one of the big</span></div>
<div style="position:absolute;left:124.80px;top:585.55px" class="cls_008"><span class="cls_008">issues when implementing the algorithm. There is no definitive "right" amount</span></div>
<div style="position:absolute;left:124.80px;top:597.51px" class="cls_008"><span class="cls_008">of clusters and it is somewhat subjective. If you do not know the dataset well,</span></div>
<div style="position:absolute;left:124.80px;top:609.46px" class="cls_008"><span class="cls_008">there are several methods to employ for determining the number of cluster.</span></div>
<div style="position:absolute;left:139.75px;top:621.42px" class="cls_008"><span class="cls_008">One of these methods, and the one we chose to use, is the Elbow Method.</span></div>
<div style="position:absolute;left:124.80px;top:633.37px" class="cls_008"><span class="cls_008">This method is used to compare the mean distance between data points and</span></div>
<div style="position:absolute;left:124.80px;top:645.33px" class="cls_008"><span class="cls_008">their cluster centroid for increasingly high values of k. Since this distance will</span></div>
<div style="position:absolute;left:124.80px;top:657.28px" class="cls_008"><span class="cls_008">shrink each time we increase the number of clusters, up until when k is equal</span></div>
<div style="position:absolute;left:124.80px;top:669.24px" class="cls_008"><span class="cls_008">to our number of data points, we can plot this distance and then look for an</span></div>
<div style="position:absolute;left:124.80px;top:681.19px" class="cls_008"><span class="cls_008">“elbow point”. An "elbow point" is where the rate of decrease shifts sharply in</span></div>
<div style="position:absolute;left:124.80px;top:693.15px" class="cls_008"><span class="cls_008">the graph and we can use this point to determine an appropriate value for our</span></div>
<div style="position:absolute;left:124.80px;top:705.10px" class="cls_008"><span class="cls_008">k.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">46</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:41699px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background050.jpg" width=595 height=841></div>
<div style="position:absolute;left:199.49px;top:180.78px" class="cls_008"><span class="cls_008">Figure 5.8: The code for the Elbow Method.</span></div>
<div style="position:absolute;left:139.75px;top:218.24px" class="cls_008"><span class="cls_008">When implementing the Elbow Method on our data we wrote a couple of</span></div>
<div style="position:absolute;left:124.80px;top:230.20px" class="cls_008"><span class="cls_008">lines of code (Figure 5.8) to run K-means on the dataset for k-values from 1 to</span></div>
<div style="position:absolute;left:124.80px;top:242.15px" class="cls_008"><span class="cls_008">9, calculate the mean distance for the data points to their cluster centroid for</span></div>
<div style="position:absolute;left:124.80px;top:254.11px" class="cls_008"><span class="cls_008">each k and then store these values in a array called distortions. We could then</span></div>
<div style="position:absolute;left:124.80px;top:266.06px" class="cls_008"><span class="cls_008">use this to plot the distances for each k.</span></div>
<div style="position:absolute;left:188.09px;top:507.44px" class="cls_008"><span class="cls_008">Figure 5.9: The Elbow Method for three features.</span></div>
<div style="position:absolute;left:139.75px;top:544.90px" class="cls_008"><span class="cls_008">When plotting the Elbow Method for three features (Figure 5.9) we see that</span></div>
<div style="position:absolute;left:124.80px;top:556.85px" class="cls_008"><span class="cls_008">the "elbow point" occurs when k = 2 as this where the sharpest shift in our plot</span></div>
<div style="position:absolute;left:124.80px;top:568.81px" class="cls_008"><span class="cls_008">occurs. As a result we chose k = 2 when running K-means on three features.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">47</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:42550px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background051.jpg" width=595 height=841></div>
<div style="position:absolute;left:187.95px;top:341.43px" class="cls_008"><span class="cls_008">Figure 5.10: The Elbow Method for four features.</span></div>
<div style="position:absolute;left:139.75px;top:378.89px" class="cls_008"><span class="cls_008">For four features (Figure 5.10) it seems like the "elbow point" is when k = 2.</span></div>
<div style="position:absolute;left:124.80px;top:390.85px" class="cls_008"><span class="cls_008">One could argue that there is also an "elbow point" when k = 4, but since the</span></div>
<div style="position:absolute;left:124.80px;top:402.80px" class="cls_008"><span class="cls_008">sharpest shift happens when k = 2 we chose to use this as our k.</span></div>
<div style="position:absolute;left:189.21px;top:644.18px" class="cls_008"><span class="cls_008">Figure 5.11: The Elbow Method for five features.</span></div>
<div style="position:absolute;left:139.75px;top:681.64px" class="cls_008"><span class="cls_008">Finally, for five features (Figure 5.11) we see quite clearly that the "elbow</span></div>
<div style="position:absolute;left:124.80px;top:693.59px" class="cls_008"><span class="cls_008">point" is located where k = 3 so this is what we set our k for five features.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">48</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:43401px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background052.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:122.92px" class="cls_017"><span class="cls_017">5.2.2</span></div>
<div style="position:absolute;left:165.90px;top:122.92px" class="cls_017"><span class="cls_017">Running K-means</span></div>
<div style="position:absolute;left:124.80px;top:143.30px" class="cls_008"><span class="cls_008">When we had chosen the k-value for each dataset we would run K-means on, all</span></div>
<div style="position:absolute;left:124.80px;top:155.25px" class="cls_008"><span class="cls_008">that was left to do was running the method for each data set with the correct</span></div>
<div style="position:absolute;left:124.80px;top:167.21px" class="cls_008"><span class="cls_008">k (Figure 5.12).</span></div>
<div style="position:absolute;left:171.13px;top:244.15px" class="cls_008"><span class="cls_008">Figure 5.12: Running the doKmeans-method with k = 2.</span></div>
<div style="position:absolute;left:139.75px;top:281.61px" class="cls_008"><span class="cls_008">This returned the clust_labels array with labels for all our data points, de-</span></div>
<div style="position:absolute;left:124.80px;top:293.56px" class="cls_008"><span class="cls_008">scribing which cluster they belong to. We then appended this to our DataFrame</span></div>
<div style="position:absolute;left:124.80px;top:305.52px" class="cls_008"><span class="cls_008">as the column ’kmeans’ (Figure 5.13).</span></div>
<div style="position:absolute;left:124.80px;top:428.11px" class="cls_008"><span class="cls_008">Figure 5.13: Snippet showing which kmeans cluster each data point belongs to.</span></div>
<div style="position:absolute;left:139.75px;top:465.57px" class="cls_008"><span class="cls_008">We decided to plot all our data points and colour them according to which</span></div>
<div style="position:absolute;left:124.80px;top:477.53px" class="cls_008"><span class="cls_008">cluster they belonged to.</span></div>
<div style="position:absolute;left:166.37px;top:657.72px" class="cls_008"><span class="cls_008">Figure 5.14: The two clusters of the data for three features.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">49</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:44252px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background053.jpg" width=595 height=841></div>
<div style="position:absolute;left:168.72px;top:340.23px" class="cls_008"><span class="cls_008">Figure 5.15: The two clusters of the data for four features.</span></div>
<div style="position:absolute;left:166.65px;top:600.36px" class="cls_008"><span class="cls_008">Figure 5.16: The three clusters of the data for five features.</span></div>
<div style="position:absolute;left:124.80px;top:639.81px" class="cls_017"><span class="cls_017">5.2.3</span></div>
<div style="position:absolute;left:165.90px;top:639.81px" class="cls_017"><span class="cls_017">Using K-means to detect outliers</span></div>
<div style="position:absolute;left:124.80px;top:660.19px" class="cls_008"><span class="cls_008">After we had grouped the data into their respective clusters we needed a way</span></div>
<div style="position:absolute;left:124.80px;top:672.15px" class="cls_008"><span class="cls_008">to determine which points we would consider outliers and thereby potential</span></div>
<div style="position:absolute;left:124.80px;top:684.10px" class="cls_008"><span class="cls_008">anomalies.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">50</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:45103px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background054.jpg" width=595 height=841></div>
<div style="position:absolute;left:177.47px;top:409.03px" class="cls_008"><span class="cls_008">Figure 5.17: Example of how we would detect outliers.</span></div>
<div style="position:absolute;left:139.75px;top:446.49px" class="cls_008"><span class="cls_008">Since K-means does not have a built-in way of detecting outliers, we came</span></div>
<div style="position:absolute;left:124.80px;top:458.45px" class="cls_008"><span class="cls_008">up with the idea to use the average euclidean distance from the data points in</span></div>
<div style="position:absolute;left:124.80px;top:470.40px" class="cls_008"><span class="cls_008">a cluster to their respective cluster centroid as a metric. By using this we could</span></div>
<div style="position:absolute;left:124.80px;top:482.36px" class="cls_008"><span class="cls_008">mark as outliers any data points that were further than x × averageClusterDis-</span></div>
<div style="position:absolute;left:124.80px;top:494.31px" class="cls_008"><span class="cls_008">tance away from their centroid (Figure 5.17).  The idea behind this was that</span></div>
<div style="position:absolute;left:124.80px;top:506.27px" class="cls_008"><span class="cls_008">the clusters would most likely be centered around where most of the data was</span></div>
<div style="position:absolute;left:124.80px;top:518.22px" class="cls_008"><span class="cls_008">concentrated.  These points were unlikely to be anomalies, while points that</span></div>
<div style="position:absolute;left:124.80px;top:530.18px" class="cls_008"><span class="cls_008">had uncommon characteristics and were more likely to be anomalous would be</span></div>
<div style="position:absolute;left:124.80px;top:542.13px" class="cls_008"><span class="cls_008">located further away from the cluster center. The value of x was determined by</span></div>
<div style="position:absolute;left:124.80px;top:554.09px" class="cls_008"><span class="cls_008">testing different values and looking at how many outliers we got registered for</span></div>
<div style="position:absolute;left:124.80px;top:566.05px" class="cls_008"><span class="cls_008">each. We decided that we would use values of x where we got slightly less than</span></div>
<div style="position:absolute;left:124.80px;top:578.00px" class="cls_008"><span class="cls_008">1% of the data marked as outliers.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">51</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:45954px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background055.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:284.83px" class="cls_008"><span class="cls_008">Figure 5.18: Method for determining the average euclidean distance to cluster</span></div>
<div style="position:absolute;left:124.80px;top:296.79px" class="cls_008"><span class="cls_008">centroids for each cluster.</span></div>
<div style="position:absolute;left:139.75px;top:334.25px" class="cls_008"><span class="cls_008">To implement this we first had to create a method for determining what</span></div>
<div style="position:absolute;left:124.80px;top:346.20px" class="cls_008"><span class="cls_008">the average euclidean distance to the cluster centroid for each cluster center</span></div>
<div style="position:absolute;left:124.80px;top:358.16px" class="cls_008"><span class="cls_008">was (figure 5.18).  We then stored each average distance in an array called</span></div>
<div style="position:absolute;left:124.80px;top:370.11px" class="cls_008"><span class="cls_008">average_distance.</span></div>
<div style="position:absolute;left:124.80px;top:519.41px" class="cls_008"><span class="cls_008">Figure</span></div>
<div style="position:absolute;left:159.11px;top:519.41px" class="cls_008"><span class="cls_008">5.19:  Method  for  determining  which  data  points  were  x</span></div>
<div style="position:absolute;left:432.54px;top:519.41px" class="cls_008"><span class="cls_008">× aver-</span></div>
<div style="position:absolute;left:124.80px;top:531.37px" class="cls_008"><span class="cls_008">age_distance away from centroid.</span></div>
<div style="position:absolute;left:139.75px;top:568.83px" class="cls_008"><span class="cls_008">We then used these distances to calculate for each data point whether they</span></div>
<div style="position:absolute;left:124.80px;top:580.78px" class="cls_008"><span class="cls_008">were x× average_distance away from their centroid or not. If they were, they</span></div>
<div style="position:absolute;left:124.80px;top:592.74px" class="cls_008"><span class="cls_008">got marked with a 1 in the DataFrame.  We found x = 4 to be suitable for</span></div>
<div style="position:absolute;left:124.80px;top:604.69px" class="cls_008"><span class="cls_008">three and four features, with 913 and 978 outliers found respectively. For five</span></div>
<div style="position:absolute;left:124.80px;top:616.65px" class="cls_008"><span class="cls_008">features we had to increase the x to 10 to not end up with multiple thousands</span></div>
<div style="position:absolute;left:124.80px;top:628.60px" class="cls_008"><span class="cls_008">of data points registered as outliers. With x = 10 we ended up with 804 outliers</span></div>
<div style="position:absolute;left:124.80px;top:640.56px" class="cls_008"><span class="cls_008">detected for five features.</span></div>
<div style="position:absolute;left:124.80px;top:669.12px" class="cls_010"><span class="cls_010">5.3</span></div>
<div style="position:absolute;left:161.56px;top:669.12px" class="cls_010"><span class="cls_010">Implementation of DBSCAN</span></div>
<div style="position:absolute;left:124.80px;top:695.32px" class="cls_008"><span class="cls_008">For the implementation of the DBSCAN algorithm, we used the cluster module</span></div>
<div style="position:absolute;left:124.80px;top:707.28px" class="cls_008"><span class="cls_008">from the Scikit-learn library [5] for Python.  The module is well-documented</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">52</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:46805px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background056.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">and easy to understand. Since this is an unsupervised algorithm, the only input</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">needed is the data itself.  The input fed to the algorithm was preprocessed in</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">order to scale the data and normalize its distribution (see 5.1.2). As the amount</span></div>
<div style="position:absolute;left:124.80px;top:160.77px" class="cls_008"><span class="cls_008">of features in the datasets increased, we applied Principal Component Analysis</span></div>
<div style="position:absolute;left:124.80px;top:172.73px" class="cls_008"><span class="cls_008">(PCA) in order to reduce its dimensions both for visualization purposes and to</span></div>
<div style="position:absolute;left:124.80px;top:184.68px" class="cls_008"><span class="cls_008">remove redundant data in the set.</span></div>
<div style="position:absolute;left:139.75px;top:196.64px" class="cls_008"><span class="cls_008">There are two mandatory parameters required to be set before applying the</span></div>
<div style="position:absolute;left:124.80px;top:208.59px" class="cls_008"><span class="cls_008">algorithm to data, eps and M inP ts respectively. As stated in chapter 3.3.2, the</span></div>
<div style="position:absolute;left:124.80px;top:220.55px" class="cls_008"><span class="cls_008">eps parameter acts as a radius-distance for a point and M inP ts as an integer</span></div>
<div style="position:absolute;left:124.80px;top:232.51px" class="cls_008"><span class="cls_008">which defines the amount of nearby neighbors required to form a cluster.  To</span></div>
<div style="position:absolute;left:124.80px;top:244.46px" class="cls_008"><span class="cls_008">start with, we tested with several different eps and M inP tsintegers to get to</span></div>
<div style="position:absolute;left:124.80px;top:256.42px" class="cls_008"><span class="cls_008">know the algorithm in practice.  For the distance-metric, we used euclidean</span></div>
<div style="position:absolute;left:124.80px;top:268.37px" class="cls_008"><span class="cls_008">distance.</span></div>
<div style="position:absolute;left:124.80px;top:294.27px" class="cls_017"><span class="cls_017">5.3.1</span></div>
<div style="position:absolute;left:165.90px;top:294.27px" class="cls_017"><span class="cls_017">Setting eps values</span></div>
<div style="position:absolute;left:124.80px;top:314.65px" class="cls_008"><span class="cls_008">The original paper of DBSCAN [6] offers a heuristic method of setting the eps</span></div>
<div style="position:absolute;left:124.80px;top:326.60px" class="cls_008"><span class="cls_008">value based on observations in a dataset. This method aims to find the k-dist of</span></div>
<div style="position:absolute;left:124.80px;top:338.56px" class="cls_008"><span class="cls_008">the "thinnest" clusters in the dataset. In other words, the least dense clusters.</span></div>
<div style="position:absolute;left:124.80px;top:350.51px" class="cls_008"><span class="cls_008">To explain how we did this, we reintroduce the k-dist of a point. As described</span></div>
<div style="position:absolute;left:124.80px;top:362.47px" class="cls_008"><span class="cls_008">in chapter 3.3.2, the k-dist of a point is the distance from an arbitrary point p,</span></div>
<div style="position:absolute;left:124.80px;top:374.42px" class="cls_008"><span class="cls_008">to its k’th nearest neighbor.  The first step is to calculate the k-dist to every</span></div>
<div style="position:absolute;left:124.80px;top:386.38px" class="cls_008"><span class="cls_008">point in the dataset and sort these values in ascending order. For this task we</span></div>
<div style="position:absolute;left:124.80px;top:398.33px" class="cls_008"><span class="cls_008">applied the NearestNeighbors class from the Scikit-learn library[5] to the data.</span></div>
<div style="position:absolute;left:196.34px;top:609.58px" class="cls_008"><span class="cls_008">Figure 5.20: Code for calculating k-dist graph</span></div>
<div style="position:absolute;left:139.75px;top:647.04px" class="cls_008"><span class="cls_008">This graph is often denoted as the sorted k-dist graph. As recommended in</span></div>
<div style="position:absolute;left:124.80px;top:659.00px" class="cls_008"><span class="cls_008">the original paper, "the threshold point is the first point in the first ’valley’ of</span></div>
<div style="position:absolute;left:124.80px;top:670.95px" class="cls_008"><span class="cls_008">the sorted k-dist graph". Thus, we chose this valley point as the eps value for</span></div>
<div style="position:absolute;left:124.80px;top:682.91px" class="cls_008"><span class="cls_008">our algorithm as illustrated in figure 4.3 and 4.4.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">53</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:47656px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background057.jpg" width=595 height=841></div>
<div style="position:absolute;left:185.67px;top:305.13px" class="cls_008"><span class="cls_008">Figure 5.21: Eps for dataset with three dimensions</span></div>
<div style="position:absolute;left:139.75px;top:342.59px" class="cls_008"><span class="cls_008">We applied the same method to the different datasets and got similar, but</span></div>
<div style="position:absolute;left:124.80px;top:354.54px" class="cls_008"><span class="cls_008">not equal results, which is expected for data with different dimensions.</span></div>
<div style="position:absolute;left:188.02px;top:558.57px" class="cls_008"><span class="cls_008">Figure 5.22: Eps for dataset with four dimensions</span></div>
<div style="position:absolute;left:124.80px;top:598.01px" class="cls_017"><span class="cls_017">5.3.2</span></div>
<div style="position:absolute;left:165.90px;top:598.01px" class="cls_017"><span class="cls_017">Setting MinPts values</span></div>
<div style="position:absolute;left:124.80px;top:618.39px" class="cls_008"><span class="cls_008">While the eps parameter required to calculate the k-dist distance for every</span></div>
<div style="position:absolute;left:124.80px;top:630.35px" class="cls_008"><span class="cls_008">point in a dataset, the suggested way to set M inP ts is more straight-forward.</span></div>
<div style="position:absolute;left:124.80px;top:642.30px" class="cls_008"><span class="cls_008">The "DBSCAN revisited" paper [19] simply purposes to set the default M inP ts</span></div>
<div style="position:absolute;left:124.80px;top:654.26px" class="cls_008"><span class="cls_008">parameter for 2-dimensional data to 4, and 2 times dimension for n-dimensional</span></div>
<div style="position:absolute;left:124.80px;top:666.21px" class="cls_008"><span class="cls_008">data.  As we only apply this algorithm to 3-dimensional data and higher, we</span></div>
<div style="position:absolute;left:124.80px;top:678.17px" class="cls_008"><span class="cls_008">will use the latter suggestion.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">54</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:48507px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background058.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:122.92px" class="cls_017"><span class="cls_017">5.3.3</span></div>
<div style="position:absolute;left:165.90px;top:122.92px" class="cls_017"><span class="cls_017">Output</span></div>
<div style="position:absolute;left:124.80px;top:143.30px" class="cls_008"><span class="cls_008">The output of the algorithm gives us indices of each data point and which cluster</span></div>
<div style="position:absolute;left:124.80px;top:155.25px" class="cls_008"><span class="cls_008">it is assigned to. We used the Counter method from Python collections library</span></div>
<div style="position:absolute;left:124.80px;top:167.21px" class="cls_008"><span class="cls_008">to get a initial view of how many clusters the data was assigned, and the amount</span></div>
<div style="position:absolute;left:124.80px;top:179.16px" class="cls_008"><span class="cls_008">of data points in each cluster.</span></div>
<div style="position:absolute;left:139.75px;top:191.12px" class="cls_008"><span class="cls_008">As shown in example output of DBSCAN in figure 5.23, we observe a dictio-</span></div>
<div style="position:absolute;left:124.80px;top:203.07px" class="cls_008"><span class="cls_008">nary with keys and values. The keys represents a cluster, where -1 is appointed</span></div>
<div style="position:absolute;left:124.80px;top:215.03px" class="cls_008"><span class="cls_008">noise or outliers. In this example, the main cluster 0 includes 88484 data points,</span></div>
<div style="position:absolute;left:124.80px;top:226.98px" class="cls_008"><span class="cls_008">while -1 (representing noise) includes 399 data points.  The other keys corre-</span></div>
<div style="position:absolute;left:124.80px;top:238.94px" class="cls_008"><span class="cls_008">spond to additional distinct clusters with their amount of data points.</span></div>
<div style="position:absolute;left:223.93px;top:312.10px" class="cls_008"><span class="cls_008">Figure 5.23: Output of DBSCAN</span></div>
<div style="position:absolute;left:124.80px;top:354.21px" class="cls_010"><span class="cls_010">5.4</span></div>
<div style="position:absolute;left:161.56px;top:354.21px" class="cls_010"><span class="cls_010">Implementation of Local Outlier Factor</span></div>
<div style="position:absolute;left:124.80px;top:380.42px" class="cls_008"><span class="cls_008">The LOF algorithm was implemented and ran with the Scikit-learn neighbors</span></div>
<div style="position:absolute;left:124.80px;top:392.37px" class="cls_008"><span class="cls_008">module. Similarly to all the other algorithms implemented, the only input fed</span></div>
<div style="position:absolute;left:124.80px;top:404.33px" class="cls_008"><span class="cls_008">to the LOF class was the data itself, prepossessed with scaling and normaliza-</span></div>
<div style="position:absolute;left:124.80px;top:416.28px" class="cls_008"><span class="cls_008">tion.  In addition, Principal Component Analysis (PCA) was applied in order</span></div>
<div style="position:absolute;left:124.80px;top:428.24px" class="cls_008"><span class="cls_008">to remove redundant data, and for visualization purposes.</span></div>
<div style="position:absolute;left:139.75px;top:440.19px" class="cls_008"><span class="cls_008">For the LOF algorithm, there are several optional parameters for setting</span></div>
<div style="position:absolute;left:124.80px;top:452.15px" class="cls_008"><span class="cls_008">distance-metric, contamination (percentage of outlier data) etc.  but only one</span></div>
<div style="position:absolute;left:124.80px;top:464.10px" class="cls_008"><span class="cls_008">mandatory parameter (n-neighbors) which needs to be tuned. For the distance-</span></div>
<div style="position:absolute;left:124.80px;top:476.06px" class="cls_008"><span class="cls_008">metric we used euclidean distance.</span></div>
<div style="position:absolute;left:124.80px;top:501.95px" class="cls_017"><span class="cls_017">5.4.1</span></div>
<div style="position:absolute;left:165.90px;top:501.95px" class="cls_017"><span class="cls_017">Setting n-neighbors parameter</span></div>
<div style="position:absolute;left:124.80px;top:522.34px" class="cls_008"><span class="cls_008">This parameter defines the amount of neighbors to a point, to calculate its local</span></div>
<div style="position:absolute;left:124.80px;top:534.29px" class="cls_008"><span class="cls_008">density with.  I.e.  if we set this parameter to 3, all points in the data set will</span></div>
<div style="position:absolute;left:124.80px;top:546.25px" class="cls_008"><span class="cls_008">compare its local density with the 3 nearest-neighbors, as explained in chapter</span></div>
<div style="position:absolute;left:124.80px;top:558.20px" class="cls_008"><span class="cls_008">3.4.</span></div>
<div style="position:absolute;left:124.80px;top:584.10px" class="cls_017"><span class="cls_017">5.4.2</span></div>
<div style="position:absolute;left:165.90px;top:584.10px" class="cls_017"><span class="cls_017">Setting contamination parameter</span></div>
<div style="position:absolute;left:124.80px;top:604.48px" class="cls_008"><span class="cls_008">In short, the contamination parameter defines the amount of data points to</span></div>
<div style="position:absolute;left:124.80px;top:616.43px" class="cls_008"><span class="cls_008">categorize as outliers. Setting this parameter to 0.05, the algorithm labels data</span></div>
<div style="position:absolute;left:124.80px;top:628.39px" class="cls_008"><span class="cls_008">points with the 5% highest LOF-score as outliers.</span></div>
<div style="position:absolute;left:124.80px;top:654.28px" class="cls_017"><span class="cls_017">5.4.3</span></div>
<div style="position:absolute;left:165.90px;top:654.28px" class="cls_017"><span class="cls_017">Output</span></div>
<div style="position:absolute;left:124.80px;top:674.67px" class="cls_008"><span class="cls_008">The LOF algorithm returns two outputs, a list of the local outlier factor (neg-</span></div>
<div style="position:absolute;left:124.80px;top:686.62px" class="cls_008"><span class="cls_008">ative_outlier_factor ) to each data point, as well as a list of binary labels that</span></div>
<div style="position:absolute;left:124.80px;top:698.58px" class="cls_008"><span class="cls_008">describe points as either inlier or outlier (normal or abnormal).</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">55</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:49358px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background059.jpg" width=595 height=841></div>
<div style="position:absolute;left:139.75px;top:124.91px" class="cls_008"><span class="cls_008">We used this local outlier factor of the data points to get a visual repre-</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">sentation of the score that each observation had. The bigger the radius of the</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">observation, the higher the LOF-score. A subset of the data was ran with LOF</span></div>
<div style="position:absolute;left:124.80px;top:160.77px" class="cls_008"><span class="cls_008">to illustrate how we used the output to visualize the LOF-score and the classified</span></div>
<div style="position:absolute;left:124.80px;top:172.73px" class="cls_008"><span class="cls_008">labels.</span></div>
<div style="position:absolute;left:139.75px;top:184.68px" class="cls_008"><span class="cls_008">In figure 5.24, a subset of the data was plotted in 2-dimensions with respect</span></div>
<div style="position:absolute;left:124.80px;top:196.64px" class="cls_008"><span class="cls_008">to the three features, hours worked, FTE percentage, and total income.  The</span></div>
<div style="position:absolute;left:124.80px;top:208.59px" class="cls_008"><span class="cls_008">blue dots are labeled as outliers, while the yellow dots are labeled as inliers. The</span></div>
<div style="position:absolute;left:124.80px;top:220.55px" class="cls_008"><span class="cls_008">red circles surrounding the points illustrates the LOF-score of each observation.</span></div>
<div style="position:absolute;left:124.80px;top:389.02px" class="cls_008"><span class="cls_008">Figure 5.24: 2D plane representation of LOF-scores of each data point. Ran on</span></div>
<div style="position:absolute;left:124.80px;top:400.97px" class="cls_008"><span class="cls_008">a small sampled dataset with three features.</span></div>
<div style="position:absolute;left:139.75px;top:438.43px" class="cls_008"><span class="cls_008">We se that the red circles surrounding the blue dots have a larger radius as</span></div>
<div style="position:absolute;left:124.80px;top:450.39px" class="cls_008"><span class="cls_008">a result of being labeled as outliers. In figure 5.25, we find similar observations</span></div>
<div style="position:absolute;left:124.80px;top:462.34px" class="cls_008"><span class="cls_008">in three dimensions.</span></div>
<div style="position:absolute;left:124.80px;top:663.35px" class="cls_008"><span class="cls_008">Figure 5.25: 3D plane representation of LOF-scores of each data point. Ran on</span></div>
<div style="position:absolute;left:124.80px;top:675.30px" class="cls_008"><span class="cls_008">a small sampled dataset with three features.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">56</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:50209px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background060.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:120.52px" class="cls_010"><span class="cls_010">5.5</span></div>
<div style="position:absolute;left:161.56px;top:120.52px" class="cls_010"><span class="cls_010">Implementation of AprioriRare</span></div>
<div style="position:absolute;left:124.80px;top:146.73px" class="cls_008"><span class="cls_008">For our Rare Itemset Mining implementation we used an open-source data min-</span></div>
<div style="position:absolute;left:124.80px;top:158.68px" class="cls_008"><span class="cls_008">ing library in Java called SPMF, developed by Philippe Fournier-Viger [16]. We</span></div>
<div style="position:absolute;left:124.80px;top:170.64px" class="cls_008"><span class="cls_008">used the algorithm AprioriRare. The input of this algorithm is a Transactional</span></div>
<div style="position:absolute;left:124.80px;top:182.59px" class="cls_008"><span class="cls_008">Database T</span><span class="cls_018"><sub>d</sub></span><span class="cls_008">  that consists of several itemsets I = {i</span><span class="cls_018"><sub>1</sub></span><span class="cls_008">, i</span><span class="cls_018"><sub>2</sub></span><span class="cls_008">, ..., i</span><span class="cls_018"><sub>n</sub></span><span class="cls_008">} for n features.</span></div>
<div style="position:absolute;left:124.80px;top:194.55px" class="cls_008"><span class="cls_008">Each item i is a specific value in a numeric column in the database.  Every</span></div>
<div style="position:absolute;left:124.80px;top:206.51px" class="cls_008"><span class="cls_008">transaction requires no duplicate values and must be sorted in lexicographical</span></div>
<div style="position:absolute;left:124.80px;top:218.46px" class="cls_008"><span class="cls_008">order.</span></div>
<div style="position:absolute;left:124.80px;top:244.36px" class="cls_017"><span class="cls_017">5.5.1</span></div>
<div style="position:absolute;left:165.90px;top:244.36px" class="cls_017"><span class="cls_017">Quantization</span></div>
<div style="position:absolute;left:124.80px;top:264.74px" class="cls_008"><span class="cls_008">This meant we had to develop a script to transform our detailed CSV file into a</span></div>
<div style="position:absolute;left:124.80px;top:276.69px" class="cls_008"><span class="cls_008">compatible input for the algorithm. We achieved this by splitting the values into</span></div>
<div style="position:absolute;left:124.80px;top:288.65px" class="cls_008"><span class="cls_008">quantiles, using the Pandas qcut()-method. This distributes the large number of</span></div>
<div style="position:absolute;left:124.80px;top:300.60px" class="cls_008"><span class="cls_008">discrete values into evenly split percentages, normalizing the data in the process.</span></div>
<div style="position:absolute;left:124.80px;top:312.56px" class="cls_008"><span class="cls_008">The extreme fringe points are collected in the top and bottom categories, while</span></div>
<div style="position:absolute;left:124.80px;top:324.51px" class="cls_008"><span class="cls_008">most of the more common data points are somewhere in the middle. By adding</span></div>
<div style="position:absolute;left:124.80px;top:336.47px" class="cls_008"><span class="cls_008">a different constant to each field, we ensured that they would always be sorted</span></div>
<div style="position:absolute;left:124.80px;top:348.42px" class="cls_008"><span class="cls_008">in ascending order, meaning the first value would be between 0-99, the next</span></div>
<div style="position:absolute;left:124.80px;top:360.38px" class="cls_008"><span class="cls_008">between 100-199, and so on (see figure 5.26).  In our case, we further split</span></div>
<div style="position:absolute;left:124.80px;top:372.33px" class="cls_008"><span class="cls_008">the FTE percentage into 10% chunks, placing negative values in the smallest</span></div>
<div style="position:absolute;left:124.80px;top:384.29px" class="cls_008"><span class="cls_008">category and values over 100% in the largest category.  See examples of this</span></div>
<div style="position:absolute;left:124.80px;top:396.24px" class="cls_008"><span class="cls_008">process in figures 5.27 and 5.28:</span></div>
<div style="position:absolute;left:218.51px;top:585.28px" class="cls_008"><span class="cls_008">Figure 5.26: Splitting into quantiles</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">57</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:51060px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background061.jpg" width=595 height=841></div>
<div style="position:absolute;left:270.28px;top:123.83px" class="cls_020"><span class="cls_020">Original input</span></div>
<div style="position:absolute;left:195.28px;top:134.94px" class="cls_020"><span class="cls_020">AntallTimer</span></div>
<div style="position:absolute;left:254.65px;top:134.94px" class="cls_020"><span class="cls_020">Stillingsprosent</span></div>
<div style="position:absolute;left:325.80px;top:134.94px" class="cls_020"><span class="cls_020">Totalinntekt</span></div>
<div style="position:absolute;left:385.40px;top:134.94px" class="cls_020"><span class="cls_020">Forskuddstrekk</span></div>
<div style="position:absolute;left:164.12px;top:146.04px" class="cls_020"><span class="cls_020">0</span></div>
<div style="position:absolute;left:206.98px;top:146.04px" class="cls_020"><span class="cls_020">162.38</span></div>
<div style="position:absolute;left:274.48px;top:146.04px" class="cls_020"><span class="cls_020">100.0</span></div>
<div style="position:absolute;left:333.14px;top:146.04px" class="cls_020"><span class="cls_020">42246.50</span></div>
<div style="position:absolute;left:402.82px;top:146.04px" class="cls_020"><span class="cls_020">-13846</span></div>
<div style="position:absolute;left:164.12px;top:156.78px" class="cls_020"><span class="cls_020">1</span></div>
<div style="position:absolute;left:206.98px;top:156.78px" class="cls_020"><span class="cls_020">162.38</span></div>
<div style="position:absolute;left:274.48px;top:156.78px" class="cls_020"><span class="cls_020">100.0</span></div>
<div style="position:absolute;left:333.14px;top:156.78px" class="cls_020"><span class="cls_020">39317.00</span></div>
<div style="position:absolute;left:402.82px;top:156.78px" class="cls_020"><span class="cls_020">-13760</span></div>
<div style="position:absolute;left:164.12px;top:167.52px" class="cls_020"><span class="cls_020">2</span></div>
<div style="position:absolute;left:206.98px;top:167.52px" class="cls_020"><span class="cls_020">162.38</span></div>
<div style="position:absolute;left:274.48px;top:167.52px" class="cls_020"><span class="cls_020">100.0</span></div>
<div style="position:absolute;left:333.14px;top:167.52px" class="cls_020"><span class="cls_020">38400.00</span></div>
<div style="position:absolute;left:402.82px;top:167.52px" class="cls_020"><span class="cls_020">-11313</span></div>
<div style="position:absolute;left:164.12px;top:178.27px" class="cls_020"><span class="cls_020">3</span></div>
<div style="position:absolute;left:206.98px;top:178.27px" class="cls_020"><span class="cls_020">162.38</span></div>
<div style="position:absolute;left:274.48px;top:178.27px" class="cls_020"><span class="cls_020">100.0</span></div>
<div style="position:absolute;left:333.14px;top:178.27px" class="cls_020"><span class="cls_020">38740.50</span></div>
<div style="position:absolute;left:402.82px;top:178.27px" class="cls_020"><span class="cls_020">-11034</span></div>
<div style="position:absolute;left:164.12px;top:189.01px" class="cls_020"><span class="cls_020">4</span></div>
<div style="position:absolute;left:206.98px;top:189.01px" class="cls_020"><span class="cls_020">162.38</span></div>
<div style="position:absolute;left:274.48px;top:189.01px" class="cls_020"><span class="cls_020">100.0</span></div>
<div style="position:absolute;left:335.38px;top:189.01px" class="cls_020"><span class="cls_020">8593.50</span></div>
<div style="position:absolute;left:407.29px;top:189.01px" class="cls_020"><span class="cls_020">-860</span></div>
<div style="position:absolute;left:150.69px;top:216.45px" class="cls_020"><span class="cls_020">7967194</span></div>
<div style="position:absolute;left:206.98px;top:216.45px" class="cls_020"><span class="cls_020">126.60</span></div>
<div style="position:absolute;left:274.48px;top:216.45px" class="cls_020"><span class="cls_020">100.0</span></div>
<div style="position:absolute;left:333.14px;top:216.45px" class="cls_020"><span class="cls_020">28756.00</span></div>
<div style="position:absolute;left:405.06px;top:216.45px" class="cls_020"><span class="cls_020">-7071</span></div>
<div style="position:absolute;left:150.69px;top:227.20px" class="cls_020"><span class="cls_020">7967195</span></div>
<div style="position:absolute;left:206.98px;top:227.20px" class="cls_020"><span class="cls_020">122.65</span></div>
<div style="position:absolute;left:274.48px;top:227.20px" class="cls_020"><span class="cls_020">100.0</span></div>
<div style="position:absolute;left:333.14px;top:227.20px" class="cls_020"><span class="cls_020">27317.80</span></div>
<div style="position:absolute;left:405.06px;top:227.20px" class="cls_020"><span class="cls_020">-9307</span></div>
<div style="position:absolute;left:150.69px;top:237.94px" class="cls_020"><span class="cls_020">7967196</span></div>
<div style="position:absolute;left:206.98px;top:237.94px" class="cls_020"><span class="cls_020">126.42</span></div>
<div style="position:absolute;left:274.48px;top:237.94px" class="cls_020"><span class="cls_020">100.0</span></div>
<div style="position:absolute;left:333.14px;top:237.94px" class="cls_020"><span class="cls_020">28505.21</span></div>
<div style="position:absolute;left:405.06px;top:237.94px" class="cls_020"><span class="cls_020">-6164</span></div>
<div style="position:absolute;left:150.69px;top:248.68px" class="cls_020"><span class="cls_020">7967197</span></div>
<div style="position:absolute;left:209.22px;top:248.68px" class="cls_020"><span class="cls_020">82.47</span></div>
<div style="position:absolute;left:274.48px;top:248.68px" class="cls_020"><span class="cls_020">100.0</span></div>
<div style="position:absolute;left:333.14px;top:248.68px" class="cls_020"><span class="cls_020">19827.43</span></div>
<div style="position:absolute;left:405.06px;top:248.68px" class="cls_020"><span class="cls_020">-4280</span></div>
<div style="position:absolute;left:150.69px;top:259.42px" class="cls_020"><span class="cls_020">7967198</span></div>
<div style="position:absolute;left:209.22px;top:259.42px" class="cls_020"><span class="cls_020">37.50</span></div>
<div style="position:absolute;left:274.48px;top:259.42px" class="cls_020"><span class="cls_020">100.0</span></div>
<div style="position:absolute;left:335.38px;top:259.42px" class="cls_020"><span class="cls_020">9730.17</span></div>
<div style="position:absolute;left:405.06px;top:259.42px" class="cls_020"><span class="cls_020">-1483</span></div>
<div style="position:absolute;left:241.30px;top:280.33px" class="cls_008"><span class="cls_008">Figure 5.27: Unprocessed</span></div>
<div style="position:absolute;left:266.69px;top:317.71px" class="cls_020"><span class="cls_020">Quantile output</span></div>
<div style="position:absolute;left:195.28px;top:328.81px" class="cls_020"><span class="cls_020">AntallTimer</span></div>
<div style="position:absolute;left:254.65px;top:328.81px" class="cls_020"><span class="cls_020">Stillingsprosent</span></div>
<div style="position:absolute;left:325.80px;top:328.81px" class="cls_020"><span class="cls_020">Totalinntekt</span></div>
<div style="position:absolute;left:385.40px;top:328.81px" class="cls_020"><span class="cls_020">Forskuddstrekk</span></div>
<div style="position:absolute;left:164.12px;top:339.91px" class="cls_020"><span class="cls_020">0</span></div>
<div style="position:absolute;left:214.94px;top:339.91px" class="cls_020"><span class="cls_020">43</span></div>
<div style="position:absolute;left:277.96px;top:339.91px" class="cls_020"><span class="cls_020">110</span></div>
<div style="position:absolute;left:343.34px;top:339.91px" class="cls_020"><span class="cls_020">253</span></div>
<div style="position:absolute;left:408.79px;top:339.91px" class="cls_020"><span class="cls_020">335</span></div>
<div style="position:absolute;left:164.12px;top:350.65px" class="cls_020"><span class="cls_020">1</span></div>
<div style="position:absolute;left:214.94px;top:350.65px" class="cls_020"><span class="cls_020">43</span></div>
<div style="position:absolute;left:277.96px;top:350.65px" class="cls_020"><span class="cls_020">110</span></div>
<div style="position:absolute;left:343.34px;top:350.65px" class="cls_020"><span class="cls_020">247</span></div>
<div style="position:absolute;left:408.79px;top:350.65px" class="cls_020"><span class="cls_020">335</span></div>
<div style="position:absolute;left:164.12px;top:361.40px" class="cls_020"><span class="cls_020">2</span></div>
<div style="position:absolute;left:214.94px;top:361.40px" class="cls_020"><span class="cls_020">43</span></div>
<div style="position:absolute;left:277.96px;top:361.40px" class="cls_020"><span class="cls_020">110</span></div>
<div style="position:absolute;left:343.34px;top:361.40px" class="cls_020"><span class="cls_020">246</span></div>
<div style="position:absolute;left:408.79px;top:361.40px" class="cls_020"><span class="cls_020">345</span></div>
<div style="position:absolute;left:164.12px;top:372.14px" class="cls_020"><span class="cls_020">3</span></div>
<div style="position:absolute;left:214.94px;top:372.14px" class="cls_020"><span class="cls_020">43</span></div>
<div style="position:absolute;left:277.96px;top:372.14px" class="cls_020"><span class="cls_020">110</span></div>
<div style="position:absolute;left:343.34px;top:372.14px" class="cls_020"><span class="cls_020">246</span></div>
<div style="position:absolute;left:408.79px;top:372.14px" class="cls_020"><span class="cls_020">346</span></div>
<div style="position:absolute;left:164.12px;top:382.88px" class="cls_020"><span class="cls_020">4</span></div>
<div style="position:absolute;left:214.94px;top:382.88px" class="cls_020"><span class="cls_020">43</span></div>
<div style="position:absolute;left:277.96px;top:382.88px" class="cls_020"><span class="cls_020">110</span></div>
<div style="position:absolute;left:343.34px;top:382.88px" class="cls_020"><span class="cls_020">213</span></div>
<div style="position:absolute;left:408.79px;top:382.88px" class="cls_020"><span class="cls_020">383</span></div>
<div style="position:absolute;left:150.69px;top:410.33px" class="cls_020"><span class="cls_020">7967194</span></div>
<div style="position:absolute;left:214.94px;top:410.33px" class="cls_020"><span class="cls_020">29</span></div>
<div style="position:absolute;left:277.96px;top:410.33px" class="cls_020"><span class="cls_020">110</span></div>
<div style="position:absolute;left:343.34px;top:410.33px" class="cls_020"><span class="cls_020">230</span></div>
<div style="position:absolute;left:408.79px;top:410.33px" class="cls_020"><span class="cls_020">362</span></div>
<div style="position:absolute;left:150.69px;top:421.07px" class="cls_020"><span class="cls_020">7967195</span></div>
<div style="position:absolute;left:214.94px;top:421.07px" class="cls_020"><span class="cls_020">28</span></div>
<div style="position:absolute;left:277.96px;top:421.07px" class="cls_020"><span class="cls_020">110</span></div>
<div style="position:absolute;left:343.34px;top:421.07px" class="cls_020"><span class="cls_020">229</span></div>
<div style="position:absolute;left:408.79px;top:421.07px" class="cls_020"><span class="cls_020">354</span></div>
<div style="position:absolute;left:150.69px;top:431.81px" class="cls_020"><span class="cls_020">7967196</span></div>
<div style="position:absolute;left:214.94px;top:431.81px" class="cls_020"><span class="cls_020">29</span></div>
<div style="position:absolute;left:277.96px;top:431.81px" class="cls_020"><span class="cls_020">110</span></div>
<div style="position:absolute;left:343.34px;top:431.81px" class="cls_020"><span class="cls_020">230</span></div>
<div style="position:absolute;left:408.79px;top:431.81px" class="cls_020"><span class="cls_020">365</span></div>
<div style="position:absolute;left:150.69px;top:442.55px" class="cls_020"><span class="cls_020">7967197</span></div>
<div style="position:absolute;left:214.94px;top:442.55px" class="cls_020"><span class="cls_020">22</span></div>
<div style="position:absolute;left:277.96px;top:442.55px" class="cls_020"><span class="cls_020">110</span></div>
<div style="position:absolute;left:343.34px;top:442.55px" class="cls_020"><span class="cls_020">223</span></div>
<div style="position:absolute;left:408.79px;top:442.55px" class="cls_020"><span class="cls_020">371</span></div>
<div style="position:absolute;left:150.69px;top:453.30px" class="cls_020"><span class="cls_020">7967198</span></div>
<div style="position:absolute;left:214.94px;top:453.30px" class="cls_020"><span class="cls_020">13</span></div>
<div style="position:absolute;left:277.96px;top:453.30px" class="cls_020"><span class="cls_020">110</span></div>
<div style="position:absolute;left:343.34px;top:453.30px" class="cls_020"><span class="cls_020">214</span></div>
<div style="position:absolute;left:408.79px;top:453.30px" class="cls_020"><span class="cls_020">380</span></div>
<div style="position:absolute;left:247.18px;top:474.20px" class="cls_008"><span class="cls_008">Figure 5.28: Processed</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">58</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:51911px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background062.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:122.92px" class="cls_017"><span class="cls_017">5.5.2</span></div>
<div style="position:absolute;left:165.90px;top:122.92px" class="cls_017"><span class="cls_017">Setting values</span></div>
<div style="position:absolute;left:124.80px;top:143.30px" class="cls_008"><span class="cls_008">We then ran AprioriRare as described in figure 5.29. As the algorithm only looks</span></div>
<div style="position:absolute;left:124.80px;top:155.25px" class="cls_008"><span class="cls_008">at the combinations of items in a set, the individual values can be represented</span></div>
<div style="position:absolute;left:124.80px;top:167.21px" class="cls_008"><span class="cls_008">arbitrarily, and the index is used to reference the actual value after running</span></div>
<div style="position:absolute;left:124.80px;top:179.16px" class="cls_008"><span class="cls_008">the algorithm. We have opted to limit the results to itemset combinations with</span></div>
<div style="position:absolute;left:124.80px;top:191.12px" class="cls_008"><span class="cls_008">a single occurrence, selecting minimal support values to meet a threshold for</span></div>
<div style="position:absolute;left:124.80px;top:203.07px" class="cls_008"><span class="cls_008">anomalies of approx. 1-2% of the total data. This is a threshold we decided to</span></div>
<div style="position:absolute;left:124.80px;top:215.03px" class="cls_008"><span class="cls_008">aim for for all the algorithms, the intuition being that if it occurs more often</span></div>
<div style="position:absolute;left:124.80px;top:226.98px" class="cls_008"><span class="cls_008">than this, it is less likely to be considered an anomaly.  At the end we filter</span></div>
<div style="position:absolute;left:124.80px;top:238.94px" class="cls_008"><span class="cls_008">the output further, sorting the values and removing duplicates, until the final</span></div>
<div style="position:absolute;left:124.80px;top:250.89px" class="cls_008"><span class="cls_008">results is the list of indices of the data points flagged as anomalies. This list is</span></div>
<div style="position:absolute;left:124.80px;top:262.85px" class="cls_008"><span class="cls_008">then used to find the actual data in the original CSV file.</span></div>
<div style="position:absolute;left:219.05px;top:367.05px" class="cls_008"><span class="cls_008">Figure 5.29: Executing AprioriRare</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">59</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:52762px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background063.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:188.93px" class="cls_011"><span class="cls_011">Chapter 6</span></div>
<div style="position:absolute;left:124.80px;top:234.62px" class="cls_009"><span class="cls_009">Results and Experiments</span></div>
<div style="position:absolute;left:124.80px;top:301.25px" class="cls_008"><span class="cls_008">This chapter contains an in depth look and analysis of the results for the four</span></div>
<div style="position:absolute;left:124.80px;top:313.20px" class="cls_008"><span class="cls_008">different algorithms:  K-means, DBSCAN, LOF and AprioriRare.  The results</span></div>
<div style="position:absolute;left:124.80px;top:325.16px" class="cls_008"><span class="cls_008">are based on datasets with three, four and five features extracted from the A-</span></div>
<div style="position:absolute;left:124.80px;top:337.11px" class="cls_008"><span class="cls_008">meldings. In this chapter, the y-axis of the histograms represents the frequency</span></div>
<div style="position:absolute;left:124.80px;top:349.07px" class="cls_008"><span class="cls_008">of the distribution.</span></div>
<div style="position:absolute;left:124.80px;top:377.63px" class="cls_010"><span class="cls_010">6.1</span></div>
<div style="position:absolute;left:161.56px;top:377.63px" class="cls_010"><span class="cls_010">Results - K-means</span></div>
<div style="position:absolute;left:124.80px;top:403.83px" class="cls_008"><span class="cls_008">Before looking at the results we expected that K-means would mainly find out-</span></div>
<div style="position:absolute;left:124.80px;top:415.79px" class="cls_008"><span class="cls_008">liers outside of where most of the data points were concentrated. Since we have</span></div>
<div style="position:absolute;left:124.80px;top:427.74px" class="cls_008"><span class="cls_008">based the outlier detection on how far points are from their cluster center, com-</span></div>
<div style="position:absolute;left:124.80px;top:439.70px" class="cls_008"><span class="cls_008">pared to the average distance for the cluster, we suspect that we will mostly</span></div>
<div style="position:absolute;left:124.80px;top:451.66px" class="cls_008"><span class="cls_008">find outliers where one or more of the features either have a really high or a</span></div>
<div style="position:absolute;left:124.80px;top:463.61px" class="cls_008"><span class="cls_008">really low value. Ideally we would be able to find some outliers among the main</span></div>
<div style="position:absolute;left:124.80px;top:475.57px" class="cls_008"><span class="cls_008">concentration of data points, but after seeing how the data looked and how the</span></div>
<div style="position:absolute;left:124.80px;top:487.52px" class="cls_008"><span class="cls_008">cluster formed after running K-means this seemed unlikely.</span></div>
<div style="position:absolute;left:139.75px;top:499.48px" class="cls_008"><span class="cls_008">For K-means we assume that for both three and four features we will find</span></div>
<div style="position:absolute;left:124.80px;top:511.43px" class="cls_008"><span class="cls_008">many of the same data points as the fourth feature (prepayment deductions) is</span></div>
<div style="position:absolute;left:124.80px;top:523.39px" class="cls_008"><span class="cls_008">supposed to be highly related to the total income feature, they both had the</span></div>
<div style="position:absolute;left:124.80px;top:535.34px" class="cls_008"><span class="cls_008">same clusters k = 2 and we used the same, 4 × averageDistance metric for</span></div>
<div style="position:absolute;left:124.80px;top:547.30px" class="cls_008"><span class="cls_008">marking them as outliers. For five features we suspect that we will get different</span></div>
<div style="position:absolute;left:124.80px;top:559.25px" class="cls_008"><span class="cls_008">results, as mentioned in chapter 5.2.</span></div>
<div style="position:absolute;left:124.80px;top:585.15px" class="cls_017"><span class="cls_017">6.1.1</span></div>
<div style="position:absolute;left:165.90px;top:585.15px" class="cls_017"><span class="cls_017">Three features</span></div>
<div style="position:absolute;left:124.80px;top:605.53px" class="cls_008"><span class="cls_008">When using K-means for anomaly detection on the three features total income,</span></div>
<div style="position:absolute;left:124.80px;top:617.48px" class="cls_008"><span class="cls_008">FTE percentage and hours worked for 100.000 data points we ended up with</span></div>
<div style="position:absolute;left:124.80px;top:629.44px" class="cls_008"><span class="cls_008">913 of those registered as outliers. Instead of looking at each point individually</span></div>
<div style="position:absolute;left:124.80px;top:641.39px" class="cls_008"><span class="cls_008">we created histograms, both for the ones registered as outliers and the ones not,</span></div>
<div style="position:absolute;left:124.80px;top:653.35px" class="cls_008"><span class="cls_008">to show the frequency of values and to analyze for what values of each feature</span></div>
<div style="position:absolute;left:124.80px;top:665.31px" class="cls_008"><span class="cls_008">we commonly get registered outliers.</span></div>
<div style="position:absolute;left:139.75px;top:677.26px" class="cls_008"><span class="cls_008">Since some of the values for our features are many times larger than the</span></div>
<div style="position:absolute;left:124.80px;top:689.22px" class="cls_008"><span class="cls_008">rest the histograms will be very skewed and unreadable. To counteract this we</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">60</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:53613px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background064.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">adjusted the top and bottom 1% of the values for each feature to a set max (the</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">top 0.99 quantile) and min value (the bottom 0.01 quantile).</span></div>
<div style="position:absolute;left:149.07px;top:320.96px" class="cls_008"><span class="cls_008">Figure 6.1: Histogram of inliers and outliers related to total income</span></div>
<div style="position:absolute;left:139.75px;top:358.31px" class="cls_008"><span class="cls_008">When comparing the two histograms for total income (Figure 6.1) we see</span></div>
<div style="position:absolute;left:124.80px;top:370.27px" class="cls_008"><span class="cls_008">that although the majority of the income values are in the 0-100000 region, most</span></div>
<div style="position:absolute;left:124.80px;top:382.22px" class="cls_008"><span class="cls_008">of the registered outliers occur when the income is much higher. Based on how</span></div>
<div style="position:absolute;left:124.80px;top:394.18px" class="cls_008"><span class="cls_008">we have implemented k-means for registering outliers it makes sense to mark</span></div>
<div style="position:absolute;left:124.80px;top:406.13px" class="cls_008"><span class="cls_008">abnormally high values as outliers. Because of this we can assume that most of</span></div>
<div style="position:absolute;left:124.80px;top:418.09px" class="cls_008"><span class="cls_008">these are even higher than 175.000 and were among the ones that got reduced</span></div>
<div style="position:absolute;left:124.80px;top:430.04px" class="cls_008"><span class="cls_008">when we adjusted the top 1%.</span></div>
<div style="position:absolute;left:141.03px;top:613.58px" class="cls_008"><span class="cls_008">Figure 6.2: Histogram of inliers and outliers related to FTE percentage</span></div>
<div style="position:absolute;left:139.75px;top:650.94px" class="cls_008"><span class="cls_008">Next, when looking at the histogram related to FTE percentage (Figure 6.2),</span></div>
<div style="position:absolute;left:124.80px;top:662.89px" class="cls_008"><span class="cls_008">it is apparent that a very large majority has 100% specified as their percentage</span></div>
<div style="position:absolute;left:124.80px;top:674.85px" class="cls_008"><span class="cls_008">of employment. Because of this a lot of our outliers occur when their percentage</span></div>
<div style="position:absolute;left:124.80px;top:686.80px" class="cls_008"><span class="cls_008">of employment is 100%.  From beforehand, when analyzing our data, we saw</span></div>
<div style="position:absolute;left:124.80px;top:698.76px" class="cls_008"><span class="cls_008">that some data points had an abnormally high FTE percentage so its likely</span></div>
<div style="position:absolute;left:124.80px;top:710.71px" class="cls_008"><span class="cls_008">that some of these are in the 100% bin, but were reduced when making the</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">61</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:54464px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background065.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">histograms. The other major occurrence of outliers are when the percentage of</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">employment is 0%. From earlier data analysis we know that most data points</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">with 0% also have zero or a low number for their total income and hours worked.</span></div>
<div style="position:absolute;left:124.80px;top:160.77px" class="cls_008"><span class="cls_008">Based on this we can make the assumption that a lot of the outliers with 0%</span></div>
<div style="position:absolute;left:124.80px;top:172.73px" class="cls_008"><span class="cls_008">probably have an uncommonly high total income, hours worked or both.</span></div>
<div style="position:absolute;left:147.22px;top:356.38px" class="cls_008"><span class="cls_008">Figure 6.3: Histogram of inliers and outliers related to hours worked</span></div>
<div style="position:absolute;left:139.75px;top:383.87px" class="cls_008"><span class="cls_008">Lastly, when looking at hours worked (Figure 6.3) we see that most data</span></div>
<div style="position:absolute;left:124.80px;top:395.83px" class="cls_008"><span class="cls_008">points are registered with right above 150 hours. Since the standard month of</span></div>
<div style="position:absolute;left:124.80px;top:407.78px" class="cls_008"><span class="cls_008">work is considered 162,5 hours it is logical that this is the range where we find</span></div>
<div style="position:absolute;left:124.80px;top:419.74px" class="cls_008"><span class="cls_008">the majority of data points and by extension also most of the outliers. We also</span></div>
<div style="position:absolute;left:124.80px;top:431.69px" class="cls_008"><span class="cls_008">see that outliers are found either when hours worked is around zero or when</span></div>
<div style="position:absolute;left:124.80px;top:443.65px" class="cls_008"><span class="cls_008">it is really high.  The outliers for when hours worked is zero makes sense as</span></div>
<div style="position:absolute;left:124.80px;top:455.60px" class="cls_008"><span class="cls_008">potential anomalies if they have a high value for either total income or FTE</span></div>
<div style="position:absolute;left:124.80px;top:467.56px" class="cls_008"><span class="cls_008">percentage as it’s unlikely that someone with zero hours worked has a high</span></div>
<div style="position:absolute;left:124.80px;top:479.51px" class="cls_008"><span class="cls_008">income or percentage of employment. The high values are probably registered</span></div>
<div style="position:absolute;left:124.80px;top:491.47px" class="cls_008"><span class="cls_008">because they are very high, and although 300 hours worked a month, almost 14</span></div>
<div style="position:absolute;left:124.80px;top:503.42px" class="cls_008"><span class="cls_008">hours per day, might not be impossibly high a lot of these are probably higher</span></div>
<div style="position:absolute;left:124.80px;top:515.38px" class="cls_008"><span class="cls_008">and have been cut for the histograms.</span></div>
<div style="position:absolute;left:139.75px;top:527.33px" class="cls_008"><span class="cls_008">After looking at the histograms we decided to plot all the 100.000 data points</span></div>
<div style="position:absolute;left:124.80px;top:539.29px" class="cls_008"><span class="cls_008">in a 3D-space (figure 6.4) with total income, FTE percentage and hours worked</span></div>
<div style="position:absolute;left:124.80px;top:551.25px" class="cls_008"><span class="cls_008">as the axis.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">62</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:55315px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background066.jpg" width=595 height=841></div>
<div style="position:absolute;left:150.36px;top:403.85px" class="cls_008"><span class="cls_008">Figure 6.4: All 100.000 data points plotted, outliers marked in red.</span></div>
<div style="position:absolute;left:139.75px;top:441.31px" class="cls_008"><span class="cls_008">When looking at the plot of the data we see that a lot of the earlier as-</span></div>
<div style="position:absolute;left:124.80px;top:453.27px" class="cls_008"><span class="cls_008">sumptions about what gets flagged as outliers by K-means is correct.  Almost</span></div>
<div style="position:absolute;left:124.80px;top:465.22px" class="cls_008"><span class="cls_008">all the 913 registered outliers occur when either total income, FTE percentage,</span></div>
<div style="position:absolute;left:124.80px;top:477.18px" class="cls_008"><span class="cls_008">hours worked or a combination of the three have either a very high or a very</span></div>
<div style="position:absolute;left:124.80px;top:489.13px" class="cls_008"><span class="cls_008">low value.  Because of how we used K-means for detecting these outliers, this</span></div>
<div style="position:absolute;left:124.80px;top:501.09px" class="cls_008"><span class="cls_008">is in line with what we assumed would be the result. We see that when hours</span></div>
<div style="position:absolute;left:124.80px;top:513.05px" class="cls_008"><span class="cls_008">worked passes a couple of hundred or when they are in the negatives they get</span></div>
<div style="position:absolute;left:124.80px;top:525.00px" class="cls_008"><span class="cls_008">marked. This makes sense from a real world perspective of what is possible so</span></div>
<div style="position:absolute;left:124.80px;top:536.96px" class="cls_008"><span class="cls_008">these might really be anomalous. As soon as someone has a FTE percentage of</span></div>
<div style="position:absolute;left:124.80px;top:548.91px" class="cls_008"><span class="cls_008">more than a 100% they also get marked.  Most of these might not necessarily</span></div>
<div style="position:absolute;left:124.80px;top:560.87px" class="cls_008"><span class="cls_008">be anomalies, but the very high ones such as the one with 2500% are almost</span></div>
<div style="position:absolute;left:124.80px;top:572.82px" class="cls_008"><span class="cls_008">certainly an anomaly. A lot of our registered outliers occurs when the total in-</span></div>
<div style="position:absolute;left:124.80px;top:584.78px" class="cls_008"><span class="cls_008">come is above a couple of hundred thousand. It is hard to judge whether these</span></div>
<div style="position:absolute;left:124.80px;top:596.73px" class="cls_008"><span class="cls_008">really are anomalous without any other references.  We do also see that there</span></div>
<div style="position:absolute;left:124.80px;top:608.69px" class="cls_008"><span class="cls_008">were a few registered outliers among the inliers, where most of the data points</span></div>
<div style="position:absolute;left:124.80px;top:620.64px" class="cls_008"><span class="cls_008">are concentrated, this seem to not be a result of abnormally high or low values.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">63</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:56166px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background067.jpg" width=595 height=841></div>
<div style="position:absolute;left:157.83px;top:465.23px" class="cls_008"><span class="cls_008">Figure 6.5: Closeup of the highest concentration of data points.</span></div>
<div style="position:absolute;left:139.75px;top:502.69px" class="cls_008"><span class="cls_008">When looking closer at where most of the data points are concentrated (Fig-</span></div>
<div style="position:absolute;left:124.80px;top:514.65px" class="cls_008"><span class="cls_008">ure 6.5) to look at these points we find that they do not seem to be anomalous</span></div>
<div style="position:absolute;left:124.80px;top:526.60px" class="cls_008"><span class="cls_008">for any specific reason. More likely they seem to be a result of being just more</span></div>
<div style="position:absolute;left:124.80px;top:538.56px" class="cls_008"><span class="cls_008">than 4 times the average distance away from their cluster center which is the</span></div>
<div style="position:absolute;left:124.80px;top:550.51px" class="cls_008"><span class="cls_008">metric we used for determining points as outliers.  We can assume from this</span></div>
<div style="position:absolute;left:124.80px;top:562.47px" class="cls_008"><span class="cls_008">that they are most likely not anomalies.  This serves as a testament to how</span></div>
<div style="position:absolute;left:124.80px;top:574.42px" class="cls_008"><span class="cls_008">K-means is not very well suited for finding outliers inside big concentrations of</span></div>
<div style="position:absolute;left:124.80px;top:586.38px" class="cls_008"><span class="cls_008">data points.</span></div>
<div style="position:absolute;left:124.80px;top:612.27px" class="cls_017"><span class="cls_017">6.1.2</span></div>
<div style="position:absolute;left:165.90px;top:612.27px" class="cls_017"><span class="cls_017">Four features</span></div>
<div style="position:absolute;left:124.80px;top:632.66px" class="cls_008"><span class="cls_008">Next, when looking at the 978 outliers detected when we used the previous</span></div>
<div style="position:absolute;left:124.80px;top:644.61px" class="cls_008"><span class="cls_008">three features as well as a fourth feature, PPD (prepayment deductions), we</span></div>
<div style="position:absolute;left:124.80px;top:656.57px" class="cls_008"><span class="cls_008">once again decided that histograms would be a good place to start. These once</span></div>
<div style="position:absolute;left:124.80px;top:668.52px" class="cls_008"><span class="cls_008">again had their max and min 1% values "cut".</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">64</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:57017px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background068.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:551.43px" class="cls_008"><span class="cls_008">Figure 6.6:  Histograms for total income, FTE percentage, and hours worked</span></div>
<div style="position:absolute;left:124.80px;top:563.39px" class="cls_008"><span class="cls_008">with K-means run on four features.</span></div>
<div style="position:absolute;left:139.75px;top:590.88px" class="cls_008"><span class="cls_008">When looking at the histograms for total income, FTE percentage and hours</span></div>
<div style="position:absolute;left:124.80px;top:602.84px" class="cls_008"><span class="cls_008">worked (Figure 6.6), they looked very similar to the previous histograms for only</span></div>
<div style="position:absolute;left:124.80px;top:614.79px" class="cls_008"><span class="cls_008">three features. This was not unexpected as we assumed that it would still mark</span></div>
<div style="position:absolute;left:124.80px;top:626.75px" class="cls_008"><span class="cls_008">most of the same data points as outliers.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">65</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:57868px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background069.jpg" width=595 height=841></div>
<div style="position:absolute;left:160.71px;top:269.34px" class="cls_008"><span class="cls_008">Figure 6.7: Histogram of K-means for prepayment deductions.</span></div>
<div style="position:absolute;left:139.75px;top:306.80px" class="cls_008"><span class="cls_008">For the histograms of the new feature PPD (Figure 6.7), we expectantly</span></div>
<div style="position:absolute;left:124.80px;top:318.76px" class="cls_008"><span class="cls_008">found that most of the registered outliers have very low values, probably lower</span></div>
<div style="position:absolute;left:124.80px;top:330.71px" class="cls_008"><span class="cls_008">than what the histogram shows. We see that the histogram almost looks like a</span></div>
<div style="position:absolute;left:124.80px;top:342.67px" class="cls_008"><span class="cls_008">reverse of the histogram for total income. Since the two features are supposed</span></div>
<div style="position:absolute;left:124.80px;top:354.62px" class="cls_008"><span class="cls_008">to be related to each other this might indicate that it is the same data points</span></div>
<div style="position:absolute;left:124.80px;top:366.58px" class="cls_008"><span class="cls_008">that both have a really high total income and really low PPD getting registered</span></div>
<div style="position:absolute;left:124.80px;top:378.53px" class="cls_008"><span class="cls_008">as outliers, and realistically these might not really be anomalies.</span></div>
<div style="position:absolute;left:139.75px;top:402.44px" class="cls_008"><span class="cls_008">We wanted to plot the results of K-means on four features in a 3D-plot,</span></div>
<div style="position:absolute;left:124.80px;top:414.40px" class="cls_008"><span class="cls_008">but since plotting in four dimensions is impossible we either had to use PCA to</span></div>
<div style="position:absolute;left:124.80px;top:426.35px" class="cls_008"><span class="cls_008">reduce the dimensions, thereby losing the context of what each value represents,</span></div>
<div style="position:absolute;left:124.80px;top:438.31px" class="cls_008"><span class="cls_008">or only plot three of the four features. We chose to do the second.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">66</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:58719px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background070.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:465.23px" class="cls_008"><span class="cls_008">Figure 6.8: Plot of outliers for four features with total income, PPD and hours</span></div>
<div style="position:absolute;left:124.80px;top:477.19px" class="cls_008"><span class="cls_008">worked as the axis.</span></div>
<div style="position:absolute;left:139.75px;top:514.65px" class="cls_008"><span class="cls_008">First we plotted the results with total income, PPD and hours worked as the</span></div>
<div style="position:absolute;left:124.80px;top:526.60px" class="cls_008"><span class="cls_008">axis (Figure 6.8). From this we can see that for the most part total income and</span></div>
<div style="position:absolute;left:124.80px;top:538.56px" class="cls_008"><span class="cls_008">PPD are heavily related to each other and that our previous assumption might</span></div>
<div style="position:absolute;left:124.80px;top:550.51px" class="cls_008"><span class="cls_008">be correct in that the ones with both high total income and low PPD might</span></div>
<div style="position:absolute;left:124.80px;top:562.47px" class="cls_008"><span class="cls_008">not really be anomalies. We do see that a some of the high total incomes that</span></div>
<div style="position:absolute;left:124.80px;top:574.42px" class="cls_008"><span class="cls_008">were marked as outliers do not have a correspondingly low PPD. These might</span></div>
<div style="position:absolute;left:124.80px;top:586.38px" class="cls_008"><span class="cls_008">be more likely to be true anomalies.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">67</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:59570px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background071.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:371.88px" class="cls_008"><span class="cls_008">Figure 6.9: Plot of outliers for 4 features with total income, prepayment deduc-</span></div>
<div style="position:absolute;left:124.80px;top:383.84px" class="cls_008"><span class="cls_008">tions and FTE perentage as the axis.</span></div>
<div style="position:absolute;left:139.75px;top:421.30px" class="cls_008"><span class="cls_008">When plotting for three features excluding hours worked (Figure 6.9) we</span></div>
<div style="position:absolute;left:124.80px;top:433.25px" class="cls_008"><span class="cls_008">found nothing of any significance that we had not already previously seen and</span></div>
<div style="position:absolute;left:124.80px;top:445.21px" class="cls_008"><span class="cls_008">since total income and PPD were generally highly related, excluding total in-</span></div>
<div style="position:absolute;left:124.80px;top:457.17px" class="cls_008"><span class="cls_008">come for our plot yielded a plot very similar to when plotting for K-means on</span></div>
<div style="position:absolute;left:124.80px;top:469.12px" class="cls_008"><span class="cls_008">only 3 features earlier, see figure 6.4.</span></div>
<div style="position:absolute;left:124.80px;top:495.02px" class="cls_017"><span class="cls_017">6.1.3</span></div>
<div style="position:absolute;left:165.90px;top:495.02px" class="cls_017"><span class="cls_017">Five features.</span></div>
<div style="position:absolute;left:124.80px;top:515.40px" class="cls_008"><span class="cls_008">When running K-means with the five features: total income, FTE percentage,</span></div>
<div style="position:absolute;left:124.80px;top:527.35px" class="cls_008"><span class="cls_008">hours worked, PPD, WTA (working time arrangement), and with a k = 3 we</span></div>
<div style="position:absolute;left:124.80px;top:539.31px" class="cls_008"><span class="cls_008">registered 804 outliers.  We assumed earlier that because of the increase in</span></div>
<div style="position:absolute;left:124.80px;top:551.26px" class="cls_008"><span class="cls_008">number of clusters, as well as an increased x× average_distance metric, plus</span></div>
<div style="position:absolute;left:124.80px;top:563.22px" class="cls_008"><span class="cls_008">the inclusion of a new categorical feature, the results from this would likely</span></div>
<div style="position:absolute;left:124.80px;top:575.17px" class="cls_008"><span class="cls_008">differ more from the others.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">68</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:60421px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background072.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:690.68px" class="cls_008"><span class="cls_008">Figure 6.10: Histograms for total income, FTE percentage, hours worked and</span></div>
<div style="position:absolute;left:124.80px;top:702.64px" class="cls_008"><span class="cls_008">PPD with K-means run on 5 features.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">69</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:61272px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background073.jpg" width=595 height=841></div>
<div style="position:absolute;left:139.75px;top:124.91px" class="cls_008"><span class="cls_008">When looking at the histograms for the features total income, FTE percent-</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">age, hours worked and prepayment deductions (figure 6.10), it looks like this</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">time the results are quite different from previously. For three and four features,</span></div>
<div style="position:absolute;left:124.80px;top:160.77px" class="cls_008"><span class="cls_008">when looking at the outliers value for total income, most occurred when total</span></div>
<div style="position:absolute;left:124.80px;top:172.73px" class="cls_008"><span class="cls_008">income was 175.000+. This time the values are more evenly distributed among</span></div>
<div style="position:absolute;left:124.80px;top:184.68px" class="cls_008"><span class="cls_008">both high, low and in between. Ideally this means that the algorithm has not</span></div>
<div style="position:absolute;left:124.80px;top:196.64px" class="cls_008"><span class="cls_008">just found outliers based on them having a high income, but rather considered</span></div>
<div style="position:absolute;left:124.80px;top:208.59px" class="cls_008"><span class="cls_008">other factors as well.  For FTE percentage it seems mostly the same as where</span></div>
<div style="position:absolute;left:124.80px;top:220.55px" class="cls_008"><span class="cls_008">we found outliers previously. For hours worked surprisingly we found very few</span></div>
<div style="position:absolute;left:124.80px;top:232.51px" class="cls_008"><span class="cls_008">outliers detected when the hours were high, instead they are mostly found when</span></div>
<div style="position:absolute;left:124.80px;top:244.46px" class="cls_008"><span class="cls_008">the hours are zero or close to zero.  Earlier we found most outliers where the</span></div>
<div style="position:absolute;left:124.80px;top:256.42px" class="cls_008"><span class="cls_008">PPD had a very high negative value, for five features however we see that these</span></div>
<div style="position:absolute;left:124.80px;top:268.37px" class="cls_008"><span class="cls_008">are now more evenly spread out in a similar fashion to total income. This comes</span></div>
<div style="position:absolute;left:124.80px;top:280.33px" class="cls_008"><span class="cls_008">as no surprise as these two are heavily related.</span></div>
<div style="position:absolute;left:135.98px;top:514.25px" class="cls_008"><span class="cls_008">Figure 6.11: Barplot of outliers and inliers for working time arrangement.</span></div>
<div style="position:absolute;left:139.75px;top:551.71px" class="cls_008"><span class="cls_008">When looking at the barplot for the fifth feature, working time arrangement,</span></div>
<div style="position:absolute;left:124.80px;top:563.66px" class="cls_008"><span class="cls_008">we find that all the detected outliers occur for data points with "ikkeSkift" as</span></div>
<div style="position:absolute;left:124.80px;top:575.62px" class="cls_008"><span class="cls_008">their value. Although we know that this is what the majority of the data points</span></div>
<div style="position:absolute;left:124.80px;top:587.57px" class="cls_008"><span class="cls_008">have as their value this is still a bit odd.  Since this was categorical data that</span></div>
<div style="position:absolute;left:124.80px;top:599.53px" class="cls_008"><span class="cls_008">was split into five different features when running the algorithm this might</span></div>
<div style="position:absolute;left:124.80px;top:611.48px" class="cls_008"><span class="cls_008">indicate that the algorithm has not placed much value on anything other than</span></div>
<div style="position:absolute;left:124.80px;top:623.44px" class="cls_008"><span class="cls_008">the "ikkeSkift"-feature or that the others were removed when we used PCA on</span></div>
<div style="position:absolute;left:124.80px;top:635.39px" class="cls_008"><span class="cls_008">the data.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">70</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:62123px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background074.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:362.68px" class="cls_008"><span class="cls_008">Figure 6.12: K-means on five features plot with total income, hours worked and</span></div>
<div style="position:absolute;left:124.80px;top:374.64px" class="cls_008"><span class="cls_008">WTA as the axis.</span></div>
<div style="position:absolute;left:139.75px;top:412.10px" class="cls_008"><span class="cls_008">We plotted the outliers and inliers with regards to their total income and</span></div>
<div style="position:absolute;left:124.80px;top:424.05px" class="cls_008"><span class="cls_008">hours worked, features where we know we find a lot of excessively high values,</span></div>
<div style="position:absolute;left:124.80px;top:436.01px" class="cls_008"><span class="cls_008">and WTA (figure 6.12) to see if there was a discernible reason for why all outliers</span></div>
<div style="position:absolute;left:124.80px;top:447.96px" class="cls_008"><span class="cls_008">occured when WTA had the value "ikkeSkift". From the plot we see that for all</span></div>
<div style="position:absolute;left:124.80px;top:459.92px" class="cls_008"><span class="cls_008">the data points with WTA values that are not "ikkeSkift" we do not really find</span></div>
<div style="position:absolute;left:124.80px;top:471.87px" class="cls_008"><span class="cls_008">abnormally high values for any of the other features.  This indicates that K-</span></div>
<div style="position:absolute;left:124.80px;top:483.83px" class="cls_008"><span class="cls_008">means just did not find any outliers for any WTA values except for "ikkeSkift".</span></div>
<div style="position:absolute;left:124.80px;top:495.78px" class="cls_008"><span class="cls_008">From this plot we also see that with K-means for five features a lot of the data</span></div>
<div style="position:absolute;left:124.80px;top:507.74px" class="cls_008"><span class="cls_008">points with an unnaturally high number of hours worked do not get marked as</span></div>
<div style="position:absolute;left:124.80px;top:519.69px" class="cls_008"><span class="cls_008">outliers whereas with the previous two experiments they did. Instead this time</span></div>
<div style="position:absolute;left:124.80px;top:531.65px" class="cls_008"><span class="cls_008">a higher number of data points with a negative amount of hours worked got</span></div>
<div style="position:absolute;left:124.80px;top:543.60px" class="cls_008"><span class="cls_008">marked.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">71</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:62974px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background075.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:397.60px" class="cls_008"><span class="cls_008">Figure 6.13:  K-means on five features plot with total income, PPD and FTE</span></div>
<div style="position:absolute;left:124.80px;top:409.55px" class="cls_008"><span class="cls_008">percentage as the axis.</span></div>
<div style="position:absolute;left:139.75px;top:447.01px" class="cls_008"><span class="cls_008">When plotting this experiment (figure 6.13) to look at the relationship be-</span></div>
<div style="position:absolute;left:124.80px;top:458.97px" class="cls_008"><span class="cls_008">tween total income and PPD, as well as FTE percentage, we had hoped to find</span></div>
<div style="position:absolute;left:124.80px;top:470.92px" class="cls_008"><span class="cls_008">that more of the data points with correlating values between total income and</span></div>
<div style="position:absolute;left:124.80px;top:482.88px" class="cls_008"><span class="cls_008">PPD were disregarded as outliers and instead those with little correlation were</span></div>
<div style="position:absolute;left:124.80px;top:494.83px" class="cls_008"><span class="cls_008">marked. From our understanding of how the data is related these are more likely</span></div>
<div style="position:absolute;left:124.80px;top:506.79px" class="cls_008"><span class="cls_008">to be anomalies. This was not the case as fewer than in previous experiments,</span></div>
<div style="position:absolute;left:124.80px;top:518.74px" class="cls_008"><span class="cls_008">of the points with little to no correlation, were marked as outliers. We also see</span></div>
<div style="position:absolute;left:124.80px;top:530.70px" class="cls_008"><span class="cls_008">that data points with high FTE value were for this experiment marked mainly</span></div>
<div style="position:absolute;left:124.80px;top:542.65px" class="cls_008"><span class="cls_008">as inliers, except for ones that had a higher total income. This also seems wrong</span></div>
<div style="position:absolute;left:124.80px;top:554.61px" class="cls_008"><span class="cls_008">when looking for anomalies based on how we believe they should be related.</span></div>
<div style="position:absolute;left:124.80px;top:580.50px" class="cls_017"><span class="cls_017">6.1.4</span></div>
<div style="position:absolute;left:165.90px;top:580.50px" class="cls_017"><span class="cls_017">Comparing K-means results</span></div>
<div style="position:absolute;left:124.80px;top:600.89px" class="cls_008"><span class="cls_008">To look at how the different experiments compared to each other we used a</span></div>
<div style="position:absolute;left:124.80px;top:612.84px" class="cls_008"><span class="cls_008">Venn diagram of which data points each experiment had marked as outliers.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">72</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:63825px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background076.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:398.05px" class="cls_008"><span class="cls_008">Figure 6.14: Venn-diagram for the different outliers detected when running K-</span></div>
<div style="position:absolute;left:124.80px;top:410.01px" class="cls_008"><span class="cls_008">means.</span></div>
<div style="position:absolute;left:139.75px;top:447.47px" class="cls_008"><span class="cls_008">From this Venn diagram we found the most overlap between the experiments</span></div>
<div style="position:absolute;left:124.80px;top:459.42px" class="cls_008"><span class="cls_008">with three and four features (figure 6.14) which had 640 points in common.</span></div>
<div style="position:absolute;left:124.80px;top:471.38px" class="cls_008"><span class="cls_008">Less so for the experiment with five features which had 200 overlapping with</span></div>
<div style="position:absolute;left:124.80px;top:483.33px" class="cls_008"><span class="cls_008">the 3 feature experiment and 327 points overlapping the 4 feature experiment.</span></div>
<div style="position:absolute;left:124.80px;top:495.29px" class="cls_008"><span class="cls_008">They all had 192 of the same points marked.  We can assume that these were</span></div>
<div style="position:absolute;left:124.80px;top:507.24px" class="cls_008"><span class="cls_008">most likely only the data points with the highest and lowest values for the</span></div>
<div style="position:absolute;left:124.80px;top:519.20px" class="cls_008"><span class="cls_008">features total income, hours worked and FTE percentage.  Although we had</span></div>
<div style="position:absolute;left:124.80px;top:531.15px" class="cls_008"><span class="cls_008">hoped that the more features we included the better the algorithm would be at</span></div>
<div style="position:absolute;left:124.80px;top:543.11px" class="cls_008"><span class="cls_008">detecting potential anomalies, when looking at and analyzing the results from</span></div>
<div style="position:absolute;left:124.80px;top:555.06px" class="cls_008"><span class="cls_008">each experiment it might seem like this is not the case. Since we are not sure of</span></div>
<div style="position:absolute;left:124.80px;top:567.02px" class="cls_008"><span class="cls_008">what exactly qualifies as an anomaly it is hard for us to determine which of the</span></div>
<div style="position:absolute;left:124.80px;top:578.97px" class="cls_008"><span class="cls_008">experiments is better suited for detecting anomalies and whether they are any</span></div>
<div style="position:absolute;left:124.80px;top:590.93px" class="cls_008"><span class="cls_008">good at all.  We would need the NTA to look at the results before concluding</span></div>
<div style="position:absolute;left:124.80px;top:602.88px" class="cls_008"><span class="cls_008">with anything. The results of the experiment might also be different if we had</span></div>
<div style="position:absolute;left:124.80px;top:614.84px" class="cls_008"><span class="cls_008">used all 8 million data points instead of just 100.000, as this might be too little</span></div>
<div style="position:absolute;left:124.80px;top:626.79px" class="cls_008"><span class="cls_008">for the algorithm to form good clusters.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">73</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:64676px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background077.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:120.52px" class="cls_010"><span class="cls_010">6.2</span></div>
<div style="position:absolute;left:161.56px;top:120.52px" class="cls_010"><span class="cls_010">Results - DBSCAN</span></div>
<div style="position:absolute;left:124.80px;top:146.73px" class="cls_008"><span class="cls_008">This section shows the results for DBSCAN. As shown in the table below, the</span></div>
<div style="position:absolute;left:124.80px;top:158.68px" class="cls_008"><span class="cls_008">data was scaled using Scikit-learns StandardScaler. In addition, datasets with</span></div>
<div style="position:absolute;left:124.80px;top:170.64px" class="cls_008"><span class="cls_008">more than three features will have PCA applied for removing redundant data</span></div>
<div style="position:absolute;left:124.80px;top:182.59px" class="cls_008"><span class="cls_008">and reduce dimensions for visualization purposes.</span></div>
<div style="position:absolute;left:124.80px;top:208.49px" class="cls_017"><span class="cls_017">6.2.1</span></div>
<div style="position:absolute;left:165.90px;top:208.49px" class="cls_017"><span class="cls_017">Three Features</span></div>
<div style="position:absolute;left:124.80px;top:228.87px" class="cls_007"><span class="cls_007">Dataset and Parameters</span></div>
<div style="position:absolute;left:138.31px;top:256.88px" class="cls_021"><span class="cls_021">Features   Algorithm   MinPts   Eps</span></div>
<div style="position:absolute;left:344.81px;top:256.88px" class="cls_021"><span class="cls_021">Metric</span></div>
<div style="position:absolute;left:396.68px;top:256.88px" class="cls_021"><span class="cls_021">PCA   Scale</span></div>
<div style="position:absolute;left:156.06px;top:273.36px" class="cls_021"><span class="cls_021">3</span></div>
<div style="position:absolute;left:193.98px;top:273.36px" class="cls_021"><span class="cls_021">DBSCAN</span></div>
<div style="position:absolute;left:271.00px;top:273.36px" class="cls_021"><span class="cls_021">6</span></div>
<div style="position:absolute;left:305.03px;top:273.36px" class="cls_021"><span class="cls_021">0.12</span></div>
<div style="position:absolute;left:338.17px;top:273.36px" class="cls_021"><span class="cls_021">euclidean</span></div>
<div style="position:absolute;left:401.70px;top:273.36px" class="cls_021"><span class="cls_021">No     Yes</span></div>
<div style="position:absolute;left:124.80px;top:302.89px" class="cls_008"><span class="cls_008">As described in chapter 5.3, we used the proposed way of setting M inP ts and</span></div>
<div style="position:absolute;left:124.80px;top:314.85px" class="cls_008"><span class="cls_008">eps parameters. M inP ts is set as 2 × dimension (features). For three features</span></div>
<div style="position:absolute;left:124.80px;top:326.80px" class="cls_008"><span class="cls_008">the following sorted k-dist graph can be seen in figure 6.15 below.</span></div>
<div style="position:absolute;left:136.34px;top:509.24px" class="cls_008"><span class="cls_008">Figure 6.15: Sorted k-dist graph proposes the eps value for three features</span></div>
<div style="position:absolute;left:124.80px;top:548.69px" class="cls_007"><span class="cls_007">Result</span></div>
<div style="position:absolute;left:124.80px;top:567.08px" class="cls_008"><span class="cls_008">To get an initial view of the outliers/inliers in the feature space, we scatter-</span></div>
<div style="position:absolute;left:124.80px;top:579.03px" class="cls_008"><span class="cls_008">plotted the data in figure 6.16 below. We have limited the X, Y and Z axis to</span></div>
<div style="position:absolute;left:124.80px;top:590.99px" class="cls_008"><span class="cls_008">get a better view of the data, as only outliers were shown without limitations. In</span></div>
<div style="position:absolute;left:124.80px;top:602.94px" class="cls_008"><span class="cls_008">total, 1345 data points were labeled as outliers with respect to the parameters</span></div>
<div style="position:absolute;left:124.80px;top:614.90px" class="cls_008"><span class="cls_008">set. This suggest 1,345% of the data is potentially anomalous.</span></div>
<div style="position:absolute;left:139.75px;top:638.81px" class="cls_008"><span class="cls_008">Observing the figures below, we can notice data points positioned in sparse</span></div>
<div style="position:absolute;left:124.80px;top:650.76px" class="cls_008"><span class="cls_008">areas are all labeled as outliers. This is due to the parameters set before run-</span></div>
<div style="position:absolute;left:124.80px;top:662.72px" class="cls_008"><span class="cls_008">ning the algorithm.  In short, a data point for this dataset requires at least 6</span></div>
<div style="position:absolute;left:124.80px;top:674.67px" class="cls_008"><span class="cls_008">neighbouring points within 0.12 epsilon radius.  In addition, a data point can</span></div>
<div style="position:absolute;left:124.80px;top:686.63px" class="cls_008"><span class="cls_008">also be labeled as inlier if it has at least 1 neighbouring point which fulfills the</span></div>
<div style="position:absolute;left:124.80px;top:698.59px" class="cls_008"><span class="cls_008">requirement to be a core point as described in chapter 3.3.2. This trait enables</span></div>
<div style="position:absolute;left:124.80px;top:710.54px" class="cls_008"><span class="cls_008">DBSCAN to easily locate global outliers with respect to the data. Clusters can</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">74</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:65527px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background078.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">be of any shape, size and form, as we observe the horizontal line of inlying data</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">points in figure 6.16 and the main cluster in figure 6.17.</span></div>
<div style="position:absolute;left:124.80px;top:342.41px" class="cls_008"><span class="cls_008">Figure 6.16: 3D graph showing the output from DBSCAN. Outliers are colored</span></div>
<div style="position:absolute;left:124.80px;top:354.37px" class="cls_008"><span class="cls_008">blue, while inliers are colored yellow.</span></div>
<div style="position:absolute;left:139.75px;top:391.83px" class="cls_008"><span class="cls_008">Separating the outliers from the inliers, we can observe that most outliers</span></div>
<div style="position:absolute;left:124.80px;top:403.78px" class="cls_008"><span class="cls_008">lie outside of the dense areas in the data. As a result, we can assume that the</span></div>
<div style="position:absolute;left:124.80px;top:415.74px" class="cls_008"><span class="cls_008">distribution of data will lie outside the regular/average values for the different</span></div>
<div style="position:absolute;left:124.80px;top:427.69px" class="cls_008"><span class="cls_008">features.  The inliers create a smooth cluster of data points connected to each</span></div>
<div style="position:absolute;left:124.80px;top:439.65px" class="cls_008"><span class="cls_008">other by the M inP ts and eps parameters. In comparison to the LOF algorithm,</span></div>
<div style="position:absolute;left:124.80px;top:451.60px" class="cls_008"><span class="cls_008">which is able to find local outliers, DBSCAN labels most of the local data points</span></div>
<div style="position:absolute;left:124.80px;top:463.56px" class="cls_008"><span class="cls_008">within dense areas as part of a cluster.  The reason for this, is that they exist</span></div>
<div style="position:absolute;left:124.80px;top:475.51px" class="cls_008"><span class="cls_008">near very dense areas of data and holds a large number of neighbouring points</span></div>
<div style="position:absolute;left:124.80px;top:487.47px" class="cls_008"><span class="cls_008">within the epsilon radius.</span></div>
<div style="position:absolute;left:139.75px;top:511.38px" class="cls_008"><span class="cls_008">In addition, notice the tiny cluster on the right graph in figure 6.17. These</span></div>
<div style="position:absolute;left:124.80px;top:523.33px" class="cls_008"><span class="cls_008">data points visually lie far from the main cluster due to the high values of FTE</span></div>
<div style="position:absolute;left:124.80px;top:535.29px" class="cls_008"><span class="cls_008">percentage. From the parameters, we know that the amount of data points lying</span></div>
<div style="position:absolute;left:124.80px;top:547.24px" class="cls_008"><span class="cls_008">in this cluster is above 6, and we also know that most lie within a 0.12 radius</span></div>
<div style="position:absolute;left:124.80px;top:559.20px" class="cls_008"><span class="cls_008">of each other creating core points and border points. This shows the need for</span></div>
<div style="position:absolute;left:124.80px;top:571.15px" class="cls_008"><span class="cls_008">tuning the parameters with respect to the data given instead of solely following</span></div>
<div style="position:absolute;left:124.80px;top:583.11px" class="cls_008"><span class="cls_008">the proposed method of setting the parameters. This proposed method should</span></div>
<div style="position:absolute;left:124.80px;top:595.06px" class="cls_008"><span class="cls_008">be viewed as an initial action rather than a final one.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">75</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:66378px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background079.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:278.97px" class="cls_008"><span class="cls_008">Figure 6.17:  Two 3D graphs showing the separated inliers and outliers from</span></div>
<div style="position:absolute;left:124.80px;top:290.92px" class="cls_008"><span class="cls_008">DBSCAN. Outliers are colored blue, while inliers are colored yellow.</span></div>
<div style="position:absolute;left:139.75px;top:328.38px" class="cls_008"><span class="cls_008">The histogram visualizing data with regards to total income (see 6.18) seems</span></div>
<div style="position:absolute;left:124.80px;top:340.34px" class="cls_008"><span class="cls_008">to have a similar distribution to the inliers, spiking around 40.000. One big and</span></div>
<div style="position:absolute;left:124.80px;top:352.29px" class="cls_008"><span class="cls_008">interesting difference is the amount of outliers containing the value 0 compared</span></div>
<div style="position:absolute;left:124.80px;top:364.25px" class="cls_008"><span class="cls_008">to the inliers.  As a large portion of inlier points contain this value as total</span></div>
<div style="position:absolute;left:124.80px;top:376.20px" class="cls_008"><span class="cls_008">income, and almost no outliers contain this value, this suggests that outliers lie</span></div>
<div style="position:absolute;left:124.80px;top:388.16px" class="cls_008"><span class="cls_008">outside dense areas of data and strengthens the assumptions that outliers lie in</span></div>
<div style="position:absolute;left:124.80px;top:400.12px" class="cls_008"><span class="cls_008">sparser areas.</span></div>
<div style="position:absolute;left:124.80px;top:582.17px" class="cls_008"><span class="cls_008">Figure 6.18:  Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:124.80px;top:594.12px" class="cls_008"><span class="cls_008">regards to total income</span></div>
<div style="position:absolute;left:139.75px;top:631.58px" class="cls_008"><span class="cls_008">Unlike the histograms for total income, the histograms for FTE percentage</span></div>
<div style="position:absolute;left:124.80px;top:643.54px" class="cls_008"><span class="cls_008">does not look similar in terms of distribution.  Outliers tend to have a wide</span></div>
<div style="position:absolute;left:124.80px;top:655.49px" class="cls_008"><span class="cls_008">spread range of values, and inliers tend to have either 0 or 100 as this value.</span></div>
<div style="position:absolute;left:124.80px;top:667.45px" class="cls_008"><span class="cls_008">In addition, unlike total income distribution, a good portion of outliers have</span></div>
<div style="position:absolute;left:124.80px;top:679.41px" class="cls_008"><span class="cls_008">average values such as 0 or 100 as FTE percentage.  Assuming global outliers</span></div>
<div style="position:absolute;left:124.80px;top:691.36px" class="cls_008"><span class="cls_008">should not have average values for the different features, this might seem strange.</span></div>
<div style="position:absolute;left:124.80px;top:703.32px" class="cls_008"><span class="cls_008">An explanation for this could be that the these outliers containing average</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">76</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:67229px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background080.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">values for FTE percentage, also contain uncommon/abnormal values for the</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">other features and therefore is still anomalous in terms of the data points.</span></div>
<div style="position:absolute;left:124.80px;top:318.34px" class="cls_008"><span class="cls_008">Figure 6.19:  Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:124.80px;top:330.29px" class="cls_008"><span class="cls_008">regards to FTE percentage</span></div>
<div style="position:absolute;left:139.75px;top:366.70px" class="cls_008"><span class="cls_008">Looking at the histogram for hours worked, we can observe a wide spread</span></div>
<div style="position:absolute;left:124.80px;top:378.66px" class="cls_008"><span class="cls_008">distribution of values, ranging mostly from -100 to 500, but also a good quantity</span></div>
<div style="position:absolute;left:124.80px;top:390.61px" class="cls_008"><span class="cls_008">above 500.  As shown in the distribution for inliers, most of the data points</span></div>
<div style="position:absolute;left:124.80px;top:402.57px" class="cls_008"><span class="cls_008">contain a value of 140-180 which is around average working hours.  Some of</span></div>
<div style="position:absolute;left:124.80px;top:414.52px" class="cls_008"><span class="cls_008">these bars have had their frequency clipped for visualization purposes.  This</span></div>
<div style="position:absolute;left:124.80px;top:426.48px" class="cls_008"><span class="cls_008">observation further strengthens the assumption that outliers lie mostly outside</span></div>
<div style="position:absolute;left:124.80px;top:438.43px" class="cls_008"><span class="cls_008">the main cluster, and the majority should not have average values for features.</span></div>
<div style="position:absolute;left:124.80px;top:614.52px" class="cls_008"><span class="cls_008">Figure 6.20:  Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:124.80px;top:626.48px" class="cls_008"><span class="cls_008">regards to hours worked</span></div>
<div style="position:absolute;left:139.75px;top:662.89px" class="cls_008"><span class="cls_008">The heatmaps in figure 6.21 for inliers and outliers have some interesting</span></div>
<div style="position:absolute;left:124.80px;top:674.85px" class="cls_008"><span class="cls_008">observations. For inliers, we notice a high positive correlation for hours worked</span></div>
<div style="position:absolute;left:124.80px;top:686.80px" class="cls_008"><span class="cls_008">and FTE percentage (67.4%), and similarly a relative high positive correlation</span></div>
<div style="position:absolute;left:124.80px;top:698.76px" class="cls_008"><span class="cls_008">for total income vs hours worked and FTE percentage.  In comparison, the</span></div>
<div style="position:absolute;left:124.80px;top:710.71px" class="cls_008"><span class="cls_008">outliers have nearly no correlation on the latter, and a lower correlation (42.2%)</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">77</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:68080px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background081.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">for hours worked and FTE percentage.  This suggests that there is a medium</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">strong correlation in the dense areas of data where inliers lie, while outliers tend</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">to have less or no correlation of feature data.</span></div>
<div style="position:absolute;left:124.80px;top:315.03px" class="cls_008"><span class="cls_008">Figure 6.21:  Heatmaps showing the correlation of the data for outliers and</span></div>
<div style="position:absolute;left:124.80px;top:326.98px" class="cls_008"><span class="cls_008">inliers. Inlier heatmap on the left, and outliers on the right.</span></div>
<div style="position:absolute;left:124.80px;top:366.43px" class="cls_007"><span class="cls_007">Key observations</span></div>
<div style="position:absolute;left:139.75px;top:384.82px" class="cls_008"><span class="cls_008">- The assumption of outliers having non-average values for their features is</span></div>
<div style="position:absolute;left:149.71px;top:396.77px" class="cls_008"><span class="cls_008">strengthened by the observations in both the histograms and heatmaps.</span></div>
<div style="position:absolute;left:139.75px;top:416.70px" class="cls_008"><span class="cls_008">- As most of the outliers are global data points lying outside the main</span></div>
<div style="position:absolute;left:149.71px;top:428.65px" class="cls_008"><span class="cls_008">cluster, we can assume that data points labeled as outliers tend to have</span></div>
<div style="position:absolute;left:149.71px;top:440.61px" class="cls_008"><span class="cls_008">less- or uncorrelated features.</span></div>
<div style="position:absolute;left:124.80px;top:466.50px" class="cls_017"><span class="cls_017">6.2.2</span></div>
<div style="position:absolute;left:165.90px;top:466.50px" class="cls_017"><span class="cls_017">Four Features</span></div>
<div style="position:absolute;left:124.80px;top:486.89px" class="cls_007"><span class="cls_007">Data set and Parameters</span></div>
<div style="position:absolute;left:137.54px;top:514.97px" class="cls_022"><span class="cls_022">Features   Algorithm   MinPts   Eps</span></div>
<div style="position:absolute;left:332.35px;top:514.97px" class="cls_022"><span class="cls_022">Metric</span></div>
<div style="position:absolute;left:391.01px;top:514.97px" class="cls_022"><span class="cls_022">PCA     Scale</span></div>
<div style="position:absolute;left:154.29px;top:530.52px" class="cls_022"><span class="cls_022">4</span></div>
<div style="position:absolute;left:190.06px;top:530.52px" class="cls_022"><span class="cls_022">DBSCAN</span></div>
<div style="position:absolute;left:262.72px;top:530.52px" class="cls_022"><span class="cls_022">8</span></div>
<div style="position:absolute;left:294.82px;top:530.52px" class="cls_022"><span class="cls_022">0.17</span></div>
<div style="position:absolute;left:326.09px;top:530.52px" class="cls_022"><span class="cls_022">euclidean   Yes(to 3)    Yes</span></div>
<div style="position:absolute;left:124.80px;top:559.16px" class="cls_008"><span class="cls_008">As described in chapter 5.3, we used the proposed way of setting M inP ts and</span></div>
<div style="position:absolute;left:124.80px;top:571.12px" class="cls_008"><span class="cls_008">eps parameters. M inP ts is set as 2 × dimension (features). For four features</span></div>
<div style="position:absolute;left:124.80px;top:583.07px" class="cls_008"><span class="cls_008">the following sorted k-dist graph can be seen in figure 6.22 below.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">78</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:68931px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background082.jpg" width=595 height=841></div>
<div style="position:absolute;left:138.69px;top:282.32px" class="cls_008"><span class="cls_008">Figure 6.22: Sorted k-dist graph proposes the eps value for four features</span></div>
<div style="position:absolute;left:124.80px;top:321.76px" class="cls_007"><span class="cls_007">Result</span></div>
<div style="position:absolute;left:124.80px;top:340.15px" class="cls_008"><span class="cls_008">Similar to the experiment with three features, we limited the X, Y and Z axis to</span></div>
<div style="position:absolute;left:124.80px;top:352.11px" class="cls_008"><span class="cls_008">get a better view of the data. The four features were reduced to three with PCA</span></div>
<div style="position:absolute;left:124.80px;top:364.06px" class="cls_008"><span class="cls_008">for visualization purposes, and in order to remove redundant data. Therefore,</span></div>
<div style="position:absolute;left:124.80px;top:376.02px" class="cls_008"><span class="cls_008">the new dimensions are named PC1, PC2 and PC3, as they are the new features</span></div>
<div style="position:absolute;left:124.80px;top:387.97px" class="cls_008"><span class="cls_008">which represent the data.  We can observe the same outcome as figure 6.23 in</span></div>
<div style="position:absolute;left:124.80px;top:399.93px" class="cls_008"><span class="cls_008">the previous experiment where outliers seems to lie outside the main cluster. In</span></div>
<div style="position:absolute;left:124.80px;top:411.88px" class="cls_008"><span class="cls_008">total, 893 data points were labeled as outliers which suggests a percentage of</span></div>
<div style="position:absolute;left:124.80px;top:423.84px" class="cls_008"><span class="cls_008">0.893% of the data.</span></div>
<div style="position:absolute;left:124.80px;top:596.06px" class="cls_008"><span class="cls_008">Figure 6.23: 3D graph showing the output from DBSCAN. Data is reduced to</span></div>
<div style="position:absolute;left:124.80px;top:608.02px" class="cls_008"><span class="cls_008">three dimensions with PCA. Outliers are colored blue, while inliers are colored</span></div>
<div style="position:absolute;left:124.80px;top:619.97px" class="cls_008"><span class="cls_008">yellow.</span></div>
<div style="position:absolute;left:139.75px;top:657.43px" class="cls_008"><span class="cls_008">Separating the outliers from the inliers, we can observe the same phenomena</span></div>
<div style="position:absolute;left:124.80px;top:669.39px" class="cls_008"><span class="cls_008">as figure 6.16, where the inliers create a smooth clusters stretching to the less</span></div>
<div style="position:absolute;left:124.80px;top:681.34px" class="cls_008"><span class="cls_008">dense areas.  For this graph, observations of "mini"-clusters outside the main</span></div>
<div style="position:absolute;left:124.80px;top:693.30px" class="cls_008"><span class="cls_008">cluster seems non-existent, unlike what we saw in the previous experiment.</span></div>
<div style="position:absolute;left:124.80px;top:705.25px" class="cls_008"><span class="cls_008">This is most likely due to the increase of the M inP ts and eps parameters,</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">79</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:69782px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background083.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">which means that there is a greater requirement to form a cluster.</span></div>
<div style="position:absolute;left:124.80px;top:301.54px" class="cls_008"><span class="cls_008">Figure 6.24:  Two 3D graphs showing the separated inliers and outliers from</span></div>
<div style="position:absolute;left:124.80px;top:313.50px" class="cls_008"><span class="cls_008">DBSCAN. Outliers are colored blue, while inliers are colored yellow.</span></div>
<div style="position:absolute;left:139.75px;top:350.96px" class="cls_008"><span class="cls_008">Comparing the histograms below (figure 6.25) with figure 6.18, we see nearly</span></div>
<div style="position:absolute;left:124.80px;top:362.91px" class="cls_008"><span class="cls_008">identical distributions in terms of total income. The difference is the frequency</span></div>
<div style="position:absolute;left:124.80px;top:374.87px" class="cls_008"><span class="cls_008">of the distinct distribution bins, which can be explained as this experiment</span></div>
<div style="position:absolute;left:124.80px;top:386.82px" class="cls_008"><span class="cls_008">labeled close to 500 fewer data points as outliers.</span></div>
<div style="position:absolute;left:124.80px;top:567.65px" class="cls_008"><span class="cls_008">Figure 6.25:  Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:124.80px;top:579.61px" class="cls_008"><span class="cls_008">regards to total income</span></div>
<div style="position:absolute;left:139.75px;top:617.07px" class="cls_008"><span class="cls_008">For the histogram of FTE percentage (figure 6.26), the distribution also</span></div>
<div style="position:absolute;left:124.80px;top:629.02px" class="cls_008"><span class="cls_008">seems identical with the distribution in the previous experiment. The outliers</span></div>
<div style="position:absolute;left:124.80px;top:640.98px" class="cls_008"><span class="cls_008">containing 0 and 100 values for FTE percentage is close to the same as before.</span></div>
<div style="position:absolute;left:124.80px;top:652.93px" class="cls_008"><span class="cls_008">Based on these observations for similar distributions in FTE percentage and</span></div>
<div style="position:absolute;left:124.80px;top:664.89px" class="cls_008"><span class="cls_008">total income, we can assume that a good size of the same data points are labeled</span></div>
<div style="position:absolute;left:124.80px;top:676.84px" class="cls_008"><span class="cls_008">as outliers in both experiments.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">80</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:70633px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background084.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:279.92px" class="cls_008"><span class="cls_008">Figure 6.26:  Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:124.80px;top:291.88px" class="cls_008"><span class="cls_008">regards to FTE percentage</span></div>
<div style="position:absolute;left:139.75px;top:329.34px" class="cls_008"><span class="cls_008">As for the distribution of hours worked (figure 6.27, we observe a similar</span></div>
<div style="position:absolute;left:124.80px;top:341.29px" class="cls_008"><span class="cls_008">range as figure 6.20. Unlike the latter figure, more than an eighth of the outliers</span></div>
<div style="position:absolute;left:124.80px;top:353.25px" class="cls_008"><span class="cls_008">here have 160 hours worked as their value, and a large portion contain a value</span></div>
<div style="position:absolute;left:124.80px;top:365.20px" class="cls_008"><span class="cls_008">of 0.</span></div>
<div style="position:absolute;left:124.80px;top:544.76px" class="cls_008"><span class="cls_008">Figure 6.27:  Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:124.80px;top:556.71px" class="cls_008"><span class="cls_008">regards to hours worked</span></div>
<div style="position:absolute;left:139.75px;top:594.17px" class="cls_008"><span class="cls_008">For prepayment deductions (see 6.28), we see that more of the positive values</span></div>
<div style="position:absolute;left:124.80px;top:606.13px" class="cls_008"><span class="cls_008">are registered as anomalies, as well as the values from -50.000 and below. We can</span></div>
<div style="position:absolute;left:124.80px;top:618.08px" class="cls_008"><span class="cls_008">also see that the inliers with value 0 are more highly represented than outliers,</span></div>
<div style="position:absolute;left:124.80px;top:630.04px" class="cls_008"><span class="cls_008">indicating that points with 0 NOK for PPD are in denser areas.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">81</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:71484px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background085.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:281.65px" class="cls_008"><span class="cls_008">Figure 6.28:  Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:124.80px;top:293.61px" class="cls_008"><span class="cls_008">regards to prepayment deduction</span></div>
<div style="position:absolute;left:139.75px;top:331.07px" class="cls_008"><span class="cls_008">Similarily to the heatmap in figure 6.21, we find low to no correlation be-</span></div>
<div style="position:absolute;left:124.80px;top:343.02px" class="cls_008"><span class="cls_008">tween total income and both FTE percentage and hours worked for the outliers</span></div>
<div style="position:absolute;left:124.80px;top:354.98px" class="cls_008"><span class="cls_008">(see 6.29). We also find a reduced correlation between hours worked and FTE</span></div>
<div style="position:absolute;left:124.80px;top:366.93px" class="cls_008"><span class="cls_008">percentage. Prepayment deduction and total income show a higher correlation</span></div>
<div style="position:absolute;left:124.80px;top:378.89px" class="cls_008"><span class="cls_008">for the outliers compared to the inliers, unlike our assumptions.</span></div>
<div style="position:absolute;left:124.80px;top:547.26px" class="cls_008"><span class="cls_008">Figure 6.29: Heatmaps showing the correlation of the data for inliers (left) and</span></div>
<div style="position:absolute;left:124.80px;top:559.21px" class="cls_008"><span class="cls_008">outliers (right).</span></div>
<div style="position:absolute;left:124.80px;top:598.66px" class="cls_007"><span class="cls_007">Key observations</span></div>
<div style="position:absolute;left:139.75px;top:617.05px" class="cls_008"><span class="cls_008">- Similarly to the experiment with three features, we observe that the cor-</span></div>
<div style="position:absolute;left:149.71px;top:629.00px" class="cls_008"><span class="cls_008">relation between all the features drop, except for PPD and total income.</span></div>
<div style="position:absolute;left:139.75px;top:648.93px" class="cls_008"><span class="cls_008">- Outliers tend to lie outside dense areas of the data.  This shows that</span></div>
<div style="position:absolute;left:149.71px;top:660.88px" class="cls_008"><span class="cls_008">the DBSCAN algorithm often labels global data points as outliers. With</span></div>
<div style="position:absolute;left:149.71px;top:672.84px" class="cls_008"><span class="cls_008">this trait, we are able to detect data points with extreme negative or</span></div>
<div style="position:absolute;left:149.71px;top:684.79px" class="cls_008"><span class="cls_008">positive values. Nevertheless, this trait is controlled by the M inP ts and</span></div>
<div style="position:absolute;left:149.71px;top:696.75px" class="cls_008"><span class="cls_008">eps parameters, which means that if we set these parameters too high, we</span></div>
<div style="position:absolute;left:149.71px;top:708.70px" class="cls_008"><span class="cls_008">might label sparse areas of outliers as inliers.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">82</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:72335px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background086.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:122.92px" class="cls_017"><span class="cls_017">6.2.3</span></div>
<div style="position:absolute;left:165.90px;top:122.92px" class="cls_017"><span class="cls_017">Five Features</span></div>
<div style="position:absolute;left:124.80px;top:143.30px" class="cls_007"><span class="cls_007">Data set and Parameters</span></div>
<div style="position:absolute;left:137.60px;top:171.38px" class="cls_023"><span class="cls_023">Features   Algorithm   MinPts   Eps</span></div>
<div style="position:absolute;left:331.73px;top:171.38px" class="cls_023"><span class="cls_023">Metric</span></div>
<div style="position:absolute;left:390.66px;top:171.38px" class="cls_023"><span class="cls_023">PCA     Scale</span></div>
<div style="position:absolute;left:154.42px;top:186.99px" class="cls_023"><span class="cls_023">5</span></div>
<div style="position:absolute;left:190.36px;top:186.99px" class="cls_023"><span class="cls_023">DBSCAN</span></div>
<div style="position:absolute;left:260.70px;top:186.99px" class="cls_023"><span class="cls_023">10</span></div>
<div style="position:absolute;left:297.45px;top:186.99px" class="cls_023"><span class="cls_023">0.2</span></div>
<div style="position:absolute;left:325.45px;top:186.99px" class="cls_023"><span class="cls_023">euclidean   Yes(to 3)    Yes</span></div>
<div style="position:absolute;left:124.80px;top:215.71px" class="cls_008"><span class="cls_008">As described in chapter 5.3, we used the proposed way of setting M inP ts and</span></div>
<div style="position:absolute;left:124.80px;top:227.66px" class="cls_008"><span class="cls_008">eps parameters.  M inP ts is set as 2 × dimension (features).  For five features</span></div>
<div style="position:absolute;left:124.80px;top:239.62px" class="cls_008"><span class="cls_008">the following sorted k-dist graph can be seen in figure 6.30 below.</span></div>
<div style="position:absolute;left:139.95px;top:416.40px" class="cls_008"><span class="cls_008">Figure 6.30: Sorted k-dist graph proposes the eps value for five features</span></div>
<div style="position:absolute;left:124.80px;top:455.85px" class="cls_007"><span class="cls_007">Result</span></div>
<div style="position:absolute;left:124.80px;top:474.24px" class="cls_008"><span class="cls_008">In addition to all the features used in the experiment for four features, we added</span></div>
<div style="position:absolute;left:124.80px;top:486.19px" class="cls_008"><span class="cls_008">a fifth categorical feature, working time arrangement (WTA). As this feature</span></div>
<div style="position:absolute;left:124.80px;top:498.15px" class="cls_008"><span class="cls_008">contains categorical values, and the algorithms only take numerical values, we</span></div>
<div style="position:absolute;left:124.80px;top:510.10px" class="cls_008"><span class="cls_008">had to convert this to numbers.  For this we applied one hot encoding as de-</span></div>
<div style="position:absolute;left:124.80px;top:522.06px" class="cls_008"><span class="cls_008">scribed in section 5.3.  The data was scaled and had PCA applied, and the</span></div>
<div style="position:absolute;left:124.80px;top:534.01px" class="cls_008"><span class="cls_008">parameters M inP ts and eps was changed with regards to the method described</span></div>
<div style="position:absolute;left:124.80px;top:545.97px" class="cls_008"><span class="cls_008">in 5.3. In total, 503 data points were labeled as outliers which is 0.503% of the</span></div>
<div style="position:absolute;left:124.80px;top:557.92px" class="cls_008"><span class="cls_008">total data.</span></div>
<div style="position:absolute;left:139.75px;top:581.83px" class="cls_008"><span class="cls_008">Initially, the main difference between the previous graphs figure 6.23 and</span></div>
<div style="position:absolute;left:124.80px;top:593.79px" class="cls_008"><span class="cls_008">figure 6.16, is that we can observe two larger clusters in figure 6.31, which is</span></div>
<div style="position:absolute;left:124.80px;top:605.75px" class="cls_008"><span class="cls_008">quite interesting. The new feature added as a one hot encoded vector, reshaped</span></div>
<div style="position:absolute;left:124.80px;top:617.70px" class="cls_008"><span class="cls_008">the data. We still find that the outliers lie outside of dense areas.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">83</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:73186px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background087.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:286.00px" class="cls_008"><span class="cls_008">Figure 6.31: 3D graph showing the output from DBSCAN. Data is reduced to</span></div>
<div style="position:absolute;left:124.80px;top:297.95px" class="cls_008"><span class="cls_008">three dimensions with PCA. Outliers are colored blue, while inliers are colored</span></div>
<div style="position:absolute;left:124.80px;top:309.91px" class="cls_008"><span class="cls_008">yellow.</span></div>
<div style="position:absolute;left:139.75px;top:347.37px" class="cls_008"><span class="cls_008">Separating the outliers from the inliers in figure 6.33, we can observe the two</span></div>
<div style="position:absolute;left:124.80px;top:359.32px" class="cls_008"><span class="cls_008">main clusters creates a smooth surface.  From the output of the algorithm in</span></div>
<div style="position:absolute;left:124.80px;top:371.28px" class="cls_008"><span class="cls_008">figure 6.32, we recognize two large clusters consisting of 84550 and 12722 data</span></div>
<div style="position:absolute;left:124.80px;top:383.23px" class="cls_008"><span class="cls_008">points. (Notice the -1 which represents the amount of outliers).</span></div>
<div style="position:absolute;left:124.80px;top:428.14px" class="cls_008"><span class="cls_008">Figure 6.32: Output of DBSCAN, representing different clusters and the amount</span></div>
<div style="position:absolute;left:124.80px;top:440.10px" class="cls_008"><span class="cls_008">of data points in them.</span></div>
<div style="position:absolute;left:124.80px;top:646.11px" class="cls_008"><span class="cls_008">Figure 6.33:  Two 3D graphs showing the separated inliers and outliers from</span></div>
<div style="position:absolute;left:124.80px;top:658.06px" class="cls_008"><span class="cls_008">DBSCAN. Outliers are colored blue, while inliers are colored yellow.</span></div>
<div style="position:absolute;left:139.75px;top:695.52px" class="cls_008"><span class="cls_008">The distribution regarding the outliers for PPD, hours worked and FTE</span></div>
<div style="position:absolute;left:124.80px;top:707.48px" class="cls_008"><span class="cls_008">percentage has not changed noticeably compared to the previous experiments.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">84</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:74037px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background088.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">On the other hand, we observe a higher frequency of data points with 0 for total</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">income.</span></div>
<div style="position:absolute;left:124.80px;top:584.33px" class="cls_008"><span class="cls_008">Figure 6.34: Histogram of the distributions of total income, PPD, hours worked</span></div>
<div style="position:absolute;left:124.80px;top:596.29px" class="cls_008"><span class="cls_008">and FTE percentage in that order.</span></div>
<div style="position:absolute;left:139.75px;top:633.75px" class="cls_008"><span class="cls_008">For the distribution of the new feature, WTA, we notice that more than half</span></div>
<div style="position:absolute;left:124.80px;top:645.70px" class="cls_008"><span class="cls_008">of the outliers have "ikkeSkift" as its value.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">85</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:74888px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background089.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:340.53px" class="cls_008"><span class="cls_008">Figure 6.35:  Histogram showing the distribution of inliers (left) and outliers</span></div>
<div style="position:absolute;left:124.80px;top:352.49px" class="cls_008"><span class="cls_008">(right) with respect to WTA.</span></div>
<div style="position:absolute;left:124.80px;top:391.93px" class="cls_007"><span class="cls_007">Key observations</span></div>
<div style="position:absolute;left:139.75px;top:410.32px" class="cls_008"><span class="cls_008">- Similarly with the previous experiments, most of the outliers lie outside</span></div>
<div style="position:absolute;left:149.71px;top:422.28px" class="cls_008"><span class="cls_008">the dense area of data. In this case, we can observe two distinct clusters</span></div>
<div style="position:absolute;left:149.71px;top:434.23px" class="cls_008"><span class="cls_008">from which the outliers are extracted.</span></div>
<div style="position:absolute;left:139.75px;top:454.16px" class="cls_008"><span class="cls_008">- Histograms showing the distribution of the different features seem mostly</span></div>
<div style="position:absolute;left:149.71px;top:466.11px" class="cls_008"><span class="cls_008">the same compared with the other experiments, except for the 0-bin in</span></div>
<div style="position:absolute;left:149.71px;top:478.07px" class="cls_008"><span class="cls_008">total income outliers.  This suggests that the different experiments does</span></div>
<div style="position:absolute;left:149.71px;top:490.02px" class="cls_008"><span class="cls_008">not locate all the same data points as outliers.</span></div>
<div style="position:absolute;left:124.80px;top:515.92px" class="cls_017"><span class="cls_017">6.2.4</span></div>
<div style="position:absolute;left:165.90px;top:515.92px" class="cls_017"><span class="cls_017">Comparing DBSCAN results</span></div>
<div style="position:absolute;left:124.80px;top:536.30px" class="cls_008"><span class="cls_008">In order to visualize and see the overlap between the different experiments,</span></div>
<div style="position:absolute;left:124.80px;top:548.26px" class="cls_008"><span class="cls_008">we created a Venn diagram with the results from the different experiments.</span></div>
<div style="position:absolute;left:124.80px;top:560.21px" class="cls_008"><span class="cls_008">From figure 6.36, we observe an overlap of 776 outlier points between three</span></div>
<div style="position:absolute;left:124.80px;top:572.17px" class="cls_008"><span class="cls_008">and four features.  The overlap contains roughly 86% of the outliers found for</span></div>
<div style="position:absolute;left:124.80px;top:584.12px" class="cls_008"><span class="cls_008">four features.  In addition, we can see an overlap of 366 points between four</span></div>
<div style="position:absolute;left:124.80px;top:596.08px" class="cls_008"><span class="cls_008">and five features which anount to around 72% of the outliers found for five</span></div>
<div style="position:absolute;left:124.80px;top:608.03px" class="cls_008"><span class="cls_008">features.  This suggests that most of the data points labeled as outliers in the</span></div>
<div style="position:absolute;left:124.80px;top:619.99px" class="cls_008"><span class="cls_008">experiments identifies mostly the same outliers.</span></div>
<div style="position:absolute;left:348.85px;top:619.99px" class="cls_008"><span class="cls_008">294 points are overlapping</span></div>
<div style="position:absolute;left:124.80px;top:631.94px" class="cls_008"><span class="cls_008">between all experiments. As we can not determine which data points qualified</span></div>
<div style="position:absolute;left:124.80px;top:643.90px" class="cls_008"><span class="cls_008">as anomalous or not, it is difficult to assume something about which of the</span></div>
<div style="position:absolute;left:124.80px;top:655.85px" class="cls_008"><span class="cls_008">datasets performed best. It would be interesting to further consult the domain</span></div>
<div style="position:absolute;left:124.80px;top:667.81px" class="cls_008"><span class="cls_008">experts from the NTA and to use it on production data for each predicted</span></div>
<div style="position:absolute;left:124.80px;top:679.76px" class="cls_008"><span class="cls_008">outlier, and investigate the points even further.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">86</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:75739px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background090.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:462.54px" class="cls_008"><span class="cls_008">Figure 6.36:  Venn diagram showing the similar outliers of the three distinct</span></div>
<div style="position:absolute;left:124.80px;top:474.49px" class="cls_008"><span class="cls_008">experiments.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">87</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:76590px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background091.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:120.52px" class="cls_010"><span class="cls_010">6.3</span></div>
<div style="position:absolute;left:161.56px;top:120.52px" class="cls_010"><span class="cls_010">Results - Local Outlier Factor</span></div>
<div style="position:absolute;left:124.80px;top:146.73px" class="cls_008"><span class="cls_008">This section shows the results for Local Outlier Factor. As shown in the table</span></div>
<div style="position:absolute;left:124.80px;top:158.68px" class="cls_008"><span class="cls_008">below, the data was scaled using Scikit-learns StandardScaler. For this experi-</span></div>
<div style="position:absolute;left:124.80px;top:170.64px" class="cls_008"><span class="cls_008">ment, the algorithm will compare the lrd of each data point with respect to 25</span></div>
<div style="position:absolute;left:124.80px;top:182.59px" class="cls_008"><span class="cls_008">of its nearest neighbors, and select the top 2.5 percentage of the highest scores</span></div>
<div style="position:absolute;left:124.80px;top:194.55px" class="cls_008"><span class="cls_008">as outliers.</span></div>
<div style="position:absolute;left:124.80px;top:220.45px" class="cls_017"><span class="cls_017">6.3.1</span></div>
<div style="position:absolute;left:165.90px;top:220.45px" class="cls_017"><span class="cls_017">Three Features</span></div>
<div style="position:absolute;left:124.80px;top:240.83px" class="cls_007"><span class="cls_007">Data set and Parameters</span></div>
<div style="position:absolute;left:135.87px;top:269.08px" class="cls_024"><span class="cls_024">Features   Algorithm   N-neighbors</span></div>
<div style="position:absolute;left:296.62px;top:269.08px" class="cls_024"><span class="cls_024">Metric</span></div>
<div style="position:absolute;left:339.13px;top:269.08px" class="cls_024"><span class="cls_024">Contamination   PCA   Scale</span></div>
<div style="position:absolute;left:150.42px;top:282.58px" class="cls_024"><span class="cls_024">3</span></div>
<div style="position:absolute;left:191.51px;top:282.58px" class="cls_024"><span class="cls_024">LOF</span></div>
<div style="position:absolute;left:251.68px;top:282.58px" class="cls_024"><span class="cls_024">25</span></div>
<div style="position:absolute;left:291.18px;top:282.58px" class="cls_024"><span class="cls_024">euclidean</span></div>
<div style="position:absolute;left:358.52px;top:282.58px" class="cls_024"><span class="cls_024">0.025</span></div>
<div style="position:absolute;left:413.75px;top:282.58px" class="cls_024"><span class="cls_024">No     Yes</span></div>
<div style="position:absolute;left:124.80px;top:309.31px" class="cls_007"><span class="cls_007">Results</span></div>
<div style="position:absolute;left:124.80px;top:327.69px" class="cls_008"><span class="cls_008">In figure 6.37, the data is presented as a 3-dimensional scatter plot. The outliers</span></div>
<div style="position:absolute;left:124.80px;top:339.65px" class="cls_008"><span class="cls_008">are colored blue while the inliers are yellow. The red circles depicts the LOF-</span></div>
<div style="position:absolute;left:124.80px;top:351.60px" class="cls_008"><span class="cls_008">score of the point they surround. A higher LOF-score is indicated by a larger</span></div>
<div style="position:absolute;left:124.80px;top:363.56px" class="cls_008"><span class="cls_008">circle.  We also observe that most of the 2500 outliers are located within the</span></div>
<div style="position:absolute;left:124.80px;top:375.52px" class="cls_008"><span class="cls_008">area of highest density. This is because the LOF algorithm specializes in finding</span></div>
<div style="position:absolute;left:124.80px;top:387.47px" class="cls_008"><span class="cls_008">local outliers. The more ’obvious’ outliers that are located at the edges of the</span></div>
<div style="position:absolute;left:124.80px;top:399.43px" class="cls_008"><span class="cls_008">3D space has a very small red circle.</span></div>
<div style="position:absolute;left:124.80px;top:601.33px" class="cls_008"><span class="cls_008">Figure 6.37:  Identical 3D plots of three featured data set from distinct view</span></div>
<div style="position:absolute;left:124.80px;top:613.29px" class="cls_008"><span class="cls_008">angles.  Outliers are colored blue, while inliers are colored yellow.  Red circle</span></div>
<div style="position:absolute;left:124.80px;top:625.24px" class="cls_008"><span class="cls_008">defines the LOF-score of outliers.</span></div>
<div style="position:absolute;left:139.75px;top:662.70px" class="cls_008"><span class="cls_008">Limiting the X,Y,Z of the graph, we can inspect the local outliers within the</span></div>
<div style="position:absolute;left:124.80px;top:674.66px" class="cls_008"><span class="cls_008">dense area of figure 6.38. Observing the outliers on the bottom right side of the</span></div>
<div style="position:absolute;left:124.80px;top:686.61px" class="cls_008"><span class="cls_008">figure with the largest radius of red circles, we clearly see that these data points</span></div>
<div style="position:absolute;left:124.80px;top:698.57px" class="cls_008"><span class="cls_008">are located in a sparse area relative to the dense area.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">88</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:77441px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background092.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:280.17px" class="cls_008"><span class="cls_008">Figure 6.38:  Identical 3D plots of three featured data set from distinct view</span></div>
<div style="position:absolute;left:124.80px;top:292.13px" class="cls_008"><span class="cls_008">angles.  Outliers are colored blue, while inliers are colored yellow.  Red circle</span></div>
<div style="position:absolute;left:124.80px;top:304.08px" class="cls_008"><span class="cls_008">defines the LOF-score of outliers.</span></div>
<div style="position:absolute;left:139.75px;top:341.54px" class="cls_008"><span class="cls_008">In figure 6.39 and 6.40, we find the extreme values of the outliers sorted by</span></div>
<div style="position:absolute;left:124.80px;top:353.50px" class="cls_008"><span class="cls_008">hours worked and FTE percentage.  Inspecting these results, we see abnormal</span></div>
<div style="position:absolute;left:124.80px;top:365.45px" class="cls_008"><span class="cls_008">values with respect to normal values of monthly hours worked and FTE per-</span></div>
<div style="position:absolute;left:124.80px;top:377.41px" class="cls_008"><span class="cls_008">centage. For hours worked, we can observe values ranging from negative -488,</span></div>
<div style="position:absolute;left:124.80px;top:389.36px" class="cls_008"><span class="cls_008">to positive 4156. For FTE percentage the extreme values are ranging from 500</span></div>
<div style="position:absolute;left:124.80px;top:401.32px" class="cls_008"><span class="cls_008">up to 2560.  In addition, we see from the left of figure 6.39, zero-values are</span></div>
<div style="position:absolute;left:124.80px;top:413.27px" class="cls_008"><span class="cls_008">reported for both hours worked and FTE percentage, but are still reported with</span></div>
<div style="position:absolute;left:124.80px;top:425.23px" class="cls_008"><span class="cls_008">an income.</span></div>
<div style="position:absolute;left:124.80px;top:615.62px" class="cls_008"><span class="cls_008">Figure 6.39: Values for</span><span class="cls_007"> outliers</span><span class="cls_008"> sorted ascending (left) and descending (right)</span></div>
<div style="position:absolute;left:124.80px;top:627.58px" class="cls_008"><span class="cls_008">by FTE percentage.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">89</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:78292px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background093.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:291.16px" class="cls_008"><span class="cls_008">Figure 6.40: Values for</span><span class="cls_007"> outliers</span><span class="cls_008"> sorted ascending (left) and descending (right)</span></div>
<div style="position:absolute;left:124.80px;top:303.12px" class="cls_008"><span class="cls_008">by hours worked.</span></div>
<div style="position:absolute;left:139.75px;top:330.61px" class="cls_008"><span class="cls_008">Comparing these findings with the extreme values for the</span><span class="cls_007"> inliers</span><span class="cls_008">, we still</span></div>
<div style="position:absolute;left:124.80px;top:342.57px" class="cls_008"><span class="cls_008">observe similar abnormal values for hours worked, with numbers ranging from</span></div>
<div style="position:absolute;left:124.80px;top:354.52px" class="cls_008"><span class="cls_008">-162 up to 1702.  These extreme positive values are somewhat strange, since</span></div>
<div style="position:absolute;left:124.80px;top:366.48px" class="cls_008"><span class="cls_008">the maximum amount of hours in one month is 744 hours. This indicates that</span></div>
<div style="position:absolute;left:124.80px;top:378.43px" class="cls_008"><span class="cls_008">these data points are located in areas where the 25 nearest neighbouring data</span></div>
<div style="position:absolute;left:124.80px;top:390.39px" class="cls_008"><span class="cls_008">points share a similar lrd and the algorithm not able to label these as outliers.</span></div>
<div style="position:absolute;left:124.80px;top:402.34px" class="cls_008"><span class="cls_008">This shows a further need to tune the parameters to be able to pick these up as</span></div>
<div style="position:absolute;left:124.80px;top:414.30px" class="cls_008"><span class="cls_008">outliers.</span></div>
<div style="position:absolute;left:124.80px;top:604.01px" class="cls_008"><span class="cls_008">Figure 6.41:  Values for</span><span class="cls_007"> inliers</span><span class="cls_008"> sorted ascending (left) and descending (right)</span></div>
<div style="position:absolute;left:124.80px;top:615.96px" class="cls_008"><span class="cls_008">by hours worked.</span></div>
<div style="position:absolute;left:139.75px;top:643.46px" class="cls_008"><span class="cls_008">In figure 6.42, 6.43 and 6.44 we observe the distribution of values for each</span></div>
<div style="position:absolute;left:124.80px;top:655.41px" class="cls_008"><span class="cls_008">feature in the data set.  On the left in all figures, we show the distribution of</span></div>
<div style="position:absolute;left:124.80px;top:667.37px" class="cls_008"><span class="cls_008">outliers, and on the right we find the inliers.</span></div>
<div style="position:absolute;left:139.75px;top:679.33px" class="cls_008"><span class="cls_008">Observing figure 6.42, the distribution of values for the outliers appears to</span></div>
<div style="position:absolute;left:124.80px;top:691.28px" class="cls_008"><span class="cls_008">be similar to the distribution of the inliers. We found that the highest frequency</span></div>
<div style="position:absolute;left:124.80px;top:703.24px" class="cls_008"><span class="cls_008">is 0, showing that over 200 of the outliers have 0 as total income.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">90</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:79143px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background094.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:283.01px" class="cls_008"><span class="cls_008">Figure 6.42:  Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:124.80px;top:294.96px" class="cls_008"><span class="cls_008">regards to total income</span></div>
<div style="position:absolute;left:139.75px;top:332.42px" class="cls_008"><span class="cls_008">Figure 6.43 describes the distribution with respect to hours worked. We can</span></div>
<div style="position:absolute;left:124.80px;top:344.38px" class="cls_008"><span class="cls_008">observe most of the outliers contain value of around 160 hours worked monthly.</span></div>
<div style="position:absolute;left:124.80px;top:356.33px" class="cls_008"><span class="cls_008">Over 1200 of the 2500 total outliers has this value as hours worked. Examining</span></div>
<div style="position:absolute;left:124.80px;top:368.29px" class="cls_008"><span class="cls_008">the inlier distribution, we see a wide spread range of different hours worked,</span></div>
<div style="position:absolute;left:124.80px;top:380.24px" class="cls_008"><span class="cls_008">thinning out from around 200 and up. Assuming outliers should lie in the most</span></div>
<div style="position:absolute;left:124.80px;top:392.20px" class="cls_008"><span class="cls_008">dense areas, the distribution of the outliers seems mostly to be correct with</span></div>
<div style="position:absolute;left:124.80px;top:404.15px" class="cls_008"><span class="cls_008">respect to only this feature, hours worked.</span></div>
<div style="position:absolute;left:124.80px;top:580.23px" class="cls_008"><span class="cls_008">Figure 6.43:  Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:124.80px;top:592.19px" class="cls_008"><span class="cls_008">regards to hours worked</span></div>
<div style="position:absolute;left:139.75px;top:629.64px" class="cls_008"><span class="cls_008">As for the distribution with respect to FTE percentage, over 2000 of the</span></div>
<div style="position:absolute;left:124.80px;top:641.60px" class="cls_008"><span class="cls_008">2500 total outliers contain a value of 100.  And almost 250 outliers contain</span></div>
<div style="position:absolute;left:124.80px;top:653.56px" class="cls_008"><span class="cls_008">0. With respect to the inliers, these graphs seems almost identical in terms of</span></div>
<div style="position:absolute;left:124.80px;top:665.51px" class="cls_008"><span class="cls_008">distribution. As the outliers reported by LOF tend to appear in denser areas,</span></div>
<div style="position:absolute;left:124.80px;top:677.47px" class="cls_008"><span class="cls_008">these findings is probably correct.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">91</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:79994px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background095.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:277.85px" class="cls_008"><span class="cls_008">Figure 6.44:  Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:124.80px;top:289.80px" class="cls_008"><span class="cls_008">regards to FTE percentage</span></div>
<div style="position:absolute;left:124.80px;top:329.25px" class="cls_007"><span class="cls_007">Key observations</span></div>
<div style="position:absolute;left:139.75px;top:347.64px" class="cls_008"><span class="cls_008">- Most of the outliers do not contain any extreme values in any of the three</span></div>
<div style="position:absolute;left:149.71px;top:359.59px" class="cls_008"><span class="cls_008">features which again indicates that most of the outliers lie within the dense</span></div>
<div style="position:absolute;left:149.71px;top:371.55px" class="cls_008"><span class="cls_008">areas of the dataset.  Viewing the graph in figure 6.37, this makes sense</span></div>
<div style="position:absolute;left:149.71px;top:383.50px" class="cls_008"><span class="cls_008">as the data points with the largest surrounding red circles are located in</span></div>
<div style="position:absolute;left:149.71px;top:395.46px" class="cls_008"><span class="cls_008">the areas of highest density.</span></div>
<div style="position:absolute;left:139.75px;top:415.38px" class="cls_008"><span class="cls_008">- As the input dataset is just a small sample compared to the complete set,</span></div>
<div style="position:absolute;left:149.71px;top:427.34px" class="cls_008"><span class="cls_008">the outliers might not be labeled as outliers if a larger dataset were used.</span></div>
<div style="position:absolute;left:139.75px;top:447.26px" class="cls_008"><span class="cls_008">- LOF is somewhat able to detect outliers with extreme values, but if those</span></div>
<div style="position:absolute;left:149.71px;top:459.22px" class="cls_008"><span class="cls_008">values lie within the same average euclidean distance to each other, they</span></div>
<div style="position:absolute;left:149.71px;top:471.17px" class="cls_008"><span class="cls_008">might still be labeled as inliers because of the n − neighbours parameter.</span></div>
<div style="position:absolute;left:139.75px;top:493.09px" class="cls_008"><span class="cls_008">To demonstrate the third key observation we set the n-neighbors parameter</span></div>
<div style="position:absolute;left:124.80px;top:505.05px" class="cls_008"><span class="cls_008">to 5, using the same data set. We obtained the following graph in figure 6.45.</span></div>
<div style="position:absolute;left:124.80px;top:517.00px" class="cls_008"><span class="cls_008">We see that LOF now considers many of the previous global outliers from figure</span></div>
<div style="position:absolute;left:124.80px;top:528.96px" class="cls_008"><span class="cls_008">6.41 as inliers.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">92</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:80845px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background096.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:303.34px" class="cls_008"><span class="cls_008">Figure 6.45:  Identical 3D plots of three featured data set from distinct view</span></div>
<div style="position:absolute;left:124.80px;top:315.30px" class="cls_008"><span class="cls_008">angles.  Outliers are colored blue, while inliers are colored yellow.  Red circle</span></div>
<div style="position:absolute;left:124.80px;top:327.25px" class="cls_008"><span class="cls_008">defines the LOF-score of outliers.</span></div>
<div style="position:absolute;left:124.80px;top:366.69px" class="cls_017"><span class="cls_017">6.3.2</span></div>
<div style="position:absolute;left:165.90px;top:366.69px" class="cls_017"><span class="cls_017">Four Features</span></div>
<div style="position:absolute;left:124.80px;top:387.08px" class="cls_007"><span class="cls_007">Dataset and Parameters</span></div>
<div style="position:absolute;left:135.35px;top:415.38px" class="cls_025"><span class="cls_025">Features   Algorithm   N-neighbors</span></div>
<div style="position:absolute;left:288.56px;top:415.38px" class="cls_025"><span class="cls_025">Metric</span></div>
<div style="position:absolute;left:329.08px;top:415.38px" class="cls_025"><span class="cls_025">Contamination</span></div>
<div style="position:absolute;left:404.34px;top:415.38px" class="cls_025"><span class="cls_025">PCA     Scale</span></div>
<div style="position:absolute;left:149.22px;top:428.25px" class="cls_025"><span class="cls_025">4</span></div>
<div style="position:absolute;left:188.39px;top:428.25px" class="cls_025"><span class="cls_025">LOF</span></div>
<div style="position:absolute;left:245.73px;top:428.25px" class="cls_025"><span class="cls_025">25</span></div>
<div style="position:absolute;left:283.38px;top:428.25px" class="cls_025"><span class="cls_025">euclidean</span></div>
<div style="position:absolute;left:347.56px;top:428.25px" class="cls_025"><span class="cls_025">0.025</span></div>
<div style="position:absolute;left:396.28px;top:428.25px" class="cls_025"><span class="cls_025">Yes(to 3)    Yes</span></div>
<div style="position:absolute;left:124.80px;top:454.37px" class="cls_007"><span class="cls_007">Result</span></div>
<div style="position:absolute;left:124.80px;top:472.76px" class="cls_008"><span class="cls_008">For this data set containing four features, we implemented PCA to reduce the</span></div>
<div style="position:absolute;left:124.80px;top:484.72px" class="cls_008"><span class="cls_008">number of dimensions to three. Below in figure 5.31, we plotted these three new</span></div>
<div style="position:absolute;left:124.80px;top:496.67px" class="cls_008"><span class="cls_008">dimensions, PC1,PC2 and PC3, to visualize the output of the LOF algorithm.</span></div>
<div style="position:absolute;left:124.80px;top:508.63px" class="cls_008"><span class="cls_008">As we set the contamination parameter to 0.025, the amount of data points</span></div>
<div style="position:absolute;left:124.80px;top:520.58px" class="cls_008"><span class="cls_008">labeled as outliers will be 2500.</span></div>
<div style="position:absolute;left:139.75px;top:544.49px" class="cls_008"><span class="cls_008">Initially we can observe a lot of the global secluded data points being labeled</span></div>
<div style="position:absolute;left:124.80px;top:556.45px" class="cls_008"><span class="cls_008">as outliers with regards to the n-neighbors parameter.  But similarly with the</span></div>
<div style="position:absolute;left:124.80px;top:568.40px" class="cls_008"><span class="cls_008">3D graph showing the three featured data set in figure 6.37, the data points</span></div>
<div style="position:absolute;left:124.80px;top:580.36px" class="cls_008"><span class="cls_008">with the highest LOF-score lies within the densest areas.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">93</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:81696px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background097.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:296.08px" class="cls_008"><span class="cls_008">Figure 6.46:  Identical 3D plots of four featured data set from distinct view</span></div>
<div style="position:absolute;left:124.80px;top:308.04px" class="cls_008"><span class="cls_008">angles. Data is reduced to three dimensions with PCA. Outliers are colored blue,</span></div>
<div style="position:absolute;left:124.80px;top:319.99px" class="cls_008"><span class="cls_008">while inliers are colored yellow. Red circle defines the LOF-score of outliers.</span></div>
<div style="position:absolute;left:139.75px;top:356.87px" class="cls_008"><span class="cls_008">Limiting the X,Y and Z axis, we can examine the most local outliers in figure</span></div>
<div style="position:absolute;left:124.80px;top:368.82px" class="cls_008"><span class="cls_008">6.47.  Similar to figure 6.38, the data points with the largest red circles lie in</span></div>
<div style="position:absolute;left:124.80px;top:380.78px" class="cls_008"><span class="cls_008">sparse areas relative to the dense. With regards to the different feature values</span></div>
<div style="position:absolute;left:124.80px;top:392.73px" class="cls_008"><span class="cls_008">of the local outliers, we can assume the distribution will be somewhat similar to</span></div>
<div style="position:absolute;left:124.80px;top:404.69px" class="cls_008"><span class="cls_008">the inlier distribution as we saw in the previous experiment with three features.</span></div>
<div style="position:absolute;left:124.80px;top:602.11px" class="cls_008"><span class="cls_008">Figure 6.47:  Identical 3D plots of four featured data set from distinct view</span></div>
<div style="position:absolute;left:124.80px;top:614.06px" class="cls_008"><span class="cls_008">angles. Data is reduced to three dimensions with PCA. Outliers are colored blue,</span></div>
<div style="position:absolute;left:124.80px;top:626.02px" class="cls_008"><span class="cls_008">while inliers are colored yellow. Red circle defines the LOF-score of outliers.</span></div>
<div style="position:absolute;left:139.75px;top:662.89px" class="cls_008"><span class="cls_008">Looking at the values for the outliers with the highest LOF-score in figure</span></div>
<div style="position:absolute;left:124.80px;top:674.85px" class="cls_008"><span class="cls_008">6.48, the most common observation is the zero-valued or low-valued PPD. In</span></div>
<div style="position:absolute;left:124.80px;top:686.80px" class="cls_008"><span class="cls_008">addition, most of the rows containing these zero-valued PPDs has a frequently</span></div>
<div style="position:absolute;left:124.80px;top:698.76px" class="cls_008"><span class="cls_008">high value for hours worked, as well as for FTE percentage, with a abnormally</span></div>
<div style="position:absolute;left:124.80px;top:710.71px" class="cls_008"><span class="cls_008">low total income. As we can not conclude anything based on these values alone,</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">94</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:82547px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background098.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">these are still the most "outlying" local outliers.</span></div>
<div style="position:absolute;left:158.88px;top:341.37px" class="cls_008"><span class="cls_008">Figure 6.48: Values for the outliers with the highest LOF-score</span></div>
<div style="position:absolute;left:139.75px;top:378.83px" class="cls_008"><span class="cls_008">Comparing the result from figure 6.42, the values in figure 6.49 seems more</span></div>
<div style="position:absolute;left:124.80px;top:390.78px" class="cls_008"><span class="cls_008">evenly spread in terms of distribution with a high frequency around 0.  This</span></div>
<div style="position:absolute;left:124.80px;top:402.74px" class="cls_008"><span class="cls_008">implies that a large batch of outliers contain a value around 0.</span></div>
<div style="position:absolute;left:134.36px;top:584.03px" class="cls_008"><span class="cls_008">Figure 6.49: Histogram of outliers and inliers with regards to total income</span></div>
<div style="position:absolute;left:139.75px;top:621.49px" class="cls_008"><span class="cls_008">Similarly with the histogram from the three featured data set in figure 6.43,</span></div>
<div style="position:absolute;left:124.80px;top:633.44px" class="cls_008"><span class="cls_008">we observe nearly equal distributions of features regarding FTE percentage (fig-</span></div>
<div style="position:absolute;left:124.80px;top:645.40px" class="cls_008"><span class="cls_008">ure 6.50) and hours worked (figure 6.51). About 1750 outliers contain the value</span></div>
<div style="position:absolute;left:124.80px;top:657.35px" class="cls_008"><span class="cls_008">of 100 for FTE percentage, and most of the hours worked distribution lies be-</span></div>
<div style="position:absolute;left:124.80px;top:669.31px" class="cls_008"><span class="cls_008">tween 100-160. This makes sense, as the total amount of data points for three</span></div>
<div style="position:absolute;left:124.80px;top:681.26px" class="cls_008"><span class="cls_008">features containing the same values, is around 70% of the data set.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">95</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:83398px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background099.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:279.51px" class="cls_008"><span class="cls_008">Figure 6.50:  Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:124.80px;top:291.47px" class="cls_008"><span class="cls_008">regards to FTE percentage</span></div>
<div style="position:absolute;left:124.80px;top:493.07px" class="cls_008"><span class="cls_008">Figure 6.51:  Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:124.80px;top:505.02px" class="cls_008"><span class="cls_008">regards to hours worked</span></div>
<div style="position:absolute;left:139.75px;top:542.48px" class="cls_008"><span class="cls_008">As for the distribution of prepayment deduction (figure 6.52), we observe a</span></div>
<div style="position:absolute;left:124.80px;top:554.44px" class="cls_008"><span class="cls_008">quite similar distribution with respect to the inliers. Over 400 outliers contain</span></div>
<div style="position:absolute;left:124.80px;top:566.39px" class="cls_008"><span class="cls_008">a zero-value for this feature, while the rest seems normally distributed.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">96</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:84249px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background100.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:275.35px" class="cls_008"><span class="cls_008">Figure 6.52:  Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:124.80px;top:287.31px" class="cls_008"><span class="cls_008">regards to "Forskuddstrekk"</span></div>
<div style="position:absolute;left:124.80px;top:326.75px" class="cls_007"><span class="cls_007">Key observations</span></div>
<div style="position:absolute;left:139.75px;top:345.14px" class="cls_008"><span class="cls_008">- Most of the outliers contain either regular values for all four features,</span></div>
<div style="position:absolute;left:149.71px;top:357.10px" class="cls_008"><span class="cls_008">except for a large batch of outliers containing zero-values for total income,</span></div>
<div style="position:absolute;left:149.71px;top:369.05px" class="cls_008"><span class="cls_008">hours worked and prepayment deduction.  This is similar with what was</span></div>
<div style="position:absolute;left:149.71px;top:381.01px" class="cls_008"><span class="cls_008">observed with the results for the three featured data set.</span></div>
<div style="position:absolute;left:139.75px;top:400.93px" class="cls_008"><span class="cls_008">- As the algorithms goal is to detect local outliers, it makes sense that many</span></div>
<div style="position:absolute;left:149.71px;top:412.89px" class="cls_008"><span class="cls_008">of the outliers contain high frequency values as they are located in dense</span></div>
<div style="position:absolute;left:149.71px;top:424.84px" class="cls_008"><span class="cls_008">areas of the data, similarly with the experiment with three features.</span></div>
<div style="position:absolute;left:124.80px;top:450.74px" class="cls_017"><span class="cls_017">6.3.3</span></div>
<div style="position:absolute;left:165.90px;top:450.74px" class="cls_017"><span class="cls_017">Five Features</span></div>
<div style="position:absolute;left:124.80px;top:471.12px" class="cls_007"><span class="cls_007">Data set and Parameters</span></div>
<div style="position:absolute;left:135.35px;top:499.43px" class="cls_025"><span class="cls_025">Features   Algorithm   N-neighbors</span></div>
<div style="position:absolute;left:288.56px;top:499.43px" class="cls_025"><span class="cls_025">Metric</span></div>
<div style="position:absolute;left:329.08px;top:499.43px" class="cls_025"><span class="cls_025">Contamination</span></div>
<div style="position:absolute;left:404.34px;top:499.43px" class="cls_025"><span class="cls_025">PCA     Scale</span></div>
<div style="position:absolute;left:149.22px;top:512.30px" class="cls_025"><span class="cls_025">5</span></div>
<div style="position:absolute;left:188.39px;top:512.30px" class="cls_025"><span class="cls_025">LOF</span></div>
<div style="position:absolute;left:245.73px;top:512.30px" class="cls_025"><span class="cls_025">25</span></div>
<div style="position:absolute;left:283.38px;top:512.30px" class="cls_025"><span class="cls_025">euclidean</span></div>
<div style="position:absolute;left:347.56px;top:512.30px" class="cls_025"><span class="cls_025">0.025</span></div>
<div style="position:absolute;left:396.28px;top:512.30px" class="cls_025"><span class="cls_025">Yes(to 3)    Yes</span></div>
<div style="position:absolute;left:124.80px;top:538.42px" class="cls_007"><span class="cls_007">Results</span></div>
<div style="position:absolute;left:124.80px;top:556.81px" class="cls_008"><span class="cls_008">For the last experiment we added the feature WTA. This being a categorical</span></div>
<div style="position:absolute;left:124.80px;top:568.76px" class="cls_008"><span class="cls_008">value we first had to apply one hot encoding (see 5.1.1). We also implemented</span></div>
<div style="position:absolute;left:124.80px;top:580.72px" class="cls_008"><span class="cls_008">PCA to reduce the number of dimensions from five to three. Below in figure 6.53</span></div>
<div style="position:absolute;left:124.80px;top:592.67px" class="cls_008"><span class="cls_008">we see a 3D visualization of the output with five features. The contamination</span></div>
<div style="position:absolute;left:124.80px;top:604.63px" class="cls_008"><span class="cls_008">is still</span></div>
<div style="position:absolute;left:155.80px;top:604.63px" class="cls_008"><span class="cls_008">0.025, meaning that the algorithm will output the 2500 most outlying</span></div>
<div style="position:absolute;left:124.80px;top:616.58px" class="cls_008"><span class="cls_008">points.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">97</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:85100px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background101.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:285.02px" class="cls_008"><span class="cls_008">Figure 6.53: Identical 3D plots of five featured dataset from distinct view angles.</span></div>
<div style="position:absolute;left:124.80px;top:296.97px" class="cls_008"><span class="cls_008">Outliers are colored blue, while inliers are colored yellow. Red circle defines the</span></div>
<div style="position:absolute;left:124.80px;top:308.93px" class="cls_008"><span class="cls_008">LOF-score of outliers.</span></div>
<div style="position:absolute;left:124.80px;top:523.44px" class="cls_008"><span class="cls_008">Figure 6.54: Identical 3D plots of five featured dataset from distinct view angles.</span></div>
<div style="position:absolute;left:124.80px;top:535.39px" class="cls_008"><span class="cls_008">Outliers are colored blue, while inliers are colored yellow. Red circle defines the</span></div>
<div style="position:absolute;left:124.80px;top:547.35px" class="cls_008"><span class="cls_008">LOF-score of outliers.</span></div>
<div style="position:absolute;left:139.75px;top:584.81px" class="cls_008"><span class="cls_008">From the histograms (figure 6.55) for all five features we find that the dis-</span></div>
<div style="position:absolute;left:124.80px;top:596.76px" class="cls_008"><span class="cls_008">tribution of where we find outliers, with regards to total income, were mostly</span></div>
<div style="position:absolute;left:124.80px;top:608.72px" class="cls_008"><span class="cls_008">in the same range as the previous experiment with four features. When looking</span></div>
<div style="position:absolute;left:124.80px;top:620.67px" class="cls_008"><span class="cls_008">at PPD, hours worked and FTE percentage we find that the same applies for</span></div>
<div style="position:absolute;left:124.80px;top:632.63px" class="cls_008"><span class="cls_008">these as well, with only minor differences. This might indicate that LOF with</span></div>
<div style="position:absolute;left:124.80px;top:644.58px" class="cls_008"><span class="cls_008">five features registers mostly the same outliers as with four.</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">98</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:85951px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background102.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:543.98px" class="cls_008"><span class="cls_008">Figure 6.55: Histogram of the distributions of total income, prepayment deduc-</span></div>
<div style="position:absolute;left:124.80px;top:555.94px" class="cls_008"><span class="cls_008">tion, hours worked and FTE percentage in that order.</span></div>
<div style="position:absolute;left:139.75px;top:593.39px" class="cls_008"><span class="cls_008">When looking at the distribution of outliers and inliers with respect to WTA</span></div>
<div style="position:absolute;left:124.80px;top:605.35px" class="cls_008"><span class="cls_008">(figure 6.56) we find that the outliers seems to be distributed among all the</span></div>
<div style="position:absolute;left:124.80px;top:617.31px" class="cls_008"><span class="cls_008">different values for WTA in the same fashion as the inliers.  This might be a</span></div>
<div style="position:absolute;left:124.80px;top:629.26px" class="cls_008"><span class="cls_008">coincidence or it might indicate that the WTA values are not very relevant for</span></div>
<div style="position:absolute;left:124.80px;top:641.22px" class="cls_008"><span class="cls_008">the detection of outliers.  The latter can be supported by also looking at the</span></div>
<div style="position:absolute;left:124.80px;top:653.17px" class="cls_008"><span class="cls_008">Venn diagram comparing the algorithm on different numbers of features (figure</span></div>
<div style="position:absolute;left:124.80px;top:665.13px" class="cls_008"><span class="cls_008">6.57).</span></div>
<div style="position:absolute;left:291.68px;top:740.60px" class="cls_008"><span class="cls_008">99</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:86802px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background103.jpg" width=595 height=841></div>
<div style="position:absolute;left:126.02px;top:335.76px" class="cls_008"><span class="cls_008">Figure 6.56: Barplot of inliers (left) and outliers (right) with respect to WTA.</span></div>
<div style="position:absolute;left:124.80px;top:375.20px" class="cls_007"><span class="cls_007">Comparing LOF results</span></div>
<div style="position:absolute;left:124.80px;top:393.59px" class="cls_008"><span class="cls_008">When plotting the results for the three experiments in a Venn diagram (figure</span></div>
<div style="position:absolute;left:124.80px;top:405.54px" class="cls_008"><span class="cls_008">6.57) we see that the the experiments for four and five features have much more</span></div>
<div style="position:absolute;left:124.80px;top:417.50px" class="cls_008"><span class="cls_008">in common than the experiment with three. We had expected the results to be</span></div>
<div style="position:absolute;left:124.80px;top:429.45px" class="cls_008"><span class="cls_008">somewhat different as we believed that increasing the number of features would</span></div>
<div style="position:absolute;left:124.80px;top:441.41px" class="cls_008"><span class="cls_008">lead to the detection of different outliers. We did not however expect the results</span></div>
<div style="position:absolute;left:124.80px;top:453.37px" class="cls_008"><span class="cls_008">for four and five features to be this similar. This could indicate, as previously</span></div>
<div style="position:absolute;left:124.80px;top:465.32px" class="cls_008"><span class="cls_008">stated, that the feature WTA does not contribute anything significant to the</span></div>
<div style="position:absolute;left:124.80px;top:477.28px" class="cls_008"><span class="cls_008">results.  The WTA feature might have a stronger effect on the results if we</span></div>
<div style="position:absolute;left:124.80px;top:489.23px" class="cls_008"><span class="cls_008">included features that are more strongly related to the different possible WTA</span></div>
<div style="position:absolute;left:124.80px;top:501.19px" class="cls_008"><span class="cls_008">values.</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">100</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:87653px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background104.jpg" width=595 height=841></div>
<div style="position:absolute;left:272.08px;top:434.47px" class="cls_008"><span class="cls_008">Figure 6.57</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">101</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:88504px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background105.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:120.52px" class="cls_010"><span class="cls_010">6.4</span></div>
<div style="position:absolute;left:161.56px;top:120.52px" class="cls_010"><span class="cls_010">Results - Rare Itemset Mining</span></div>
<div style="position:absolute;left:124.80px;top:146.73px" class="cls_008"><span class="cls_008">Rare Itemset Mining differs from the three other algorithms used. As mentioned</span></div>
<div style="position:absolute;left:124.80px;top:158.68px" class="cls_008"><span class="cls_008">earlier, AprioriRare looks at the combinations of itemsets rather than the cat-</span></div>
<div style="position:absolute;left:124.80px;top:170.64px" class="cls_008"><span class="cls_008">egorical and numerical features. This means that we can expect the algorithm</span></div>
<div style="position:absolute;left:124.80px;top:182.59px" class="cls_008"><span class="cls_008">to detect a different set of anomalies compared to the other clustering methods.</span></div>
<div style="position:absolute;left:124.80px;top:194.55px" class="cls_008"><span class="cls_008">As with the other algorithms, we applied the algorithm on the same 100.000</span></div>
<div style="position:absolute;left:124.80px;top:206.51px" class="cls_008"><span class="cls_008">data points in order to be able to compare the results.</span></div>
<div style="position:absolute;left:124.80px;top:232.40px" class="cls_017"><span class="cls_017">6.4.1</span></div>
<div style="position:absolute;left:165.90px;top:232.40px" class="cls_017"><span class="cls_017">Three features</span></div>
<div style="position:absolute;left:124.80px;top:252.78px" class="cls_008"><span class="cls_008">Using AprioriRare with 0.015% minimal support on the features total income,</span></div>
<div style="position:absolute;left:124.80px;top:264.74px" class="cls_008"><span class="cls_008">FTE percentage, and hours worked, we got 1435 outliers.</span></div>
<div style="position:absolute;left:139.75px;top:276.69px" class="cls_008"><span class="cls_008">In most of the figures we see a strong similarity between the graphs for in-</span></div>
<div style="position:absolute;left:124.80px;top:288.65px" class="cls_008"><span class="cls_008">and outliers, the main difference being the sheer volume of inliers compared to</span></div>
<div style="position:absolute;left:124.80px;top:300.60px" class="cls_008"><span class="cls_008">outliers. This is to be expected, as the algorithm only considers combinations</span></div>
<div style="position:absolute;left:124.80px;top:312.56px" class="cls_008"><span class="cls_008">of values, not the individual values themselves.</span></div>
<div style="position:absolute;left:139.75px;top:324.51px" class="cls_008"><span class="cls_008">For total income (figure 6.58), there is a bigger emphasis on the lower end of</span></div>
<div style="position:absolute;left:124.80px;top:336.47px" class="cls_008"><span class="cls_008">the spectrum, and the largest peak in occurrences for the outliers is slightly lower</span></div>
<div style="position:absolute;left:124.80px;top:348.42px" class="cls_008"><span class="cls_008">than the peak for inliers. This indicates that the relative amount of outliers in</span></div>
<div style="position:absolute;left:124.80px;top:360.38px" class="cls_008"><span class="cls_008">the largest block is not too severe, most of the outliers are occurring outside the</span></div>
<div style="position:absolute;left:124.80px;top:372.33px" class="cls_008"><span class="cls_008">majority.</span></div>
<div style="position:absolute;left:146.58px;top:573.21px" class="cls_008"><span class="cls_008">Figure 6.58: Histogram of inliers and outliers related to total income</span></div>
<div style="position:absolute;left:139.75px;top:600.71px" class="cls_008"><span class="cls_008">For FTE percentage (figure 6.59), the overwhelming majority of inliers reside</span></div>
<div style="position:absolute;left:124.80px;top:612.66px" class="cls_008"><span class="cls_008">at 100%, while the outliers are a bit more evenly distributed. This again shows</span></div>
<div style="position:absolute;left:124.80px;top:624.62px" class="cls_008"><span class="cls_008">that a larger proportion of the outliers are distributed outside of the "normal"</span></div>
<div style="position:absolute;left:124.80px;top:636.57px" class="cls_008"><span class="cls_008">working conditions.</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">102</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:89355px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background106.jpg" width=595 height=841></div>
<div style="position:absolute;left:138.54px;top:300.93px" class="cls_008"><span class="cls_008">Figure 6.59: Histogram of inliers and outliers related to FTE percentage</span></div>
<div style="position:absolute;left:139.75px;top:328.42px" class="cls_008"><span class="cls_008">For hours worked (figure 6.60), most of the inliers are right above 150 hours,</span></div>
<div style="position:absolute;left:124.80px;top:340.38px" class="cls_008"><span class="cls_008">which is equivalent to a 100% position, while in the outliers, this value is not as</span></div>
<div style="position:absolute;left:124.80px;top:352.34px" class="cls_008"><span class="cls_008">highly represented.</span></div>
<div style="position:absolute;left:144.73px;top:553.21px" class="cls_008"><span class="cls_008">Figure 6.60: Histogram of inliers and outliers related to hours worked</span></div>
<div style="position:absolute;left:139.75px;top:580.71px" class="cls_008"><span class="cls_008">The above figures show the isolated values, however, due to the nature of</span></div>
<div style="position:absolute;left:124.80px;top:592.66px" class="cls_008"><span class="cls_008">the AprioriRare algorithm, it can be more beneficial to visualize the results in</span></div>
<div style="position:absolute;left:124.80px;top:604.62px" class="cls_008"><span class="cls_008">a more holistic fashion.  The outlier data points may have one or two of the</span></div>
<div style="position:absolute;left:124.80px;top:616.57px" class="cls_008"><span class="cls_008">features in a normal range, but the third is anomalous.</span></div>
<div style="position:absolute;left:139.75px;top:628.53px" class="cls_008"><span class="cls_008">Figure 6.61 shows the data points in a three dimensional scatter plot, which</span></div>
<div style="position:absolute;left:124.80px;top:640.48px" class="cls_008"><span class="cls_008">confirms the difference in approach between RIM and the clustering algorithms.</span></div>
<div style="position:absolute;left:124.80px;top:652.44px" class="cls_008"><span class="cls_008">The anomalous combinations are not clustered together, but evaluated individ-</span></div>
<div style="position:absolute;left:124.80px;top:664.39px" class="cls_008"><span class="cls_008">ually in relation to the complete data set.  Some of the outliers are obvious</span></div>
<div style="position:absolute;left:124.80px;top:676.35px" class="cls_008"><span class="cls_008">extreme values, however, most of them are not.</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">103</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:90206px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background107.jpg" width=595 height=841></div>
<div style="position:absolute;left:167.78px;top:294.95px" class="cls_008"><span class="cls_008">Figure 6.61: Scatter plot of inliers (blue) and outliers (red)</span></div>
<div style="position:absolute;left:139.75px;top:322.45px" class="cls_008"><span class="cls_008">In figure 6.62 we can see heatmaps of the correllation between the features.</span></div>
<div style="position:absolute;left:190.85px;top:480.87px" class="cls_026"><span class="cls_026">(a) Inliers</span></div>
<div style="position:absolute;left:358.74px;top:480.87px" class="cls_026"><span class="cls_026">(b) Outliers</span></div>
<div style="position:absolute;left:156.10px;top:501.50px" class="cls_008"><span class="cls_008">Figure 6.62: Heatmaps of inliers and outliers with three features</span></div>
<div style="position:absolute;left:139.75px;top:528.99px" class="cls_008"><span class="cls_008">The inliers seem to have a more pronounced correlation between the features,</span></div>
<div style="position:absolute;left:124.80px;top:540.95px" class="cls_008"><span class="cls_008">while the outliers have closer to no correlation.  We see a consistently lower</span></div>
<div style="position:absolute;left:124.80px;top:552.90px" class="cls_008"><span class="cls_008">correlation coefficient on all the feature combinations of the outliers compared</span></div>
<div style="position:absolute;left:124.80px;top:564.86px" class="cls_008"><span class="cls_008">to the inliers.</span></div>
<div style="position:absolute;left:124.80px;top:590.75px" class="cls_007"><span class="cls_007">Key observations</span></div>
<div style="position:absolute;left:139.75px;top:609.14px" class="cls_008"><span class="cls_008">- The outliers tend to be distributed fairly similarly to the inliers, although</span></div>
<div style="position:absolute;left:149.71px;top:621.10px" class="cls_008"><span class="cls_008">some extreme values are reported.</span></div>
<div style="position:absolute;left:139.75px;top:641.02px" class="cls_008"><span class="cls_008">- The inliers tend to consistently correlate more than the outliers.</span></div>
<div style="position:absolute;left:139.75px;top:660.95px" class="cls_008"><span class="cls_008">- The distribution of the histogram values are quite similar, however, for</span></div>
<div style="position:absolute;left:149.71px;top:672.90px" class="cls_008"><span class="cls_008">three features, it seems that hours worked might be the primary source of</span></div>
<div style="position:absolute;left:149.71px;top:684.86px" class="cls_008"><span class="cls_008">outliers due to the difference between the in- and outlier histograms.</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">104</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:91057px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background108.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:122.92px" class="cls_017"><span class="cls_017">6.4.2</span></div>
<div style="position:absolute;left:165.90px;top:122.92px" class="cls_017"><span class="cls_017">Four and five features</span></div>
<div style="position:absolute;left:124.80px;top:143.30px" class="cls_008"><span class="cls_008">Using AprioriRare with 1% minimal support on the features total income, FTE</span></div>
<div style="position:absolute;left:124.80px;top:155.25px" class="cls_008"><span class="cls_008">percentage, hours worked, and PPD, we got 1184 outliers.  See histograms in</span></div>
<div style="position:absolute;left:124.80px;top:167.21px" class="cls_008"><span class="cls_008">figure 6.63.</span></div>
<div style="position:absolute;left:155.65px;top:345.75px" class="cls_008"><span class="cls_008">Figure 6.63: Histograms of inliers and outliers with four features</span></div>
<div style="position:absolute;left:124.80px;top:372.71px" class="cls_008"><span class="cls_008">Using AprioriRare with 1% minimal support on the features total income, FTE</span></div>
<div style="position:absolute;left:124.80px;top:384.66px" class="cls_008"><span class="cls_008">percentage, Hours worked (Antall timer), prepayment deductions, and working</span></div>
<div style="position:absolute;left:124.80px;top:396.62px" class="cls_008"><span class="cls_008">time arrangement, we got 1217 outliers. See histograms in figure 6.64.</span></div>
<div style="position:absolute;left:156.90px;top:647.88px" class="cls_008"><span class="cls_008">Figure 6.64: Histograms of inliers and outliers with five features</span></div>
<div style="position:absolute;left:124.80px;top:674.85px" class="cls_008"><span class="cls_008">In both these experiments, the graphs showing inliers and outliers are much</span></div>
<div style="position:absolute;left:124.80px;top:686.80px" class="cls_008"><span class="cls_008">more similar, but the heatmaps in figures 6.65 and 6.66 still show a lower corre-</span></div>
<div style="position:absolute;left:124.80px;top:698.76px" class="cls_008"><span class="cls_008">lation coefficient on the outliers compared to the inliers. The PPD column has</span></div>
<div style="position:absolute;left:124.80px;top:710.71px" class="cls_008"><span class="cls_008">negative values, which explain the inverted relationships on that column. The</span></div>
<div style="position:absolute;left:289.18px;top:740.60px" class="cls_008"><span class="cls_008">105</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:91908px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background109.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">in- and outlier distributions are similar, but there is relatively higher amount of</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">outliers outside the obvious peaks. Total income and PPD contains the biggest</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">differences in the distribution of outliers.</span></div>
<div style="position:absolute;left:190.85px;top:305.31px" class="cls_026"><span class="cls_026">(a) Inliers</span></div>
<div style="position:absolute;left:358.74px;top:305.31px" class="cls_026"><span class="cls_026">(b) Outliers</span></div>
<div style="position:absolute;left:158.45px;top:325.93px" class="cls_008"><span class="cls_008">Figure 6.65: Heatmaps of inliers and outliers with four features</span></div>
<div style="position:absolute;left:190.85px;top:497.96px" class="cls_026"><span class="cls_026">(a) Inliers</span></div>
<div style="position:absolute;left:358.74px;top:497.96px" class="cls_026"><span class="cls_026">(b) Outliers</span></div>
<div style="position:absolute;left:159.71px;top:518.58px" class="cls_008"><span class="cls_008">Figure 6.66: Heatmaps of inliers and outliers with five features</span></div>
<div style="position:absolute;left:124.80px;top:548.06px" class="cls_007"><span class="cls_007">Key observations</span></div>
<div style="position:absolute;left:139.75px;top:566.45px" class="cls_008"><span class="cls_008">- The outliers and inliers have an even more similar distribution, and the</span></div>
<div style="position:absolute;left:149.71px;top:578.41px" class="cls_008"><span class="cls_008">differences between four and five features are miniscule.</span></div>
<div style="position:absolute;left:139.75px;top:598.33px" class="cls_008"><span class="cls_008">- The inliers still correlate significantly more than the outliers.</span></div>
<div style="position:absolute;left:139.75px;top:618.26px" class="cls_008"><span class="cls_008">- Looking at the histograms, the biggest differences come from total income</span></div>
<div style="position:absolute;left:149.71px;top:630.21px" class="cls_008"><span class="cls_008">and prepayment deductions.</span></div>
<div style="position:absolute;left:139.75px;top:650.14px" class="cls_008"><span class="cls_008">- There is less of a difference when using five features compared to four, as</span></div>
<div style="position:absolute;left:149.71px;top:662.09px" class="cls_008"><span class="cls_008">they tend to register the same outliers.</span></div>
<div style="position:absolute;left:139.75px;top:682.02px" class="cls_008"><span class="cls_008">- A larger ratio of the outliers are found outside the median values of the</span></div>
<div style="position:absolute;left:149.71px;top:693.97px" class="cls_008"><span class="cls_008">data set.</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">106</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:92759px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background110.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:122.92px" class="cls_017"><span class="cls_017">6.4.3</span></div>
<div style="position:absolute;left:165.90px;top:122.92px" class="cls_017"><span class="cls_017">Comparing AprioriRare results</span></div>
<div style="position:absolute;left:124.80px;top:143.30px" class="cls_008"><span class="cls_008">Looking at the final comparisons in figure 6.67 we see that the experiments</span></div>
<div style="position:absolute;left:124.80px;top:155.25px" class="cls_008"><span class="cls_008">with four and five features have found mostly the same set of outliers, while the</span></div>
<div style="position:absolute;left:124.80px;top:167.21px" class="cls_008"><span class="cls_008">experiment with three features tend to return other values. The histograms with</span></div>
<div style="position:absolute;left:124.80px;top:179.16px" class="cls_008"><span class="cls_008">four and five features are mostly indistinguishable, which confirms this.  The</span></div>
<div style="position:absolute;left:124.80px;top:191.12px" class="cls_008"><span class="cls_008">minor differences between four and five features can indicate that the inclusion</span></div>
<div style="position:absolute;left:124.80px;top:203.07px" class="cls_008"><span class="cls_008">of the categorical feature WTA does not amount to a meaningful difference, as</span></div>
<div style="position:absolute;left:124.80px;top:215.03px" class="cls_008"><span class="cls_008">most of the values of that feature is the same, and the combinations are still</span></div>
<div style="position:absolute;left:124.80px;top:226.98px" class="cls_008"><span class="cls_008">as rare. The list in figure 6.69 are the first few values in the intersection of all</span></div>
<div style="position:absolute;left:124.80px;top:238.94px" class="cls_008"><span class="cls_008">three circles in the Venn diagram.</span></div>
<div style="position:absolute;left:124.80px;top:573.48px" class="cls_008"><span class="cls_008">Figure 6.67:  Venn diagram comparing outliers from all experiments (100.000</span></div>
<div style="position:absolute;left:124.80px;top:585.43px" class="cls_008"><span class="cls_008">data points)</span></div>
<div style="position:absolute;left:139.75px;top:622.89px" class="cls_008"><span class="cls_008">In figure 6.68 we see some key tendencies of the outliers in the intersection of</span></div>
<div style="position:absolute;left:124.80px;top:634.85px" class="cls_008"><span class="cls_008">all three experiments, compared to all 100.000 data points. Total income has no</span></div>
<div style="position:absolute;left:124.80px;top:646.80px" class="cls_008"><span class="cls_008">duplicate values, making it impossible to determine a mode value. AprioriRare</span></div>
<div style="position:absolute;left:124.80px;top:658.76px" class="cls_008"><span class="cls_008">does not register any of the extreme values as outliers, which probably is a result</span></div>
<div style="position:absolute;left:124.80px;top:670.71px" class="cls_008"><span class="cls_008">of the quantization process.  All the medians and means are shifted compared</span></div>
<div style="position:absolute;left:124.80px;top:682.67px" class="cls_008"><span class="cls_008">to the total data set, which can indicate that most of the more common values</span></div>
<div style="position:absolute;left:124.80px;top:694.63px" class="cls_008"><span class="cls_008">are not considered anomalous by this algorithm. WTA is a categorical feature,</span></div>
<div style="position:absolute;left:124.80px;top:706.58px" class="cls_008"><span class="cls_008">meaning it does not make sense with min, max, median and mean values.</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">107</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:93610px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background111.jpg" width=595 height=841></div>
<div style="position:absolute;left:276.52px;top:123.31px" class="cls_007"><span class="cls_007">Outliers</span></div>
<div style="position:absolute;left:230.85px;top:135.67px" class="cls_008"><span class="cls_008">Median    Mean</span></div>
<div style="position:absolute;left:330.04px;top:135.67px" class="cls_008"><span class="cls_008">Mode</span></div>
<div style="position:absolute;left:380.88px;top:135.67px" class="cls_008"><span class="cls_008">Max</span></div>
<div style="position:absolute;left:430.33px;top:135.67px" class="cls_008"><span class="cls_008">Min</span></div>
<div style="position:absolute;left:135.17px;top:148.02px" class="cls_008"><span class="cls_008">Stillingsprosent</span></div>
<div style="position:absolute;left:242.06px;top:148.02px" class="cls_008"><span class="cls_008">80</span></div>
<div style="position:absolute;left:284.46px;top:148.02px" class="cls_008"><span class="cls_008">69.7</span></div>
<div style="position:absolute;left:334.74px;top:148.02px" class="cls_008"><span class="cls_008">100</span></div>
<div style="position:absolute;left:383.09px;top:148.02px" class="cls_008"><span class="cls_008">100</span></div>
<div style="position:absolute;left:436.56px;top:148.02px" class="cls_008"><span class="cls_008">0</span></div>
<div style="position:absolute;left:135.17px;top:159.98px" class="cls_008"><span class="cls_008">Antall timer</span></div>
<div style="position:absolute;left:239.57px;top:159.98px" class="cls_008"><span class="cls_008">103</span></div>
<div style="position:absolute;left:285.84px;top:159.98px" class="cls_008"><span class="cls_008">106</span></div>
<div style="position:absolute;left:337.23px;top:159.98px" class="cls_008"><span class="cls_008">81</span></div>
<div style="position:absolute;left:380.60px;top:159.98px" class="cls_008"><span class="cls_008">1009</span></div>
<div style="position:absolute;left:432.41px;top:159.98px" class="cls_008"><span class="cls_008">-14</span></div>
<div style="position:absolute;left:135.17px;top:171.93px" class="cls_008"><span class="cls_008">Totalinntekt</span></div>
<div style="position:absolute;left:230.72px;top:171.93px" class="cls_008"><span class="cls_008">58382.5</span></div>
<div style="position:absolute;left:276.99px;top:171.93px" class="cls_008"><span class="cls_008">64927.8</span></div>
<div style="position:absolute;left:375.62px;top:171.93px" class="cls_008"><span class="cls_008">642646</span></div>
<div style="position:absolute;left:424.93px;top:171.93px" class="cls_008"><span class="cls_008">-34521</span></div>
<div style="position:absolute;left:135.17px;top:183.89px" class="cls_008"><span class="cls_008">Forskuddstrekk</span></div>
<div style="position:absolute;left:232.93px;top:183.89px" class="cls_008"><span class="cls_008">-14284</span></div>
<div style="position:absolute;left:275.32px;top:183.89px" class="cls_008"><span class="cls_008">-18830.4</span></div>
<div style="position:absolute;left:339.72px;top:183.89px" class="cls_008"><span class="cls_008">0</span></div>
<div style="position:absolute;left:378.11px;top:183.89px" class="cls_008"><span class="cls_008">12306</span></div>
<div style="position:absolute;left:422.44px;top:183.89px" class="cls_008"><span class="cls_008">-321323</span></div>
<div style="position:absolute;left:135.17px;top:195.84px" class="cls_008"><span class="cls_008">Arbeidstidsordning</span></div>
<div style="position:absolute;left:323.26px;top:195.84px" class="cls_008"><span class="cls_008">ikkeSkift</span></div>
<div style="position:absolute;left:283.67px;top:220.15px" class="cls_007"><span class="cls_007">Total</span></div>
<div style="position:absolute;left:230.85px;top:232.51px" class="cls_008"><span class="cls_008">Median    Mean</span></div>
<div style="position:absolute;left:330.04px;top:232.51px" class="cls_008"><span class="cls_008">Mode</span></div>
<div style="position:absolute;left:380.88px;top:232.51px" class="cls_008"><span class="cls_008">Max</span></div>
<div style="position:absolute;left:430.33px;top:232.51px" class="cls_008"><span class="cls_008">Min</span></div>
<div style="position:absolute;left:135.17px;top:244.86px" class="cls_008"><span class="cls_008">Stillingsprosent</span></div>
<div style="position:absolute;left:239.57px;top:244.86px" class="cls_008"><span class="cls_008">100</span></div>
<div style="position:absolute;left:284.46px;top:244.86px" class="cls_008"><span class="cls_008">82.9</span></div>
<div style="position:absolute;left:334.74px;top:244.86px" class="cls_008"><span class="cls_008">100</span></div>
<div style="position:absolute;left:380.60px;top:244.86px" class="cls_008"><span class="cls_008">2560</span></div>
<div style="position:absolute;left:436.56px;top:244.86px" class="cls_008"><span class="cls_008">0</span></div>
<div style="position:absolute;left:135.17px;top:256.81px" class="cls_008"><span class="cls_008">Antall timer</span></div>
<div style="position:absolute;left:239.57px;top:256.81px" class="cls_008"><span class="cls_008">162</span></div>
<div style="position:absolute;left:281.97px;top:256.81px" class="cls_008"><span class="cls_008">133.2</span></div>
<div style="position:absolute;left:334.74px;top:256.81px" class="cls_008"><span class="cls_008">162</span></div>
<div style="position:absolute;left:380.60px;top:256.81px" class="cls_008"><span class="cls_008">4156</span></div>
<div style="position:absolute;left:429.91px;top:256.81px" class="cls_008"><span class="cls_008">-486</span></div>
<div style="position:absolute;left:135.17px;top:268.77px" class="cls_008"><span class="cls_008">Totalinntekt</span></div>
<div style="position:absolute;left:234.59px;top:268.77px" class="cls_008"><span class="cls_008">41999</span></div>
<div style="position:absolute;left:276.99px;top:268.77px" class="cls_008"><span class="cls_008">48722.6</span></div>
<div style="position:absolute;left:334.74px;top:268.77px" class="cls_008"><span class="cls_008">104</span></div>
<div style="position:absolute;left:373.13px;top:268.77px" class="cls_008"><span class="cls_008">6627727</span></div>
<div style="position:absolute;left:422.44px;top:268.77px" class="cls_008"><span class="cls_008">-123652</span></div>
<div style="position:absolute;left:135.17px;top:280.72px" class="cls_008"><span class="cls_008">Forskuddstrekk</span></div>
<div style="position:absolute;left:232.93px;top:280.72px" class="cls_008"><span class="cls_008">-11793</span></div>
<div style="position:absolute;left:275.32px;top:280.72px" class="cls_008"><span class="cls_008">-15602.4</span></div>
<div style="position:absolute;left:339.72px;top:280.72px" class="cls_008"><span class="cls_008">0</span></div>
<div style="position:absolute;left:378.11px;top:280.72px" class="cls_008"><span class="cls_008">39332</span></div>
<div style="position:absolute;left:419.95px;top:280.72px" class="cls_008"><span class="cls_008">-2783645</span></div>
<div style="position:absolute;left:135.17px;top:292.68px" class="cls_008"><span class="cls_008">Arbeidstidsordning</span></div>
<div style="position:absolute;left:323.26px;top:292.68px" class="cls_008"><span class="cls_008">ikkeSkift</span></div>
<div style="position:absolute;left:138.10px;top:315.00px" class="cls_008"><span class="cls_008">Figure 6.68: Measures of central tendency - Outliers vs total data points</span></div>
<div style="position:absolute;left:124.80px;top:685.21px" class="cls_008"><span class="cls_008">Figure 6.69: Values for the first few outliers from the intersection of all three</span></div>
<div style="position:absolute;left:124.80px;top:697.16px" class="cls_008"><span class="cls_008">experiments</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">108</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:94461px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background112.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:120.52px" class="cls_010"><span class="cls_010">6.5</span></div>
<div style="position:absolute;left:161.56px;top:120.52px" class="cls_010"><span class="cls_010">Comparing the Results</span></div>
<div style="position:absolute;left:124.80px;top:146.73px" class="cls_008"><span class="cls_008">All four algorithms that we implemented found approximately the same amount</span></div>
<div style="position:absolute;left:124.80px;top:158.68px" class="cls_008"><span class="cls_008">of anomalies. This was because we adjusted the parameters of the algorithms so</span></div>
<div style="position:absolute;left:124.80px;top:170.64px" class="cls_008"><span class="cls_008">that they all labeled less than or around 2% of the data as outliers. The biggest</span></div>
<div style="position:absolute;left:124.80px;top:182.59px" class="cls_008"><span class="cls_008">surprise was that the Local Outlier Factor algorithm struggled to find the same</span></div>
<div style="position:absolute;left:124.80px;top:194.55px" class="cls_008"><span class="cls_008">anomalies as the other three algorithms. Initially, we expected the ApriorRare</span></div>
<div style="position:absolute;left:124.80px;top:206.51px" class="cls_008"><span class="cls_008">algorithms to have the least amount overlapping with the other algorithms be-</span></div>
<div style="position:absolute;left:124.80px;top:218.46px" class="cls_008"><span class="cls_008">cause it is the only algorithm that is not based upon distance calculations. In</span></div>
<div style="position:absolute;left:124.80px;top:230.42px" class="cls_008"><span class="cls_008">figure 6.70 we have drawn a Venn-diagram of all the outliers found in the four</span></div>
<div style="position:absolute;left:124.80px;top:242.37px" class="cls_008"><span class="cls_008">different algorithms using the same three features.  The different intersections</span></div>
<div style="position:absolute;left:124.80px;top:254.33px" class="cls_008"><span class="cls_008">are marked with a sequence of 4 bits. The first bit represents AprioriRare, the</span></div>
<div style="position:absolute;left:124.80px;top:266.28px" class="cls_008"><span class="cls_008">second LOF, the third DBSCAN and the fourth K-means.</span></div>
<div style="position:absolute;left:124.80px;top:590.75px" class="cls_008"><span class="cls_008">Figure 6.70: Venn diagram of outliers found in K-means, DBSCAN, AprioriRare</span></div>
<div style="position:absolute;left:124.80px;top:602.71px" class="cls_008"><span class="cls_008">and LOF using three features.</span></div>
<div style="position:absolute;left:139.75px;top:638.98px" class="cls_008"><span class="cls_008">The total number of outliers found by all the algorithms when using the</span></div>
<div style="position:absolute;left:124.80px;top:650.94px" class="cls_008"><span class="cls_008">data set with three features (Figure 6.70) is about 6000, yet the intersection of</span></div>
<div style="position:absolute;left:124.80px;top:662.89px" class="cls_008"><span class="cls_008">all four algorithms (AprioriRare ∩ LOF ∩ DBSCAN ∩ K − means) is only 13</span></div>
<div style="position:absolute;left:124.80px;top:674.85px" class="cls_008"><span class="cls_008">data points. From the Venn diagram we find that it is LOF that has the least</span></div>
<div style="position:absolute;left:124.80px;top:686.80px" class="cls_008"><span class="cls_008">points in common with any of the other algorithms.  Even though it had the</span></div>
<div style="position:absolute;left:124.80px;top:698.76px" class="cls_008"><span class="cls_008">most registered outliers with 2501, it only found 76 in common with DBSCAN</span></div>
<div style="position:absolute;left:124.80px;top:710.71px" class="cls_008"><span class="cls_008">at the most. After conducting our experiments we realized that it made sense</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">109</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:95312px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background113.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">for LOF to not have very much in common with the other clustering algorithms</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">as it in general finds outliers where the data is very dense (section 6.3) while</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">both K-means and DBSCAN find them where the data is sparser. The Apriori-</span></div>
<div style="position:absolute;left:124.80px;top:160.77px" class="cls_008"><span class="cls_008">Rare algorithm seems to have more in common with the clustering algorithms</span></div>
<div style="position:absolute;left:124.80px;top:172.73px" class="cls_008"><span class="cls_008">than we expected, especially with DBSCAN with 271 outliers in common. As</span></div>
<div style="position:absolute;left:124.80px;top:184.68px" class="cls_008"><span class="cls_008">DBSCAN has a total of 1345 outliers detected while K-means only has 913, this</span></div>
<div style="position:absolute;left:124.80px;top:196.64px" class="cls_008"><span class="cls_008">might explain somewhat why there is a greater overlap between AproriRare</span></div>
<div style="position:absolute;left:124.80px;top:208.59px" class="cls_008"><span class="cls_008">and DBSCAN than AproriRare and K-means.  Since DBSCAN and K-means</span></div>
<div style="position:absolute;left:124.80px;top:220.55px" class="cls_008"><span class="cls_008">both are clustering algorithms which finds outliers outside of where the data</span></div>
<div style="position:absolute;left:124.80px;top:232.51px" class="cls_008"><span class="cls_008">is dense, it makes sense that these found 273 of the same outliers.  K-means</span></div>
<div style="position:absolute;left:124.80px;top:244.46px" class="cls_008"><span class="cls_008">and AprioriRare have only 58 outliers detected in common. The reason for this</span></div>
<div style="position:absolute;left:124.80px;top:256.42px" class="cls_008"><span class="cls_008">is probably that the outliers K-means finds are solely based on their distance</span></div>
<div style="position:absolute;left:124.80px;top:268.37px" class="cls_008"><span class="cls_008">from the centroids of the clusters they belong to (section 5.2), while AprioriRare</span></div>
<div style="position:absolute;left:124.80px;top:280.33px" class="cls_008"><span class="cls_008">finds outliers among the data based on a combination of features. And since the</span></div>
<div style="position:absolute;left:124.80px;top:292.28px" class="cls_008"><span class="cls_008">AprioriRare algorithm splits the data into quantile batches, all these extreme</span></div>
<div style="position:absolute;left:124.80px;top:304.24px" class="cls_008"><span class="cls_008">values will most likely fall into the same batch (section 5.5).</span></div>
<div style="position:absolute;left:124.80px;top:630.45px" class="cls_008"><span class="cls_008">Figure 6.71: Venn diagram of outliers found in K-means, DBSCAN, AprioriRare</span></div>
<div style="position:absolute;left:124.80px;top:642.40px" class="cls_008"><span class="cls_008">and LOF using four features.</span></div>
<div style="position:absolute;left:139.75px;top:679.86px" class="cls_008"><span class="cls_008">As we increased the dimensionality of the feature space by including a fourth</span></div>
<div style="position:absolute;left:124.80px;top:691.82px" class="cls_008"><span class="cls_008">feature, the intersection of all the four algorithms decreased down to two (Figure</span></div>
<div style="position:absolute;left:124.80px;top:703.77px" class="cls_008"><span class="cls_008">6.71). This is not a surprise as the complexity of the data points is higher when</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">110</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:96163px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background114.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">there are four dimensions and since our algorithms specializes in different ways</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">of finding outliers the differences become more distinct.  More surprising, is</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">that the overlap between LOF and the three other algorithms increased, with</span></div>
<div style="position:absolute;left:124.80px;top:160.77px" class="cls_008"><span class="cls_008">DBSCAN and LOF now finding 130 of the same outliers. This might be because</span></div>
<div style="position:absolute;left:124.80px;top:172.73px" class="cls_008"><span class="cls_008">when we introduce new features the data becomes less dense which allows LOF</span></div>
<div style="position:absolute;left:124.80px;top:184.68px" class="cls_008"><span class="cls_008">to detect more of the same outliers as the other algorithms. K-means stills finds</span></div>
<div style="position:absolute;left:124.80px;top:196.64px" class="cls_008"><span class="cls_008">approximately the same amount of the same outliers as DBSCAN (281), this</span></div>
<div style="position:absolute;left:124.80px;top:208.59px" class="cls_008"><span class="cls_008">is logical as we previously saw that both K-means (Figure 6.14) and DBSCAN</span></div>
<div style="position:absolute;left:124.80px;top:220.55px" class="cls_008"><span class="cls_008">(Figure 6.36) still mark many of the same points as outliers for four features as</span></div>
<div style="position:absolute;left:124.80px;top:232.51px" class="cls_008"><span class="cls_008">they did for three. For four features, AprioriRare has a lower amount of outliers</span></div>
<div style="position:absolute;left:124.80px;top:244.46px" class="cls_008"><span class="cls_008">in common with DBSCAN and K-means than previously, but sees an increase</span></div>
<div style="position:absolute;left:124.80px;top:256.42px" class="cls_008"><span class="cls_008">in outliers in common with LOF.</span></div>
<div style="position:absolute;left:124.80px;top:578.87px" class="cls_008"><span class="cls_008">Figure 6.72: Venn diagram of outliers found in K-means, DBSCAN, AprioriRare</span></div>
<div style="position:absolute;left:124.80px;top:590.83px" class="cls_008"><span class="cls_008">and LOF using five features.</span></div>
<div style="position:absolute;left:139.75px;top:627.03px" class="cls_008"><span class="cls_008">When looking at the Venn diagram for five feature (Figure 6.72) we found</span></div>
<div style="position:absolute;left:124.80px;top:638.98px" class="cls_008"><span class="cls_008">zero outliers in common for all the algorithms.  We see that LOF has even</span></div>
<div style="position:absolute;left:124.80px;top:650.94px" class="cls_008"><span class="cls_008">more in common with AprioriRare with five features than previously.  This</span></div>
<div style="position:absolute;left:124.80px;top:662.89px" class="cls_008"><span class="cls_008">might indicate that the larger the feature space is, the more points LOF and</span></div>
<div style="position:absolute;left:124.80px;top:674.85px" class="cls_008"><span class="cls_008">AprioriRare find in common.  This time DBSCAN has a lot less in common</span></div>
<div style="position:absolute;left:124.80px;top:686.80px" class="cls_008"><span class="cls_008">with the other algorithms than previously, but this is likely a result of DBSCAN</span></div>
<div style="position:absolute;left:124.80px;top:698.76px" class="cls_008"><span class="cls_008">registering fewer outliers for five features (506) than previously (ca. 1000). K-</span></div>
<div style="position:absolute;left:124.80px;top:710.71px" class="cls_008"><span class="cls_008">means also has less in common with LOF than earlier. This might be because</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">111</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:97014px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background115.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">when we included the fifth feature WTA, K-means ignored all the data points</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">which had a value for this other than "ikkeSkift" which might have removed</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">previous common outliers.</span></div>
<div style="position:absolute;left:139.75px;top:172.73px" class="cls_008"><span class="cls_008">To make sure that the results of the Venn diagrams was not just random we</span></div>
<div style="position:absolute;left:124.80px;top:184.68px" class="cls_008"><span class="cls_008">did a sanity-check by plotting a Venn diagram with randomly assigned values</span></div>
<div style="position:absolute;left:124.80px;top:196.64px" class="cls_008"><span class="cls_008">from 1 to 100.000.  Each set in the figure below has the same number points</span></div>
<div style="position:absolute;left:124.80px;top:208.59px" class="cls_008"><span class="cls_008">equivalent to that of the sets in the Venn diagram with 3 features (see figure</span></div>
<div style="position:absolute;left:124.80px;top:220.55px" class="cls_008"><span class="cls_008">6.70). The results, as shown below, indicates that the intersections between the</span></div>
<div style="position:absolute;left:124.80px;top:232.51px" class="cls_008"><span class="cls_008">different algorithms are much higher than if they were chosen arbitrarily.</span></div>
<div style="position:absolute;left:127.25px;top:594.42px" class="cls_008"><span class="cls_008">Figure 6.73: Venn diagram randomly chosen numbers between 1 and 100.000.</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">112</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:97865px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background116.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:120.52px" class="cls_010"><span class="cls_010">6.6</span></div>
<div style="position:absolute;left:161.56px;top:120.52px" class="cls_010"><span class="cls_010">Discussion</span></div>
<div style="position:absolute;left:124.80px;top:146.73px" class="cls_008"><span class="cls_008">During this project we have applied and analyzed several different algorithms</span></div>
<div style="position:absolute;left:124.80px;top:158.68px" class="cls_008"><span class="cls_008">on real-world data.  Figure 6.74 below shows an excerpt of a data point whos</span></div>
<div style="position:absolute;left:124.80px;top:170.64px" class="cls_008"><span class="cls_008">features were labeled as an outlier in all four algorithms when run with three fea-</span></div>
<div style="position:absolute;left:124.80px;top:182.59px" class="cls_008"><span class="cls_008">tures. This data point had a value of negative 162.5 hours worked which seems</span></div>
<div style="position:absolute;left:124.80px;top:194.55px" class="cls_008"><span class="cls_008">impossible. But after consolidating with the domain experts at Skatteetaten we</span></div>
<div style="position:absolute;left:124.80px;top:206.51px" class="cls_008"><span class="cls_008">discovered that this case most likely is due to a correction message.</span></div>
<div style="position:absolute;left:124.80px;top:310.56px" class="cls_008"><span class="cls_008">Figure 6.74: Values from outlier 1 detected in the intersection RIM ∩ DBSCAN</span></div>
<div style="position:absolute;left:124.80px;top:322.52px" class="cls_008"><span class="cls_008">∩ K-means for three features.</span></div>
<div style="position:absolute;left:139.75px;top:359.97px" class="cls_008"><span class="cls_008">However, looking up all the A-meldinger with this PersonId (figure 6.75),</span></div>
<div style="position:absolute;left:124.80px;top:371.93px" class="cls_008"><span class="cls_008">we can see that this is a recurring occurrence, and that this is an example of a</span></div>
<div style="position:absolute;left:124.80px;top:383.89px" class="cls_008"><span class="cls_008">potential anomaly that could be investigated further.</span></div>
<div style="position:absolute;left:194.26px;top:607.06px" class="cls_008"><span class="cls_008">Figure 6.75: Other A-meldinger from outlier 1.</span></div>
<div style="position:absolute;left:139.75px;top:644.52px" class="cls_008"><span class="cls_008">Figure 6.76 show another interesting anomaly taken from the same inter-</span></div>
<div style="position:absolute;left:124.80px;top:656.47px" class="cls_008"><span class="cls_008">section as the one in figure 6.74.  This person has an FTE percentage of 0%</span></div>
<div style="position:absolute;left:124.80px;top:668.43px" class="cls_008"><span class="cls_008">and zero hours worked.  Yet the income and withholdings can be considered</span></div>
<div style="position:absolute;left:124.80px;top:680.38px" class="cls_008"><span class="cls_008">normal.  In order to look more closely at this persons features we looked up</span></div>
<div style="position:absolute;left:124.80px;top:692.34px" class="cls_008"><span class="cls_008">the A-melding and discovered that the type of employment was maritime. This</span></div>
<div style="position:absolute;left:124.80px;top:704.29px" class="cls_008"><span class="cls_008">could explain why the FTE percentage and hours worked were zero.</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">113</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:98716px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background117.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:207.74px" class="cls_008"><span class="cls_008">Figure 6.76: Values from outlier 2 detected in the intersection RIM ∩ DBSCAN</span></div>
<div style="position:absolute;left:124.80px;top:219.70px" class="cls_008"><span class="cls_008">∩ K-means for three features.</span></div>
<div style="position:absolute;left:139.75px;top:257.16px" class="cls_008"><span class="cls_008">Looking up this person over time (figure 6.77), we can see that this is again</span></div>
<div style="position:absolute;left:124.80px;top:269.11px" class="cls_008"><span class="cls_008">recurring, and in this case probably normal.</span></div>
<div style="position:absolute;left:194.26px;top:635.59px" class="cls_008"><span class="cls_008">Figure 6.77: Other A-meldinger from outlier 2.</span></div>
<div style="position:absolute;left:139.75px;top:673.05px" class="cls_008"><span class="cls_008">As stated in the introduction, our goal was too apply different machine</span></div>
<div style="position:absolute;left:124.80px;top:685.00px" class="cls_008"><span class="cls_008">learning techniques on the A-melding to detect potential anomalies.  We have</span></div>
<div style="position:absolute;left:124.80px;top:696.96px" class="cls_008"><span class="cls_008">found many different types of outliers, and some of them might be anomalies.</span></div>
<div style="position:absolute;left:124.80px;top:708.92px" class="cls_008"><span class="cls_008">We provided the NTA with around thirty of the outliers discovered by several</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">114</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:99567px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background118.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">algorithms with three and four features. The domain experts at the NTA agreed</span></div>
<div style="position:absolute;left:124.80px;top:136.86px" class="cls_008"><span class="cls_008">that the data points looked suspicious, but it was not possible for them to be</span></div>
<div style="position:absolute;left:124.80px;top:148.82px" class="cls_008"><span class="cls_008">certain due to the anonymization of data and the limitation of the features.</span></div>
<div style="position:absolute;left:124.80px;top:160.77px" class="cls_008"><span class="cls_008">Since we only used up to five features when looking for potential anomalies, the</span></div>
<div style="position:absolute;left:124.80px;top:172.73px" class="cls_008"><span class="cls_008">complexity of the points we found was quite limited. There is much information</span></div>
<div style="position:absolute;left:124.80px;top:184.68px" class="cls_008"><span class="cls_008">that is not processed like for example profession (anonymized) and industry</span></div>
<div style="position:absolute;left:124.80px;top:196.64px" class="cls_008"><span class="cls_008">(anonymized). Therefore we can not say with any certainty that the outliers we</span></div>
<div style="position:absolute;left:124.80px;top:208.59px" class="cls_008"><span class="cls_008">discovered are anomalies, but what we can say is that they do not conform with</span></div>
<div style="position:absolute;left:124.80px;top:220.55px" class="cls_008"><span class="cls_008">the rest of the data, and should therefore be considered as potential anomalies.</span></div>
<div style="position:absolute;left:139.75px;top:244.46px" class="cls_008"><span class="cls_008">Given the complexity of the data and the differences between the algorithms,</span></div>
<div style="position:absolute;left:124.80px;top:256.42px" class="cls_008"><span class="cls_008">it makes sense that the experiments tend to find different results.  The unsu-</span></div>
<div style="position:absolute;left:124.80px;top:268.37px" class="cls_008"><span class="cls_008">pervised nature of the experiments mean that the algorithms try their best to</span></div>
<div style="position:absolute;left:124.80px;top:280.33px" class="cls_008"><span class="cls_008">understand and classify the data without having a way to compare and correct.</span></div>
<div style="position:absolute;left:124.80px;top:292.28px" class="cls_008"><span class="cls_008">The sample size also has a big impact on what is considered an outlier or not,</span></div>
<div style="position:absolute;left:124.80px;top:304.24px" class="cls_008"><span class="cls_008">as data points would be clustered differently. Illustrating the difference between</span></div>
<div style="position:absolute;left:124.80px;top:316.19px" class="cls_008"><span class="cls_008">the algorithms, we can compare LOF and DBSCAN in figure 6.78. We see that</span></div>
<div style="position:absolute;left:124.80px;top:328.15px" class="cls_008"><span class="cls_008">LOF finds local outliers inside the clusters, while DBSCAN finds mostly values</span></div>
<div style="position:absolute;left:124.80px;top:340.10px" class="cls_008"><span class="cls_008">outside of the clusters.</span></div>
<div style="position:absolute;left:183.73px;top:508.08px" class="cls_026"><span class="cls_026">(a) DBSCAN</span></div>
<div style="position:absolute;left:365.43px;top:506.84px" class="cls_026"><span class="cls_026">(b) LOF</span></div>
<div style="position:absolute;left:124.80px;top:528.70px" class="cls_008"><span class="cls_008">Figure 6.78:  Comparing DBSCAN and LOF, 4 features.  Data is reduced to</span></div>
<div style="position:absolute;left:124.80px;top:540.66px" class="cls_008"><span class="cls_008">three dimensions with PCA. Outliers are colored blue, while inliers are colored</span></div>
<div style="position:absolute;left:124.80px;top:552.61px" class="cls_008"><span class="cls_008">yellow.</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">115</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:100418px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background119.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:188.93px" class="cls_011"><span class="cls_011">Chapter 7</span></div>
<div style="position:absolute;left:124.80px;top:234.62px" class="cls_009"><span class="cls_009">Conclusion</span></div>
<div style="position:absolute;left:124.80px;top:301.25px" class="cls_008"><span class="cls_008">In this thesis we have explored different unsupervised machine learning algo-</span></div>
<div style="position:absolute;left:124.80px;top:313.20px" class="cls_008"><span class="cls_008">rithms and applied them to real-world data provided by the NTA. We analyzed</span></div>
<div style="position:absolute;left:124.80px;top:325.16px" class="cls_008"><span class="cls_008">the results and made assumptions based on input from domain experts.  The</span></div>
<div style="position:absolute;left:124.80px;top:337.11px" class="cls_008"><span class="cls_008">certainty of the findings are quite low due to our limited knowledge of the</span></div>
<div style="position:absolute;left:124.80px;top:349.07px" class="cls_008"><span class="cls_008">dataset and the anonymization of several of the features. The dataset we used</span></div>
<div style="position:absolute;left:124.80px;top:361.02px" class="cls_008"><span class="cls_008">was less than 1% of the data we received, and this again was only 1% of the</span></div>
<div style="position:absolute;left:124.80px;top:372.98px" class="cls_008"><span class="cls_008">data the NTA received yearly through the A-melding.  Ideally, we would have</span></div>
<div style="position:absolute;left:124.80px;top:384.93px" class="cls_008"><span class="cls_008">applied the algorithms to all the data we received, but the computing power</span></div>
<div style="position:absolute;left:124.80px;top:396.89px" class="cls_008"><span class="cls_008">for the algorithms increased drastically as we increased the size of the input.</span></div>
<div style="position:absolute;left:124.80px;top:408.84px" class="cls_008"><span class="cls_008">Another improvement could have been to increase the feature space by adding</span></div>
<div style="position:absolute;left:124.80px;top:420.80px" class="cls_008"><span class="cls_008">more features. We tried applying the algorithms to the complete dataset using</span></div>
<div style="position:absolute;left:124.80px;top:432.75px" class="cls_008"><span class="cls_008">a greater number of features, but the algorithms proved too computationally</span></div>
<div style="position:absolute;left:124.80px;top:444.71px" class="cls_008"><span class="cls_008">expensive and we got ’Out of Memory’ errors. An argument can be made that</span></div>
<div style="position:absolute;left:124.80px;top:456.66px" class="cls_008"><span class="cls_008">our implementation of the algorithms we used may not have been suitable for</span></div>
<div style="position:absolute;left:124.80px;top:468.62px" class="cls_008"><span class="cls_008">the amounts of data we had, and that we could have explored other similar</span></div>
<div style="position:absolute;left:124.80px;top:480.57px" class="cls_008"><span class="cls_008">algorithms which are more optimized for bigger datasets.</span></div>
<div style="position:absolute;left:139.75px;top:492.53px" class="cls_008"><span class="cls_008">There are many outliers that gets through the already in-place counter mea-</span></div>
<div style="position:absolute;left:124.80px;top:504.49px" class="cls_008"><span class="cls_008">sure, and some of them could potentially be anomalies that ought to be handled.</span></div>
<div style="position:absolute;left:124.80px;top:516.44px" class="cls_008"><span class="cls_008">Many of the outliers found in the K-means algorithm were extreme values that</span></div>
<div style="position:absolute;left:124.80px;top:528.40px" class="cls_008"><span class="cls_008">could easily be prevented with some simple checks in the frontend validation.</span></div>
<div style="position:absolute;left:124.80px;top:540.35px" class="cls_008"><span class="cls_008">The usefulness of the K-means algorithm is therefore questionable as it does not</span></div>
<div style="position:absolute;left:124.80px;top:552.31px" class="cls_008"><span class="cls_008">find the more intricate outliers that exist within the clusters.  The DBSCAN</span></div>
<div style="position:absolute;left:124.80px;top:564.26px" class="cls_008"><span class="cls_008">algorithm have many similarities to the K-means algorithm and is not suitable</span></div>
<div style="position:absolute;left:124.80px;top:576.22px" class="cls_008"><span class="cls_008">for datasets with clusters with varying density. We believe that the most inter-</span></div>
<div style="position:absolute;left:124.80px;top:588.17px" class="cls_008"><span class="cls_008">esting results are output by the LOF and the AprioriRare algorithms.  As we</span></div>
<div style="position:absolute;left:124.80px;top:600.13px" class="cls_008"><span class="cls_008">saw in the the result chapter, both of these algorithms discovered outliers that</span></div>
<div style="position:absolute;left:124.80px;top:612.08px" class="cls_008"><span class="cls_008">were located within the more dense areas of the dataset.</span></div>
<div style="position:absolute;left:139.75px;top:624.04px" class="cls_008"><span class="cls_008">This thesis, being a proof of concept, yielded some results that could indicate</span></div>
<div style="position:absolute;left:124.80px;top:635.99px" class="cls_008"><span class="cls_008">that actions could be beneficial to the NTA. We did not find any conclusive proof</span></div>
<div style="position:absolute;left:124.80px;top:647.95px" class="cls_008"><span class="cls_008">of anomalies.  This is most likely not possible, and as unsupervised machine</span></div>
<div style="position:absolute;left:124.80px;top:659.90px" class="cls_008"><span class="cls_008">learning is in its early stages of development, it should for now be considered a</span></div>
<div style="position:absolute;left:124.80px;top:671.86px" class="cls_008"><span class="cls_008">tool for assisting the domain experts at the NTA until the field reaches a more</span></div>
<div style="position:absolute;left:124.80px;top:683.81px" class="cls_008"><span class="cls_008">mature state. If the data was labeled and we were able to train a neural network</span></div>
<div style="position:absolute;left:124.80px;top:695.77px" class="cls_008"><span class="cls_008">on the data using supervised learning, we could determine an accuracy of our</span></div>
<div style="position:absolute;left:124.80px;top:707.72px" class="cls_008"><span class="cls_008">findings, but as it stands we have found a set of outliers, and we will have to</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">116</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:101269px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background120.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">leave it up to the NTA to determine whether they are anomalies or not.</span></div>
<div style="position:absolute;left:124.80px;top:153.47px" class="cls_010"><span class="cls_010">7.1</span></div>
<div style="position:absolute;left:161.56px;top:153.47px" class="cls_010"><span class="cls_010">Future Work</span></div>
<div style="position:absolute;left:124.80px;top:179.68px" class="cls_008"><span class="cls_008">For future work we would suggest to explore more advanced unsupervised learn-</span></div>
<div style="position:absolute;left:124.80px;top:191.63px" class="cls_008"><span class="cls_008">ing methods that can handle big datasets with many dimensions. An interesting</span></div>
<div style="position:absolute;left:124.80px;top:203.59px" class="cls_008"><span class="cls_008">turn this project could take, is to get access to the other data that is contained</span></div>
<div style="position:absolute;left:124.80px;top:215.54px" class="cls_008"><span class="cls_008">in A-ordningen.  A lot of tax fraud and fraud in general are done through the</span></div>
<div style="position:absolute;left:124.80px;top:227.50px" class="cls_008"><span class="cls_008">huge NAV system.  Since NAV accounts for about one third of the national</span></div>
<div style="position:absolute;left:124.80px;top:239.45px" class="cls_008"><span class="cls_008">budget [2], an anomaly detection system could be useful.  Fraud detection is</span></div>
<div style="position:absolute;left:124.80px;top:251.41px" class="cls_008"><span class="cls_008">another application of anomaly detection. According to NAV about 7.5 billion</span></div>
<div style="position:absolute;left:124.80px;top:263.36px" class="cls_008"><span class="cls_008">Norwegian kroner are lost yearly due to fraud [18].  If one could introduce a</span></div>
<div style="position:absolute;left:124.80px;top:275.32px" class="cls_008"><span class="cls_008">machine learning model that could learn from previously known anomalies, one</span></div>
<div style="position:absolute;left:124.80px;top:287.27px" class="cls_008"><span class="cls_008">could automatically flag potential anomalies and alert the right instances. For</span></div>
<div style="position:absolute;left:124.80px;top:299.23px" class="cls_008"><span class="cls_008">example one could compare a persons income and number of hours worked with</span></div>
<div style="position:absolute;left:124.80px;top:311.18px" class="cls_008"><span class="cls_008">their NAV notification cards (meldekort). By also labeling these instances one</span></div>
<div style="position:absolute;left:124.80px;top:323.14px" class="cls_008"><span class="cls_008">could create training, validation and test sets, and take advantage of the more</span></div>
<div style="position:absolute;left:124.80px;top:335.09px" class="cls_008"><span class="cls_008">developed field of ML, supervised learning. We believe that this thesis serves as</span></div>
<div style="position:absolute;left:124.80px;top:347.05px" class="cls_008"><span class="cls_008">a proof of concept that there might be a need for some kind of system to detect</span></div>
<div style="position:absolute;left:124.80px;top:359.00px" class="cls_008"><span class="cls_008">anomalies and handle them accordingly.</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">117</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:102120px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background121.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:189.78px" class="cls_009"><span class="cls_009">List of Figures</span></div>
<div style="position:absolute;left:139.75px;top:256.42px" class="cls_008"><span class="cls_008">2.1</span></div>
<div style="position:absolute;left:162.66px;top:256.42px" class="cls_008"><span class="cls_008">Gantt chart of project timeline</span></div>
<div style="position:absolute;left:463.53px;top:256.42px" class="cls_008"><span class="cls_008">9</span></div>
<div style="position:absolute;left:139.75px;top:268.37px" class="cls_008"><span class="cls_008">2.2</span></div>
<div style="position:absolute;left:162.66px;top:268.37px" class="cls_008"><span class="cls_008">Example from one of the earlier meeting minutes</span></div>
<div style="position:absolute;left:458.55px;top:268.37px" class="cls_008"><span class="cls_008">12</span></div>
<div style="position:absolute;left:139.75px;top:280.33px" class="cls_008"><span class="cls_008">2.3</span></div>
<div style="position:absolute;left:162.66px;top:280.33px" class="cls_008"><span class="cls_008">Screenshot of the ’Backlog’ in Trello</span></div>
<div style="position:absolute;left:458.55px;top:280.33px" class="cls_008"><span class="cls_008">13</span></div>
<div style="position:absolute;left:139.75px;top:302.24px" class="cls_008"><span class="cls_008">3.1</span></div>
<div style="position:absolute;left:162.66px;top:302.24px" class="cls_008"><span class="cls_008">Feature engineering in the machine learning workflow</span></div>
<div style="position:absolute;left:458.55px;top:302.24px" class="cls_008"><span class="cls_008">14</span></div>
<div style="position:absolute;left:139.75px;top:314.20px" class="cls_008"><span class="cls_008">3.2</span></div>
<div style="position:absolute;left:162.66px;top:314.20px" class="cls_008"><span class="cls_008">Example of randomly placed centroids with k = 2</span></div>
<div style="position:absolute;left:458.55px;top:314.20px" class="cls_008"><span class="cls_008">16</span></div>
<div style="position:absolute;left:139.75px;top:326.15px" class="cls_008"><span class="cls_008">3.3</span></div>
<div style="position:absolute;left:162.66px;top:326.15px" class="cls_008"><span class="cls_008">Each data point is assigned a cluster based on it’s nearest centroid.</span></div>
<div style="position:absolute;left:458.55px;top:326.15px" class="cls_008"><span class="cls_008">16</span></div>
<div style="position:absolute;left:139.75px;top:338.11px" class="cls_008"><span class="cls_008">3.4</span></div>
<div style="position:absolute;left:162.66px;top:338.11px" class="cls_008"><span class="cls_008">The centroids are updated based on the new clusters</span></div>
<div style="position:absolute;left:458.55px;top:338.11px" class="cls_008"><span class="cls_008">17</span></div>
<div style="position:absolute;left:139.75px;top:350.06px" class="cls_008"><span class="cls_008">3.5</span></div>
<div style="position:absolute;left:162.66px;top:350.06px" class="cls_008"><span class="cls_008">The data points are assigned new clusters</span></div>
<div style="position:absolute;left:458.55px;top:350.06px" class="cls_008"><span class="cls_008">18</span></div>
<div style="position:absolute;left:139.75px;top:362.02px" class="cls_008"><span class="cls_008">3.6</span></div>
<div style="position:absolute;left:162.66px;top:362.02px" class="cls_008"><span class="cls_008">K-means has converged</span></div>
<div style="position:absolute;left:458.55px;top:362.02px" class="cls_008"><span class="cls_008">18</span></div>
<div style="position:absolute;left:139.75px;top:373.97px" class="cls_008"><span class="cls_008">3.7</span></div>
<div style="position:absolute;left:162.66px;top:373.97px" class="cls_008"><span class="cls_008">Traditional clustering method such as K-means would struggle to</span></div>
<div style="position:absolute;left:162.66px;top:385.93px" class="cls_008"><span class="cls_008">differentiate the clusters.  The image on the right visualize how</span></div>
<div style="position:absolute;left:162.66px;top:397.89px" class="cls_008"><span class="cls_008">DBSCAN could have clustered the data. Image taken from [12]. .</span></div>
<div style="position:absolute;left:458.55px;top:397.89px" class="cls_008"><span class="cls_008">19</span></div>
<div style="position:absolute;left:139.75px;top:409.84px" class="cls_008"><span class="cls_008">3.8</span></div>
<div style="position:absolute;left:162.66px;top:409.84px" class="cls_008"><span class="cls_008">Illustration of the different type of points</span></div>
<div style="position:absolute;left:458.55px;top:409.84px" class="cls_008"><span class="cls_008">20</span></div>
<div style="position:absolute;left:139.75px;top:421.80px" class="cls_008"><span class="cls_008">3.9</span></div>
<div style="position:absolute;left:162.66px;top:421.80px" class="cls_008"><span class="cls_008">LOF k = 3 [6]</span></div>
<div style="position:absolute;left:458.55px;top:421.80px" class="cls_008"><span class="cls_008">22</span></div>
<div style="position:absolute;left:139.75px;top:433.75px" class="cls_008"><span class="cls_008">3.10</span></div>
<div style="position:absolute;left:162.66px;top:433.75px" class="cls_008"><span class="cls_008">Transaction example with support threshold = 3</span></div>
<div style="position:absolute;left:458.55px;top:433.75px" class="cls_008"><span class="cls_008">24</span></div>
<div style="position:absolute;left:139.75px;top:445.71px" class="cls_008"><span class="cls_008">3.11</span></div>
<div style="position:absolute;left:162.66px;top:445.71px" class="cls_008"><span class="cls_008">Overview of Minimal Rare itemset.  The support of each set is</span></div>
<div style="position:absolute;left:162.66px;top:457.66px" class="cls_008"><span class="cls_008">represented with roman numerals in the top left corner of every</span></div>
<div style="position:absolute;left:162.66px;top:469.62px" class="cls_008"><span class="cls_008">box</span></div>
<div style="position:absolute;left:458.55px;top:469.62px" class="cls_008"><span class="cls_008">24</span></div>
<div style="position:absolute;left:139.75px;top:481.57px" class="cls_008"><span class="cls_008">3.12</span></div>
<div style="position:absolute;left:162.66px;top:481.57px" class="cls_008"><span class="cls_008">Pseudo code of the Apriori algorithm</span></div>
<div style="position:absolute;left:458.55px;top:481.57px" class="cls_008"><span class="cls_008">25</span></div>
<div style="position:absolute;left:139.75px;top:493.53px" class="cls_008"><span class="cls_008">3.13</span></div>
<div style="position:absolute;left:162.66px;top:493.53px" class="cls_008"><span class="cls_008">Euclidean distance in 2-dimensional space</span></div>
<div style="position:absolute;left:458.55px;top:493.53px" class="cls_008"><span class="cls_008">26</span></div>
<div style="position:absolute;left:139.75px;top:505.48px" class="cls_008"><span class="cls_008">3.14</span></div>
<div style="position:absolute;left:162.66px;top:505.48px" class="cls_008"><span class="cls_008">The basic layout of a notebook</span></div>
<div style="position:absolute;left:458.55px;top:505.48px" class="cls_008"><span class="cls_008">28</span></div>
<div style="position:absolute;left:139.75px;top:527.40px" class="cls_008"><span class="cls_008">4.1</span></div>
<div style="position:absolute;left:162.66px;top:527.40px" class="cls_008"><span class="cls_008">A step-by-step data Preprocessing Overview</span></div>
<div style="position:absolute;left:458.55px;top:527.40px" class="cls_008"><span class="cls_008">31</span></div>
<div style="position:absolute;left:139.75px;top:539.35px" class="cls_008"><span class="cls_008">4.2</span></div>
<div style="position:absolute;left:162.66px;top:539.35px" class="cls_008"><span class="cls_008">Metaview of the XML tree structure</span></div>
<div style="position:absolute;left:458.55px;top:539.35px" class="cls_008"><span class="cls_008">32</span></div>
<div style="position:absolute;left:139.75px;top:551.31px" class="cls_008"><span class="cls_008">4.3</span></div>
<div style="position:absolute;left:162.66px;top:551.31px" class="cls_008"><span class="cls_008">Screenshot taken from the NTA’s webpage. [21]</span></div>
<div style="position:absolute;left:458.55px;top:551.31px" class="cls_008"><span class="cls_008">33</span></div>
<div style="position:absolute;left:139.75px;top:563.26px" class="cls_008"><span class="cls_008">4.4</span></div>
<div style="position:absolute;left:162.66px;top:563.26px" class="cls_008"><span class="cls_008">Screenshot of an XML-file with a replacement-tag</span></div>
<div style="position:absolute;left:458.55px;top:563.26px" class="cls_008"><span class="cls_008">34</span></div>
<div style="position:absolute;left:139.75px;top:575.22px" class="cls_008"><span class="cls_008">4.5</span></div>
<div style="position:absolute;left:162.66px;top:575.22px" class="cls_008"><span class="cls_008">Screenshot of a base64 encoded XML-file</span></div>
<div style="position:absolute;left:458.55px;top:575.22px" class="cls_008"><span class="cls_008">35</span></div>
<div style="position:absolute;left:139.75px;top:587.18px" class="cls_008"><span class="cls_008">4.6</span></div>
<div style="position:absolute;left:162.66px;top:587.18px" class="cls_008"><span class="cls_008">List of the different sub-features of income and their ratio of null</span></div>
<div style="position:absolute;left:162.66px;top:599.13px" class="cls_008"><span class="cls_008">values</span></div>
<div style="position:absolute;left:458.55px;top:599.13px" class="cls_008"><span class="cls_008">36</span></div>
<div style="position:absolute;left:139.75px;top:611.09px" class="cls_008"><span class="cls_008">4.7</span></div>
<div style="position:absolute;left:162.66px;top:611.09px" class="cls_008"><span class="cls_008">Heatmap over all features</span></div>
<div style="position:absolute;left:458.56px;top:611.09px" class="cls_008"><span class="cls_008">37</span></div>
<div style="position:absolute;left:139.75px;top:623.04px" class="cls_008"><span class="cls_008">4.8</span></div>
<div style="position:absolute;left:162.66px;top:623.04px" class="cls_008"><span class="cls_008">Heatmap over four features</span></div>
<div style="position:absolute;left:458.55px;top:623.04px" class="cls_008"><span class="cls_008">38</span></div>
<div style="position:absolute;left:139.75px;top:635.00px" class="cls_008"><span class="cls_008">4.9</span></div>
<div style="position:absolute;left:162.66px;top:635.00px" class="cls_008"><span class="cls_008">Screenshot taken from the NTA’s webpage [22]</span></div>
<div style="position:absolute;left:458.55px;top:635.00px" class="cls_008"><span class="cls_008">38</span></div>
<div style="position:absolute;left:139.75px;top:646.95px" class="cls_008"><span class="cls_008">4.10</span></div>
<div style="position:absolute;left:162.66px;top:646.95px" class="cls_008"><span class="cls_008">Measures of central tendency - Total income</span></div>
<div style="position:absolute;left:458.55px;top:646.95px" class="cls_008"><span class="cls_008">39</span></div>
<div style="position:absolute;left:139.75px;top:658.91px" class="cls_008"><span class="cls_008">4.11</span></div>
<div style="position:absolute;left:162.66px;top:658.91px" class="cls_008"><span class="cls_008">Measures of central tendency - Hours worked</span></div>
<div style="position:absolute;left:458.55px;top:658.91px" class="cls_008"><span class="cls_008">39</span></div>
<div style="position:absolute;left:139.75px;top:670.86px" class="cls_008"><span class="cls_008">4.12</span></div>
<div style="position:absolute;left:162.66px;top:670.86px" class="cls_008"><span class="cls_008">Measures of central tendency - Full time equivalent percentage</span></div>
<div style="position:absolute;left:162.66px;top:682.82px" class="cls_008"><span class="cls_008">(FTE)</span></div>
<div style="position:absolute;left:458.55px;top:682.82px" class="cls_008"><span class="cls_008">39</span></div>
<div style="position:absolute;left:139.75px;top:694.77px" class="cls_008"><span class="cls_008">4.13</span></div>
<div style="position:absolute;left:162.66px;top:694.77px" class="cls_008"><span class="cls_008">Measures of central tendency - Prepayment deductions(PPD)  . .</span></div>
<div style="position:absolute;left:458.55px;top:694.77px" class="cls_008"><span class="cls_008">39</span></div>
<div style="position:absolute;left:139.75px;top:706.73px" class="cls_008"><span class="cls_008">4.14</span></div>
<div style="position:absolute;left:162.66px;top:706.73px" class="cls_008"><span class="cls_008">How to interpret Whisker plots</span></div>
<div style="position:absolute;left:458.55px;top:706.73px" class="cls_008"><span class="cls_008">40</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">118</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:102971px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background122.jpg" width=595 height=841></div>
<div style="position:absolute;left:139.75px;top:124.91px" class="cls_008"><span class="cls_008">4.15</span></div>
<div style="position:absolute;left:162.66px;top:124.91px" class="cls_008"><span class="cls_008">Whisker plot - Total income</span></div>
<div style="position:absolute;left:458.55px;top:124.91px" class="cls_008"><span class="cls_008">40</span></div>
<div style="position:absolute;left:139.75px;top:136.86px" class="cls_008"><span class="cls_008">4.16</span></div>
<div style="position:absolute;left:162.66px;top:136.86px" class="cls_008"><span class="cls_008">Whisker plot - PPD</span></div>
<div style="position:absolute;left:458.55px;top:136.86px" class="cls_008"><span class="cls_008">41</span></div>
<div style="position:absolute;left:139.75px;top:148.82px" class="cls_008"><span class="cls_008">4.17</span></div>
<div style="position:absolute;left:162.66px;top:148.82px" class="cls_008"><span class="cls_008">Whisker plot - FTE</span></div>
<div style="position:absolute;left:458.55px;top:148.82px" class="cls_008"><span class="cls_008">41</span></div>
<div style="position:absolute;left:139.75px;top:160.77px" class="cls_008"><span class="cls_008">4.18</span></div>
<div style="position:absolute;left:162.66px;top:160.77px" class="cls_008"><span class="cls_008">Whisker plot - Hours worked</span></div>
<div style="position:absolute;left:458.55px;top:160.77px" class="cls_008"><span class="cls_008">42</span></div>
<div style="position:absolute;left:139.75px;top:182.69px" class="cls_008"><span class="cls_008">5.1</span></div>
<div style="position:absolute;left:162.66px;top:182.69px" class="cls_008"><span class="cls_008">Snippet of the DataFrame from the loaded CSV</span></div>
<div style="position:absolute;left:458.55px;top:182.69px" class="cls_008"><span class="cls_008">43</span></div>
<div style="position:absolute;left:139.75px;top:194.65px" class="cls_008"><span class="cls_008">5.2</span></div>
<div style="position:absolute;left:162.66px;top:194.65px" class="cls_008"><span class="cls_008">Snippet of the extracted DataFrame</span></div>
<div style="position:absolute;left:458.55px;top:194.65px" class="cls_008"><span class="cls_008">44</span></div>
<div style="position:absolute;left:139.75px;top:206.60px" class="cls_008"><span class="cls_008">5.3</span></div>
<div style="position:absolute;left:162.66px;top:206.60px" class="cls_008"><span class="cls_008">The five different values of WTA</span></div>
<div style="position:absolute;left:458.55px;top:206.60px" class="cls_008"><span class="cls_008">44</span></div>
<div style="position:absolute;left:139.75px;top:218.56px" class="cls_008"><span class="cls_008">5.4</span></div>
<div style="position:absolute;left:162.66px;top:218.56px" class="cls_008"><span class="cls_008">Working time arrangement - one hot encoded</span></div>
<div style="position:absolute;left:458.56px;top:218.56px" class="cls_008"><span class="cls_008">45</span></div>
<div style="position:absolute;left:139.75px;top:230.51px" class="cls_008"><span class="cls_008">5.5</span></div>
<div style="position:absolute;left:162.66px;top:230.51px" class="cls_008"><span class="cls_008">The DataFrame after scaling the values</span></div>
<div style="position:absolute;left:458.55px;top:230.51px" class="cls_008"><span class="cls_008">45</span></div>
<div style="position:absolute;left:139.75px;top:242.47px" class="cls_008"><span class="cls_008">5.6</span></div>
<div style="position:absolute;left:162.66px;top:242.47px" class="cls_008"><span class="cls_008">The DataFrame after implementing PCA</span></div>
<div style="position:absolute;left:458.56px;top:242.47px" class="cls_008"><span class="cls_008">45</span></div>
<div style="position:absolute;left:139.75px;top:254.42px" class="cls_008"><span class="cls_008">5.7</span></div>
<div style="position:absolute;left:162.66px;top:254.42px" class="cls_008"><span class="cls_008">The doKmeans-method</span></div>
<div style="position:absolute;left:458.55px;top:254.42px" class="cls_008"><span class="cls_008">46</span></div>
<div style="position:absolute;left:139.75px;top:266.38px" class="cls_008"><span class="cls_008">5.8</span></div>
<div style="position:absolute;left:162.66px;top:266.38px" class="cls_008"><span class="cls_008">The code for the Elbow Method</span></div>
<div style="position:absolute;left:458.55px;top:266.38px" class="cls_008"><span class="cls_008">47</span></div>
<div style="position:absolute;left:139.75px;top:278.33px" class="cls_008"><span class="cls_008">5.9</span></div>
<div style="position:absolute;left:162.66px;top:278.33px" class="cls_008"><span class="cls_008">The Elbow Method for three features</span></div>
<div style="position:absolute;left:458.55px;top:278.33px" class="cls_008"><span class="cls_008">47</span></div>
<div style="position:absolute;left:139.75px;top:290.29px" class="cls_008"><span class="cls_008">5.10</span></div>
<div style="position:absolute;left:162.66px;top:290.29px" class="cls_008"><span class="cls_008">The Elbow Method for four features</span></div>
<div style="position:absolute;left:458.55px;top:290.29px" class="cls_008"><span class="cls_008">48</span></div>
<div style="position:absolute;left:139.75px;top:302.24px" class="cls_008"><span class="cls_008">5.11</span></div>
<div style="position:absolute;left:162.66px;top:302.24px" class="cls_008"><span class="cls_008">The Elbow Method for five features</span></div>
<div style="position:absolute;left:458.55px;top:302.24px" class="cls_008"><span class="cls_008">48</span></div>
<div style="position:absolute;left:139.75px;top:314.20px" class="cls_008"><span class="cls_008">5.12</span></div>
<div style="position:absolute;left:162.66px;top:314.20px" class="cls_008"><span class="cls_008">Running the doKmeans-method with k = 2</span></div>
<div style="position:absolute;left:458.55px;top:314.20px" class="cls_008"><span class="cls_008">49</span></div>
<div style="position:absolute;left:139.75px;top:326.15px" class="cls_008"><span class="cls_008">5.13</span></div>
<div style="position:absolute;left:162.66px;top:326.15px" class="cls_008"><span class="cls_008">Snippet showing which kmeans cluster each data point belongs to.</span></div>
<div style="position:absolute;left:458.55px;top:326.15px" class="cls_008"><span class="cls_008">49</span></div>
<div style="position:absolute;left:139.75px;top:338.11px" class="cls_008"><span class="cls_008">5.14</span></div>
<div style="position:absolute;left:162.66px;top:338.11px" class="cls_008"><span class="cls_008">The two clusters of the data for three features</span></div>
<div style="position:absolute;left:458.55px;top:338.11px" class="cls_008"><span class="cls_008">49</span></div>
<div style="position:absolute;left:139.75px;top:350.06px" class="cls_008"><span class="cls_008">5.15</span></div>
<div style="position:absolute;left:162.66px;top:350.06px" class="cls_008"><span class="cls_008">The two clusters of the data for four features</span></div>
<div style="position:absolute;left:458.55px;top:350.06px" class="cls_008"><span class="cls_008">50</span></div>
<div style="position:absolute;left:139.75px;top:362.02px" class="cls_008"><span class="cls_008">5.16</span></div>
<div style="position:absolute;left:162.66px;top:362.02px" class="cls_008"><span class="cls_008">The three clusters of the data for five features</span></div>
<div style="position:absolute;left:458.55px;top:362.02px" class="cls_008"><span class="cls_008">50</span></div>
<div style="position:absolute;left:139.75px;top:373.97px" class="cls_008"><span class="cls_008">5.17</span></div>
<div style="position:absolute;left:162.66px;top:373.97px" class="cls_008"><span class="cls_008">Example of how we would detect outliers</span></div>
<div style="position:absolute;left:458.56px;top:373.97px" class="cls_008"><span class="cls_008">51</span></div>
<div style="position:absolute;left:139.75px;top:385.93px" class="cls_008"><span class="cls_008">5.18</span></div>
<div style="position:absolute;left:162.66px;top:385.93px" class="cls_008"><span class="cls_008">Method for determining the average euclidean distance to cluster</span></div>
<div style="position:absolute;left:162.66px;top:397.89px" class="cls_008"><span class="cls_008">centroids for each cluster</span></div>
<div style="position:absolute;left:458.55px;top:397.89px" class="cls_008"><span class="cls_008">52</span></div>
<div style="position:absolute;left:139.75px;top:409.84px" class="cls_008"><span class="cls_008">5.19</span></div>
<div style="position:absolute;left:162.66px;top:409.84px" class="cls_008"><span class="cls_008">Method for determining which data points were x × average_distance</span></div>
<div style="position:absolute;left:162.66px;top:421.80px" class="cls_008"><span class="cls_008">away from centroid</span></div>
<div style="position:absolute;left:458.55px;top:421.80px" class="cls_008"><span class="cls_008">52</span></div>
<div style="position:absolute;left:139.75px;top:433.75px" class="cls_008"><span class="cls_008">5.20</span></div>
<div style="position:absolute;left:162.66px;top:433.75px" class="cls_008"><span class="cls_008">Code for calculating k-dist graph</span></div>
<div style="position:absolute;left:458.55px;top:433.75px" class="cls_008"><span class="cls_008">53</span></div>
<div style="position:absolute;left:139.75px;top:445.71px" class="cls_008"><span class="cls_008">5.21</span></div>
<div style="position:absolute;left:162.66px;top:445.71px" class="cls_008"><span class="cls_008">Eps for dataset with three dimensions</span></div>
<div style="position:absolute;left:458.55px;top:445.71px" class="cls_008"><span class="cls_008">54</span></div>
<div style="position:absolute;left:139.75px;top:457.66px" class="cls_008"><span class="cls_008">5.22</span></div>
<div style="position:absolute;left:162.66px;top:457.66px" class="cls_008"><span class="cls_008">Eps for dataset with four dimensions</span></div>
<div style="position:absolute;left:458.56px;top:457.66px" class="cls_008"><span class="cls_008">54</span></div>
<div style="position:absolute;left:139.75px;top:469.62px" class="cls_008"><span class="cls_008">5.23</span></div>
<div style="position:absolute;left:162.66px;top:469.62px" class="cls_008"><span class="cls_008">Output of DBSCAN</span></div>
<div style="position:absolute;left:458.55px;top:469.62px" class="cls_008"><span class="cls_008">55</span></div>
<div style="position:absolute;left:139.75px;top:481.57px" class="cls_008"><span class="cls_008">5.24</span></div>
<div style="position:absolute;left:162.66px;top:481.57px" class="cls_008"><span class="cls_008">2D plane representation of LOF-scores of each data point.  Ran</span></div>
<div style="position:absolute;left:162.66px;top:493.53px" class="cls_008"><span class="cls_008">on a small sampled dataset with three features</span></div>
<div style="position:absolute;left:458.55px;top:493.53px" class="cls_008"><span class="cls_008">56</span></div>
<div style="position:absolute;left:139.75px;top:505.48px" class="cls_008"><span class="cls_008">5.25</span></div>
<div style="position:absolute;left:162.66px;top:505.48px" class="cls_008"><span class="cls_008">3D plane representation of LOF-scores of each data point.  Ran</span></div>
<div style="position:absolute;left:162.66px;top:517.44px" class="cls_008"><span class="cls_008">on a small sampled dataset with three features</span></div>
<div style="position:absolute;left:458.55px;top:517.44px" class="cls_008"><span class="cls_008">56</span></div>
<div style="position:absolute;left:139.75px;top:529.39px" class="cls_008"><span class="cls_008">5.26</span></div>
<div style="position:absolute;left:162.66px;top:529.39px" class="cls_008"><span class="cls_008">Splitting into quantiles</span></div>
<div style="position:absolute;left:458.55px;top:529.39px" class="cls_008"><span class="cls_008">57</span></div>
<div style="position:absolute;left:139.75px;top:541.35px" class="cls_008"><span class="cls_008">5.27</span></div>
<div style="position:absolute;left:162.66px;top:541.35px" class="cls_008"><span class="cls_008">Unprocessed</span></div>
<div style="position:absolute;left:458.55px;top:541.35px" class="cls_008"><span class="cls_008">58</span></div>
<div style="position:absolute;left:139.75px;top:553.30px" class="cls_008"><span class="cls_008">5.28</span></div>
<div style="position:absolute;left:162.66px;top:553.30px" class="cls_008"><span class="cls_008">Processed</span></div>
<div style="position:absolute;left:458.55px;top:553.30px" class="cls_008"><span class="cls_008">58</span></div>
<div style="position:absolute;left:139.75px;top:565.26px" class="cls_008"><span class="cls_008">5.29</span></div>
<div style="position:absolute;left:162.66px;top:565.26px" class="cls_008"><span class="cls_008">Executing AprioriRare</span></div>
<div style="position:absolute;left:458.55px;top:565.26px" class="cls_008"><span class="cls_008">59</span></div>
<div style="position:absolute;left:139.75px;top:587.18px" class="cls_008"><span class="cls_008">6.1</span></div>
<div style="position:absolute;left:162.66px;top:587.18px" class="cls_008"><span class="cls_008">Histogram of inliers and outliers related to total income</span></div>
<div style="position:absolute;left:458.55px;top:587.18px" class="cls_008"><span class="cls_008">61</span></div>
<div style="position:absolute;left:139.75px;top:599.13px" class="cls_008"><span class="cls_008">6.2</span></div>
<div style="position:absolute;left:162.66px;top:599.13px" class="cls_008"><span class="cls_008">Histogram of inliers and outliers related to FTE percentage  . . .</span></div>
<div style="position:absolute;left:458.55px;top:599.13px" class="cls_008"><span class="cls_008">61</span></div>
<div style="position:absolute;left:139.75px;top:611.09px" class="cls_008"><span class="cls_008">6.3</span></div>
<div style="position:absolute;left:162.66px;top:611.09px" class="cls_008"><span class="cls_008">Histogram of inliers and outliers related to hours worked</span></div>
<div style="position:absolute;left:458.55px;top:611.09px" class="cls_008"><span class="cls_008">62</span></div>
<div style="position:absolute;left:139.75px;top:623.04px" class="cls_008"><span class="cls_008">6.4</span></div>
<div style="position:absolute;left:162.66px;top:623.04px" class="cls_008"><span class="cls_008">All 100.000 data points plotted, outliers marked in red</span></div>
<div style="position:absolute;left:458.55px;top:623.04px" class="cls_008"><span class="cls_008">63</span></div>
<div style="position:absolute;left:139.75px;top:635.00px" class="cls_008"><span class="cls_008">6.5</span></div>
<div style="position:absolute;left:162.66px;top:635.00px" class="cls_008"><span class="cls_008">Closeup of the highest concentration of data points</span></div>
<div style="position:absolute;left:458.55px;top:635.00px" class="cls_008"><span class="cls_008">64</span></div>
<div style="position:absolute;left:139.75px;top:646.95px" class="cls_008"><span class="cls_008">6.6</span></div>
<div style="position:absolute;left:162.66px;top:646.95px" class="cls_008"><span class="cls_008">Histograms for total income, FTE percentage, and hours worked</span></div>
<div style="position:absolute;left:162.66px;top:658.91px" class="cls_008"><span class="cls_008">with K-means run on four features</span></div>
<div style="position:absolute;left:458.56px;top:658.91px" class="cls_008"><span class="cls_008">65</span></div>
<div style="position:absolute;left:139.75px;top:670.86px" class="cls_008"><span class="cls_008">6.7</span></div>
<div style="position:absolute;left:162.66px;top:670.86px" class="cls_008"><span class="cls_008">Histogram of K-means for prepayment deductions</span></div>
<div style="position:absolute;left:458.55px;top:670.86px" class="cls_008"><span class="cls_008">66</span></div>
<div style="position:absolute;left:139.75px;top:682.82px" class="cls_008"><span class="cls_008">6.8</span></div>
<div style="position:absolute;left:162.66px;top:682.82px" class="cls_008"><span class="cls_008">Plot of outliers for four features with total income, PPD and</span></div>
<div style="position:absolute;left:162.66px;top:694.77px" class="cls_008"><span class="cls_008">hours worked as the axis</span></div>
<div style="position:absolute;left:458.55px;top:694.77px" class="cls_008"><span class="cls_008">67</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">119</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:103822px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background123.jpg" width=595 height=841></div>
<div style="position:absolute;left:139.75px;top:124.91px" class="cls_008"><span class="cls_008">6.9</span></div>
<div style="position:absolute;left:162.66px;top:124.91px" class="cls_008"><span class="cls_008">Plot of outliers for 4 features with total income, prepayment de-</span></div>
<div style="position:absolute;left:162.66px;top:136.86px" class="cls_008"><span class="cls_008">ductions and FTE perentage as the axis</span></div>
<div style="position:absolute;left:458.55px;top:136.86px" class="cls_008"><span class="cls_008">68</span></div>
<div style="position:absolute;left:139.75px;top:148.82px" class="cls_008"><span class="cls_008">6.10</span></div>
<div style="position:absolute;left:162.66px;top:148.82px" class="cls_008"><span class="cls_008">Histograms for total income, FTE percentage, hours worked and</span></div>
<div style="position:absolute;left:162.66px;top:160.77px" class="cls_008"><span class="cls_008">PPD with K-means run on 5 features</span></div>
<div style="position:absolute;left:458.55px;top:160.77px" class="cls_008"><span class="cls_008">69</span></div>
<div style="position:absolute;left:139.75px;top:172.73px" class="cls_008"><span class="cls_008">6.11</span></div>
<div style="position:absolute;left:162.66px;top:172.73px" class="cls_008"><span class="cls_008">Barplot of outliers and inliers for working time arrangement.  . .</span></div>
<div style="position:absolute;left:458.55px;top:172.73px" class="cls_008"><span class="cls_008">70</span></div>
<div style="position:absolute;left:139.75px;top:184.68px" class="cls_008"><span class="cls_008">6.12</span></div>
<div style="position:absolute;left:162.66px;top:184.68px" class="cls_008"><span class="cls_008">K-means on five features plot with total income, hours worked</span></div>
<div style="position:absolute;left:162.66px;top:196.64px" class="cls_008"><span class="cls_008">and WTA as the axis</span></div>
<div style="position:absolute;left:458.55px;top:196.64px" class="cls_008"><span class="cls_008">71</span></div>
<div style="position:absolute;left:139.75px;top:208.59px" class="cls_008"><span class="cls_008">6.13</span></div>
<div style="position:absolute;left:162.66px;top:208.59px" class="cls_008"><span class="cls_008">K-means on five features plot with total income, PPD and FTE</span></div>
<div style="position:absolute;left:162.66px;top:220.55px" class="cls_008"><span class="cls_008">percentage as the axis</span></div>
<div style="position:absolute;left:458.55px;top:220.55px" class="cls_008"><span class="cls_008">72</span></div>
<div style="position:absolute;left:139.75px;top:232.51px" class="cls_008"><span class="cls_008">6.14</span></div>
<div style="position:absolute;left:162.66px;top:232.51px" class="cls_008"><span class="cls_008">Venn-diagram for the different outliers detected when running</span></div>
<div style="position:absolute;left:162.66px;top:244.46px" class="cls_008"><span class="cls_008">K-means</span></div>
<div style="position:absolute;left:458.56px;top:244.46px" class="cls_008"><span class="cls_008">73</span></div>
<div style="position:absolute;left:139.75px;top:256.42px" class="cls_008"><span class="cls_008">6.15</span></div>
<div style="position:absolute;left:162.66px;top:256.42px" class="cls_008"><span class="cls_008">Sorted k-dist graph proposes the eps value for three features . . .</span></div>
<div style="position:absolute;left:458.55px;top:256.42px" class="cls_008"><span class="cls_008">74</span></div>
<div style="position:absolute;left:139.75px;top:268.37px" class="cls_008"><span class="cls_008">6.16</span></div>
<div style="position:absolute;left:162.66px;top:268.37px" class="cls_008"><span class="cls_008">3D graph showing the output from DBSCAN. Outliers are colored</span></div>
<div style="position:absolute;left:162.66px;top:280.33px" class="cls_008"><span class="cls_008">blue, while inliers are colored yellow</span></div>
<div style="position:absolute;left:458.55px;top:280.33px" class="cls_008"><span class="cls_008">75</span></div>
<div style="position:absolute;left:139.75px;top:292.28px" class="cls_008"><span class="cls_008">6.17</span></div>
<div style="position:absolute;left:162.66px;top:292.28px" class="cls_008"><span class="cls_008">Two 3D graphs showing the separated inliers and outliers from</span></div>
<div style="position:absolute;left:162.66px;top:304.24px" class="cls_008"><span class="cls_008">DBSCAN. Outliers are colored blue, while inliers are colored yellow.</span></div>
<div style="position:absolute;left:458.55px;top:304.24px" class="cls_008"><span class="cls_008">76</span></div>
<div style="position:absolute;left:139.75px;top:316.19px" class="cls_008"><span class="cls_008">6.18</span></div>
<div style="position:absolute;left:162.66px;top:316.19px" class="cls_008"><span class="cls_008">Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:162.66px;top:328.15px" class="cls_008"><span class="cls_008">regards to total income</span></div>
<div style="position:absolute;left:458.55px;top:328.15px" class="cls_008"><span class="cls_008">76</span></div>
<div style="position:absolute;left:139.75px;top:340.10px" class="cls_008"><span class="cls_008">6.19</span></div>
<div style="position:absolute;left:162.66px;top:340.10px" class="cls_008"><span class="cls_008">Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:162.66px;top:352.06px" class="cls_008"><span class="cls_008">regards to FTE percentage</span></div>
<div style="position:absolute;left:458.55px;top:352.06px" class="cls_008"><span class="cls_008">77</span></div>
<div style="position:absolute;left:139.75px;top:364.01px" class="cls_008"><span class="cls_008">6.20</span></div>
<div style="position:absolute;left:162.66px;top:364.01px" class="cls_008"><span class="cls_008">Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:162.66px;top:375.97px" class="cls_008"><span class="cls_008">regards to hours worked</span></div>
<div style="position:absolute;left:458.55px;top:375.97px" class="cls_008"><span class="cls_008">77</span></div>
<div style="position:absolute;left:139.75px;top:387.92px" class="cls_008"><span class="cls_008">6.21</span></div>
<div style="position:absolute;left:162.66px;top:387.92px" class="cls_008"><span class="cls_008">Heatmaps showing the correlation of the data for outliers and</span></div>
<div style="position:absolute;left:162.66px;top:399.88px" class="cls_008"><span class="cls_008">inliers. Inlier heatmap on the left, and outliers on the right</span></div>
<div style="position:absolute;left:458.55px;top:399.88px" class="cls_008"><span class="cls_008">78</span></div>
<div style="position:absolute;left:139.75px;top:411.83px" class="cls_008"><span class="cls_008">6.22</span></div>
<div style="position:absolute;left:162.66px;top:411.83px" class="cls_008"><span class="cls_008">Sorted k-dist graph proposes the eps value for four features  . . .</span></div>
<div style="position:absolute;left:458.55px;top:411.83px" class="cls_008"><span class="cls_008">79</span></div>
<div style="position:absolute;left:139.75px;top:423.79px" class="cls_008"><span class="cls_008">6.23</span></div>
<div style="position:absolute;left:162.66px;top:423.79px" class="cls_008"><span class="cls_008">3D graph showing the output from DBSCAN. Data is reduced</span></div>
<div style="position:absolute;left:162.66px;top:435.74px" class="cls_008"><span class="cls_008">to three dimensions with PCA. Outliers are colored blue, while</span></div>
<div style="position:absolute;left:162.66px;top:447.70px" class="cls_008"><span class="cls_008">inliers are colored yellow</span></div>
<div style="position:absolute;left:458.55px;top:447.70px" class="cls_008"><span class="cls_008">79</span></div>
<div style="position:absolute;left:139.75px;top:459.65px" class="cls_008"><span class="cls_008">6.24</span></div>
<div style="position:absolute;left:162.66px;top:459.65px" class="cls_008"><span class="cls_008">Two 3D graphs showing the separated inliers and outliers from</span></div>
<div style="position:absolute;left:162.66px;top:471.61px" class="cls_008"><span class="cls_008">DBSCAN. Outliers are colored blue, while inliers are colored yellow.</span></div>
<div style="position:absolute;left:458.55px;top:471.61px" class="cls_008"><span class="cls_008">80</span></div>
<div style="position:absolute;left:139.75px;top:483.56px" class="cls_008"><span class="cls_008">6.25</span></div>
<div style="position:absolute;left:162.66px;top:483.56px" class="cls_008"><span class="cls_008">Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:162.66px;top:495.52px" class="cls_008"><span class="cls_008">regards to total income</span></div>
<div style="position:absolute;left:458.55px;top:495.52px" class="cls_008"><span class="cls_008">80</span></div>
<div style="position:absolute;left:139.75px;top:507.47px" class="cls_008"><span class="cls_008">6.26</span></div>
<div style="position:absolute;left:162.66px;top:507.47px" class="cls_008"><span class="cls_008">Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:162.66px;top:519.43px" class="cls_008"><span class="cls_008">regards to FTE percentage</span></div>
<div style="position:absolute;left:458.55px;top:519.43px" class="cls_008"><span class="cls_008">81</span></div>
<div style="position:absolute;left:139.75px;top:531.38px" class="cls_008"><span class="cls_008">6.27</span></div>
<div style="position:absolute;left:162.66px;top:531.38px" class="cls_008"><span class="cls_008">Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:162.66px;top:543.34px" class="cls_008"><span class="cls_008">regards to hours worked</span></div>
<div style="position:absolute;left:458.55px;top:543.34px" class="cls_008"><span class="cls_008">81</span></div>
<div style="position:absolute;left:139.75px;top:555.29px" class="cls_008"><span class="cls_008">6.28</span></div>
<div style="position:absolute;left:162.66px;top:555.29px" class="cls_008"><span class="cls_008">Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:162.66px;top:567.25px" class="cls_008"><span class="cls_008">regards to prepayment deduction</span></div>
<div style="position:absolute;left:458.55px;top:567.25px" class="cls_008"><span class="cls_008">82</span></div>
<div style="position:absolute;left:139.75px;top:579.21px" class="cls_008"><span class="cls_008">6.29</span></div>
<div style="position:absolute;left:162.66px;top:579.21px" class="cls_008"><span class="cls_008">Heatmaps showing the correlation of the data for inliers (left)</span></div>
<div style="position:absolute;left:162.66px;top:591.16px" class="cls_008"><span class="cls_008">and outliers (right)</span></div>
<div style="position:absolute;left:458.56px;top:591.16px" class="cls_008"><span class="cls_008">82</span></div>
<div style="position:absolute;left:139.75px;top:603.12px" class="cls_008"><span class="cls_008">6.30</span></div>
<div style="position:absolute;left:162.66px;top:603.12px" class="cls_008"><span class="cls_008">Sorted k-dist graph proposes the eps value for five features  . . .</span></div>
<div style="position:absolute;left:458.55px;top:603.12px" class="cls_008"><span class="cls_008">83</span></div>
<div style="position:absolute;left:139.75px;top:615.07px" class="cls_008"><span class="cls_008">6.31</span></div>
<div style="position:absolute;left:162.66px;top:615.07px" class="cls_008"><span class="cls_008">3D graph showing the output from DBSCAN. Data is reduced</span></div>
<div style="position:absolute;left:162.66px;top:627.03px" class="cls_008"><span class="cls_008">to three dimensions with PCA. Outliers are colored blue, while</span></div>
<div style="position:absolute;left:162.66px;top:638.98px" class="cls_008"><span class="cls_008">inliers are colored yellow</span></div>
<div style="position:absolute;left:458.55px;top:638.98px" class="cls_008"><span class="cls_008">84</span></div>
<div style="position:absolute;left:139.75px;top:650.94px" class="cls_008"><span class="cls_008">6.32</span></div>
<div style="position:absolute;left:162.66px;top:650.94px" class="cls_008"><span class="cls_008">Output of DBSCAN, representing different clusters and the amount</span></div>
<div style="position:absolute;left:162.66px;top:662.89px" class="cls_008"><span class="cls_008">of data points in them</span></div>
<div style="position:absolute;left:458.55px;top:662.89px" class="cls_008"><span class="cls_008">84</span></div>
<div style="position:absolute;left:139.75px;top:674.85px" class="cls_008"><span class="cls_008">6.33</span></div>
<div style="position:absolute;left:162.66px;top:674.85px" class="cls_008"><span class="cls_008">Two 3D graphs showing the separated inliers and outliers from</span></div>
<div style="position:absolute;left:162.66px;top:686.80px" class="cls_008"><span class="cls_008">DBSCAN. Outliers are colored blue, while inliers are colored yellow.</span></div>
<div style="position:absolute;left:458.55px;top:686.80px" class="cls_008"><span class="cls_008">84</span></div>
<div style="position:absolute;left:139.75px;top:698.76px" class="cls_008"><span class="cls_008">6.34</span></div>
<div style="position:absolute;left:162.66px;top:698.76px" class="cls_008"><span class="cls_008">Histogram of the distributions of total income, PPD, hours worked</span></div>
<div style="position:absolute;left:162.66px;top:710.71px" class="cls_008"><span class="cls_008">and FTE percentage in that order</span></div>
<div style="position:absolute;left:458.55px;top:710.71px" class="cls_008"><span class="cls_008">85</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">120</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:104673px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background124.jpg" width=595 height=841></div>
<div style="position:absolute;left:139.75px;top:124.91px" class="cls_008"><span class="cls_008">6.35</span></div>
<div style="position:absolute;left:162.66px;top:124.91px" class="cls_008"><span class="cls_008">Histogram showing the distribution of inliers (left) and outliers</span></div>
<div style="position:absolute;left:162.66px;top:136.86px" class="cls_008"><span class="cls_008">(right) with respect to WTA</span></div>
<div style="position:absolute;left:458.55px;top:136.86px" class="cls_008"><span class="cls_008">86</span></div>
<div style="position:absolute;left:139.75px;top:148.82px" class="cls_008"><span class="cls_008">6.36</span></div>
<div style="position:absolute;left:162.66px;top:148.82px" class="cls_008"><span class="cls_008">Venn diagram showing the similar outliers of the three distinct</span></div>
<div style="position:absolute;left:162.66px;top:160.77px" class="cls_008"><span class="cls_008">experiments</span></div>
<div style="position:absolute;left:458.55px;top:160.77px" class="cls_008"><span class="cls_008">87</span></div>
<div style="position:absolute;left:139.75px;top:172.73px" class="cls_008"><span class="cls_008">6.37</span></div>
<div style="position:absolute;left:162.66px;top:172.73px" class="cls_008"><span class="cls_008">Identical 3D plots of three featured data set from distinct view</span></div>
<div style="position:absolute;left:162.66px;top:184.68px" class="cls_008"><span class="cls_008">angles. Outliers are colored blue, while inliers are colored yellow.</span></div>
<div style="position:absolute;left:162.66px;top:196.64px" class="cls_008"><span class="cls_008">Red circle defines the LOF-score of outliers</span></div>
<div style="position:absolute;left:458.55px;top:196.64px" class="cls_008"><span class="cls_008">88</span></div>
<div style="position:absolute;left:139.75px;top:208.59px" class="cls_008"><span class="cls_008">6.38</span></div>
<div style="position:absolute;left:162.66px;top:208.59px" class="cls_008"><span class="cls_008">Identical 3D plots of three featured data set from distinct view</span></div>
<div style="position:absolute;left:162.66px;top:220.55px" class="cls_008"><span class="cls_008">angles. Outliers are colored blue, while inliers are colored yellow.</span></div>
<div style="position:absolute;left:162.66px;top:232.51px" class="cls_008"><span class="cls_008">Red circle defines the LOF-score of outliers</span></div>
<div style="position:absolute;left:458.55px;top:232.51px" class="cls_008"><span class="cls_008">89</span></div>
<div style="position:absolute;left:139.75px;top:244.46px" class="cls_008"><span class="cls_008">6.39</span></div>
<div style="position:absolute;left:162.66px;top:244.46px" class="cls_008"><span class="cls_008">Values for</span><span class="cls_007"> outliers</span><span class="cls_008"> sorted ascending (left) and descending (right)</span></div>
<div style="position:absolute;left:162.66px;top:256.42px" class="cls_008"><span class="cls_008">by FTE percentage</span></div>
<div style="position:absolute;left:458.56px;top:256.42px" class="cls_008"><span class="cls_008">89</span></div>
<div style="position:absolute;left:139.75px;top:268.37px" class="cls_008"><span class="cls_008">6.40</span></div>
<div style="position:absolute;left:162.66px;top:268.37px" class="cls_008"><span class="cls_008">Values for</span><span class="cls_007"> outliers</span><span class="cls_008"> sorted ascending (left) and descending (right)</span></div>
<div style="position:absolute;left:162.66px;top:280.33px" class="cls_008"><span class="cls_008">by hours worked</span></div>
<div style="position:absolute;left:458.55px;top:280.33px" class="cls_008"><span class="cls_008">90</span></div>
<div style="position:absolute;left:139.75px;top:292.28px" class="cls_008"><span class="cls_008">6.41</span></div>
<div style="position:absolute;left:162.66px;top:292.28px" class="cls_008"><span class="cls_008">Values for</span><span class="cls_007"> inliers</span><span class="cls_008"> sorted ascending (left) and descending (right)</span></div>
<div style="position:absolute;left:162.66px;top:304.24px" class="cls_008"><span class="cls_008">by hours worked</span></div>
<div style="position:absolute;left:458.55px;top:304.24px" class="cls_008"><span class="cls_008">90</span></div>
<div style="position:absolute;left:139.75px;top:316.19px" class="cls_008"><span class="cls_008">6.42</span></div>
<div style="position:absolute;left:162.66px;top:316.19px" class="cls_008"><span class="cls_008">Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:162.66px;top:328.15px" class="cls_008"><span class="cls_008">regards to total income</span></div>
<div style="position:absolute;left:458.55px;top:328.15px" class="cls_008"><span class="cls_008">91</span></div>
<div style="position:absolute;left:139.75px;top:340.10px" class="cls_008"><span class="cls_008">6.43</span></div>
<div style="position:absolute;left:162.66px;top:340.10px" class="cls_008"><span class="cls_008">Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:162.66px;top:352.06px" class="cls_008"><span class="cls_008">regards to hours worked</span></div>
<div style="position:absolute;left:458.55px;top:352.06px" class="cls_008"><span class="cls_008">91</span></div>
<div style="position:absolute;left:139.75px;top:364.01px" class="cls_008"><span class="cls_008">6.44</span></div>
<div style="position:absolute;left:162.66px;top:364.01px" class="cls_008"><span class="cls_008">Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:162.66px;top:375.97px" class="cls_008"><span class="cls_008">regards to FTE percentage</span></div>
<div style="position:absolute;left:458.55px;top:375.97px" class="cls_008"><span class="cls_008">92</span></div>
<div style="position:absolute;left:139.75px;top:387.92px" class="cls_008"><span class="cls_008">6.45</span></div>
<div style="position:absolute;left:162.66px;top:387.92px" class="cls_008"><span class="cls_008">Identical 3D plots of three featured data set from distinct view</span></div>
<div style="position:absolute;left:162.66px;top:399.88px" class="cls_008"><span class="cls_008">angles. Outliers are colored blue, while inliers are colored yellow.</span></div>
<div style="position:absolute;left:162.66px;top:411.83px" class="cls_008"><span class="cls_008">Red circle defines the LOF-score of outliers</span></div>
<div style="position:absolute;left:458.55px;top:411.83px" class="cls_008"><span class="cls_008">93</span></div>
<div style="position:absolute;left:139.75px;top:423.79px" class="cls_008"><span class="cls_008">6.46</span></div>
<div style="position:absolute;left:162.66px;top:423.79px" class="cls_008"><span class="cls_008">Identical 3D plots of four featured data set from distinct view an-</span></div>
<div style="position:absolute;left:162.66px;top:435.74px" class="cls_008"><span class="cls_008">gles. Data is reduced to three dimensions with PCA. Outliers are</span></div>
<div style="position:absolute;left:162.66px;top:447.70px" class="cls_008"><span class="cls_008">colored blue, while inliers are colored yellow.  Red circle defines</span></div>
<div style="position:absolute;left:162.66px;top:459.65px" class="cls_008"><span class="cls_008">the LOF-score of outliers</span></div>
<div style="position:absolute;left:458.55px;top:459.65px" class="cls_008"><span class="cls_008">94</span></div>
<div style="position:absolute;left:139.75px;top:471.61px" class="cls_008"><span class="cls_008">6.47</span></div>
<div style="position:absolute;left:162.66px;top:471.61px" class="cls_008"><span class="cls_008">Identical 3D plots of four featured data set from distinct view an-</span></div>
<div style="position:absolute;left:162.66px;top:483.56px" class="cls_008"><span class="cls_008">gles. Data is reduced to three dimensions with PCA. Outliers are</span></div>
<div style="position:absolute;left:162.66px;top:495.52px" class="cls_008"><span class="cls_008">colored blue, while inliers are colored yellow.  Red circle defines</span></div>
<div style="position:absolute;left:162.66px;top:507.47px" class="cls_008"><span class="cls_008">the LOF-score of outliers</span></div>
<div style="position:absolute;left:458.55px;top:507.47px" class="cls_008"><span class="cls_008">94</span></div>
<div style="position:absolute;left:139.75px;top:519.43px" class="cls_008"><span class="cls_008">6.48</span></div>
<div style="position:absolute;left:162.66px;top:519.43px" class="cls_008"><span class="cls_008">Values for the outliers with the highest LOF-score</span></div>
<div style="position:absolute;left:458.55px;top:519.43px" class="cls_008"><span class="cls_008">95</span></div>
<div style="position:absolute;left:139.75px;top:531.38px" class="cls_008"><span class="cls_008">6.49</span></div>
<div style="position:absolute;left:162.66px;top:531.38px" class="cls_008"><span class="cls_008">Histogram of outliers and inliers with regards to total income  . .</span></div>
<div style="position:absolute;left:458.56px;top:531.38px" class="cls_008"><span class="cls_008">95</span></div>
<div style="position:absolute;left:139.75px;top:543.34px" class="cls_008"><span class="cls_008">6.50</span></div>
<div style="position:absolute;left:162.66px;top:543.34px" class="cls_008"><span class="cls_008">Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:162.66px;top:555.29px" class="cls_008"><span class="cls_008">regards to FTE percentage</span></div>
<div style="position:absolute;left:458.55px;top:555.29px" class="cls_008"><span class="cls_008">96</span></div>
<div style="position:absolute;left:139.75px;top:567.25px" class="cls_008"><span class="cls_008">6.51</span></div>
<div style="position:absolute;left:162.66px;top:567.25px" class="cls_008"><span class="cls_008">Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:162.66px;top:579.21px" class="cls_008"><span class="cls_008">regards to hours worked</span></div>
<div style="position:absolute;left:458.55px;top:579.21px" class="cls_008"><span class="cls_008">96</span></div>
<div style="position:absolute;left:139.75px;top:591.16px" class="cls_008"><span class="cls_008">6.52</span></div>
<div style="position:absolute;left:162.66px;top:591.16px" class="cls_008"><span class="cls_008">Histogram showing the distribution of outliers and inliers with</span></div>
<div style="position:absolute;left:162.66px;top:603.12px" class="cls_008"><span class="cls_008">regards to "Forskuddstrekk"</span></div>
<div style="position:absolute;left:458.55px;top:603.12px" class="cls_008"><span class="cls_008">97</span></div>
<div style="position:absolute;left:139.75px;top:615.07px" class="cls_008"><span class="cls_008">6.53</span></div>
<div style="position:absolute;left:162.66px;top:615.07px" class="cls_008"><span class="cls_008">Identical 3D plots of five featured dataset from distinct view an-</span></div>
<div style="position:absolute;left:162.66px;top:627.03px" class="cls_008"><span class="cls_008">gles.  Outliers are colored blue, while inliers are colored yellow.</span></div>
<div style="position:absolute;left:162.66px;top:638.98px" class="cls_008"><span class="cls_008">Red circle defines the LOF-score of outliers</span></div>
<div style="position:absolute;left:458.55px;top:638.98px" class="cls_008"><span class="cls_008">98</span></div>
<div style="position:absolute;left:139.75px;top:650.94px" class="cls_008"><span class="cls_008">6.54</span></div>
<div style="position:absolute;left:162.66px;top:650.94px" class="cls_008"><span class="cls_008">Identical 3D plots of five featured dataset from distinct view an-</span></div>
<div style="position:absolute;left:162.66px;top:662.89px" class="cls_008"><span class="cls_008">gles.  Outliers are colored blue, while inliers are colored yellow.</span></div>
<div style="position:absolute;left:162.66px;top:674.85px" class="cls_008"><span class="cls_008">Red circle defines the LOF-score of outliers</span></div>
<div style="position:absolute;left:458.55px;top:674.85px" class="cls_008"><span class="cls_008">98</span></div>
<div style="position:absolute;left:139.75px;top:686.80px" class="cls_008"><span class="cls_008">6.55</span></div>
<div style="position:absolute;left:162.66px;top:686.80px" class="cls_008"><span class="cls_008">Histogram of the distributions of total income, prepayment de-</span></div>
<div style="position:absolute;left:162.66px;top:698.76px" class="cls_008"><span class="cls_008">duction, hours worked and FTE percentage in that order</span></div>
<div style="position:absolute;left:458.55px;top:698.76px" class="cls_008"><span class="cls_008">99</span></div>
<div style="position:absolute;left:139.75px;top:710.71px" class="cls_008"><span class="cls_008">6.56</span></div>
<div style="position:absolute;left:162.66px;top:710.71px" class="cls_008"><span class="cls_008">Barplot of inliers (left) and outliers (right) with respect to WTA.</span></div>
<div style="position:absolute;left:453.57px;top:710.71px" class="cls_008"><span class="cls_008">100</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">121</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:105524px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background125.jpg" width=595 height=841></div>
<div style="position:absolute;left:139.75px;top:124.91px" class="cls_008"><span class="cls_008">6.57</span></div>
<div style="position:absolute;left:453.57px;top:124.91px" class="cls_008"><span class="cls_008">101</span></div>
<div style="position:absolute;left:139.75px;top:136.86px" class="cls_008"><span class="cls_008">6.58</span></div>
<div style="position:absolute;left:162.66px;top:136.86px" class="cls_008"><span class="cls_008">Histogram of inliers and outliers related to total income</span></div>
<div style="position:absolute;left:453.57px;top:136.86px" class="cls_008"><span class="cls_008">102</span></div>
<div style="position:absolute;left:139.75px;top:148.82px" class="cls_008"><span class="cls_008">6.59</span></div>
<div style="position:absolute;left:162.66px;top:148.82px" class="cls_008"><span class="cls_008">Histogram of inliers and outliers related to FTE percentage  . . .</span></div>
<div style="position:absolute;left:453.57px;top:148.82px" class="cls_008"><span class="cls_008">103</span></div>
<div style="position:absolute;left:139.75px;top:160.77px" class="cls_008"><span class="cls_008">6.60</span></div>
<div style="position:absolute;left:162.66px;top:160.77px" class="cls_008"><span class="cls_008">Histogram of inliers and outliers related to hours worked</span></div>
<div style="position:absolute;left:453.57px;top:160.77px" class="cls_008"><span class="cls_008">103</span></div>
<div style="position:absolute;left:139.75px;top:172.73px" class="cls_008"><span class="cls_008">6.61</span></div>
<div style="position:absolute;left:162.66px;top:172.73px" class="cls_008"><span class="cls_008">Scatter plot of inliers (blue) and outliers (red)</span></div>
<div style="position:absolute;left:453.57px;top:172.73px" class="cls_008"><span class="cls_008">104</span></div>
<div style="position:absolute;left:139.75px;top:184.68px" class="cls_008"><span class="cls_008">6.62</span></div>
<div style="position:absolute;left:162.66px;top:184.68px" class="cls_008"><span class="cls_008">Heatmaps of inliers and outliers with three features</span></div>
<div style="position:absolute;left:453.57px;top:184.68px" class="cls_008"><span class="cls_008">104</span></div>
<div style="position:absolute;left:139.75px;top:196.64px" class="cls_008"><span class="cls_008">6.63</span></div>
<div style="position:absolute;left:162.66px;top:196.64px" class="cls_008"><span class="cls_008">Histograms of inliers and outliers with four features</span></div>
<div style="position:absolute;left:453.57px;top:196.64px" class="cls_008"><span class="cls_008">105</span></div>
<div style="position:absolute;left:139.75px;top:208.59px" class="cls_008"><span class="cls_008">6.64</span></div>
<div style="position:absolute;left:162.66px;top:208.59px" class="cls_008"><span class="cls_008">Histograms of inliers and outliers with five features</span></div>
<div style="position:absolute;left:453.57px;top:208.59px" class="cls_008"><span class="cls_008">105</span></div>
<div style="position:absolute;left:139.75px;top:220.55px" class="cls_008"><span class="cls_008">6.65</span></div>
<div style="position:absolute;left:162.66px;top:220.55px" class="cls_008"><span class="cls_008">Heatmaps of inliers and outliers with four features</span></div>
<div style="position:absolute;left:453.57px;top:220.55px" class="cls_008"><span class="cls_008">106</span></div>
<div style="position:absolute;left:139.75px;top:232.51px" class="cls_008"><span class="cls_008">6.66</span></div>
<div style="position:absolute;left:162.66px;top:232.51px" class="cls_008"><span class="cls_008">Heatmaps of inliers and outliers with five features</span></div>
<div style="position:absolute;left:453.57px;top:232.51px" class="cls_008"><span class="cls_008">106</span></div>
<div style="position:absolute;left:139.75px;top:244.46px" class="cls_008"><span class="cls_008">6.67</span></div>
<div style="position:absolute;left:162.66px;top:244.46px" class="cls_008"><span class="cls_008">Venn diagram comparing outliers from all experiments (100.000</span></div>
<div style="position:absolute;left:162.66px;top:256.42px" class="cls_008"><span class="cls_008">data points)</span></div>
<div style="position:absolute;left:453.57px;top:256.42px" class="cls_008"><span class="cls_008">107</span></div>
<div style="position:absolute;left:139.75px;top:268.37px" class="cls_008"><span class="cls_008">6.68</span></div>
<div style="position:absolute;left:162.66px;top:268.37px" class="cls_008"><span class="cls_008">Measures of central tendency - Outliers vs total data points  . . .</span></div>
<div style="position:absolute;left:453.57px;top:268.37px" class="cls_008"><span class="cls_008">108</span></div>
<div style="position:absolute;left:139.75px;top:280.33px" class="cls_008"><span class="cls_008">6.69</span></div>
<div style="position:absolute;left:162.66px;top:280.33px" class="cls_008"><span class="cls_008">Values for the first few outliers from the intersection of all three</span></div>
<div style="position:absolute;left:162.66px;top:292.28px" class="cls_008"><span class="cls_008">experiments</span></div>
<div style="position:absolute;left:453.56px;top:292.28px" class="cls_008"><span class="cls_008">108</span></div>
<div style="position:absolute;left:139.75px;top:304.24px" class="cls_008"><span class="cls_008">6.70</span></div>
<div style="position:absolute;left:162.66px;top:304.24px" class="cls_008"><span class="cls_008">Venn diagram of outliers found in K-means, DBSCAN, Apriori-</span></div>
<div style="position:absolute;left:162.66px;top:316.19px" class="cls_008"><span class="cls_008">Rare and LOF using three features</span></div>
<div style="position:absolute;left:453.57px;top:316.19px" class="cls_008"><span class="cls_008">109</span></div>
<div style="position:absolute;left:139.75px;top:328.15px" class="cls_008"><span class="cls_008">6.71</span></div>
<div style="position:absolute;left:162.66px;top:328.15px" class="cls_008"><span class="cls_008">Venn diagram of outliers found in K-means, DBSCAN, Apriori-</span></div>
<div style="position:absolute;left:162.66px;top:340.10px" class="cls_008"><span class="cls_008">Rare and LOF using four features</span></div>
<div style="position:absolute;left:453.57px;top:340.10px" class="cls_008"><span class="cls_008">110</span></div>
<div style="position:absolute;left:139.75px;top:352.06px" class="cls_008"><span class="cls_008">6.72</span></div>
<div style="position:absolute;left:162.66px;top:352.06px" class="cls_008"><span class="cls_008">Venn diagram of outliers found in K-means, DBSCAN, Apriori-</span></div>
<div style="position:absolute;left:162.66px;top:364.01px" class="cls_008"><span class="cls_008">Rare and LOF using five features</span></div>
<div style="position:absolute;left:453.57px;top:364.01px" class="cls_008"><span class="cls_008">111</span></div>
<div style="position:absolute;left:139.75px;top:375.97px" class="cls_008"><span class="cls_008">6.73</span></div>
<div style="position:absolute;left:162.66px;top:375.97px" class="cls_008"><span class="cls_008">Venn diagram randomly chosen numbers between 1 and 100.000.</span></div>
<div style="position:absolute;left:453.57px;top:375.97px" class="cls_008"><span class="cls_008">112</span></div>
<div style="position:absolute;left:139.75px;top:387.92px" class="cls_008"><span class="cls_008">6.74</span></div>
<div style="position:absolute;left:162.66px;top:387.92px" class="cls_008"><span class="cls_008">Values from outlier 1 detected in the intersection RIM ∩ DB-</span></div>
<div style="position:absolute;left:162.66px;top:399.88px" class="cls_008"><span class="cls_008">SCAN ∩ K-means for three features</span></div>
<div style="position:absolute;left:453.57px;top:399.88px" class="cls_008"><span class="cls_008">113</span></div>
<div style="position:absolute;left:139.75px;top:411.83px" class="cls_008"><span class="cls_008">6.75</span></div>
<div style="position:absolute;left:162.66px;top:411.83px" class="cls_008"><span class="cls_008">Other A-meldinger from outlier 1</span></div>
<div style="position:absolute;left:453.56px;top:411.83px" class="cls_008"><span class="cls_008">113</span></div>
<div style="position:absolute;left:139.75px;top:423.79px" class="cls_008"><span class="cls_008">6.76</span></div>
<div style="position:absolute;left:162.66px;top:423.79px" class="cls_008"><span class="cls_008">Values from outlier 2 detected in the intersection RIM ∩ DB-</span></div>
<div style="position:absolute;left:162.66px;top:435.74px" class="cls_008"><span class="cls_008">SCAN ∩ K-means for three features</span></div>
<div style="position:absolute;left:453.57px;top:435.74px" class="cls_008"><span class="cls_008">114</span></div>
<div style="position:absolute;left:139.75px;top:447.70px" class="cls_008"><span class="cls_008">6.77</span></div>
<div style="position:absolute;left:162.66px;top:447.70px" class="cls_008"><span class="cls_008">Other A-meldinger from outlier 2</span></div>
<div style="position:absolute;left:453.56px;top:447.70px" class="cls_008"><span class="cls_008">114</span></div>
<div style="position:absolute;left:139.75px;top:459.65px" class="cls_008"><span class="cls_008">6.78</span></div>
<div style="position:absolute;left:162.66px;top:459.65px" class="cls_008"><span class="cls_008">Comparing DBSCAN and LOF, 4 features.  Data is reduced to</span></div>
<div style="position:absolute;left:162.66px;top:471.61px" class="cls_008"><span class="cls_008">three dimensions with PCA. Outliers are colored blue, while in-</span></div>
<div style="position:absolute;left:162.66px;top:483.56px" class="cls_008"><span class="cls_008">liers are colored yellow</span></div>
<div style="position:absolute;left:453.57px;top:483.56px" class="cls_008"><span class="cls_008">115</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">122</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:106375px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background126.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:189.78px" class="cls_009"><span class="cls_009">Bibliography</span></div>
<div style="position:absolute;left:129.78px;top:257.75px" class="cls_008"><span class="cls_008">[1]</span></div>
<div style="position:absolute;left:145.28px;top:257.75px" class="cls_008"><span class="cls_008">Rakesh Agrawal, Tomasz Imieliński, and Arun Swami. Mining association</span></div>
<div style="position:absolute;left:145.28px;top:269.70px" class="cls_008"><span class="cls_008">rules between sets of items in large databases. Proceedings of the 1993 ACM</span></div>
<div style="position:absolute;left:145.28px;top:281.66px" class="cls_008"><span class="cls_008">SIGMOD international conference on Management of data, pages 207-216,</span></div>
<div style="position:absolute;left:145.28px;top:293.61px" class="cls_008"><span class="cls_008">1993.</span></div>
<div style="position:absolute;left:129.78px;top:313.54px" class="cls_008"><span class="cls_008">[2]</span></div>
<div style="position:absolute;left:145.28px;top:313.54px" class="cls_008"><span class="cls_008">Arbeids-  og  Sosialdepartementet.    Arbeids-  og  velferdsetaten</span></div>
<div style="position:absolute;left:442.50px;top:313.54px" class="cls_008"><span class="cls_008">(nav).</span></div>
<div style="position:absolute;left:145.28px;top:325.49px" class="cls_008"><span class="cls_008"> </span><A HREF="https://www.regjeringen.no/no/dep/asd/org/etatstyring/underliggende-etater/arbeids_og_velferdsetaten/id1511/">https://www.regjeringen.no/no/dep/asd/org/etatstyring/</A> </div>
<div style="position:absolute;left:145.28px;top:337.45px" class="cls_008"><span class="cls_008"> </span><A HREF="https://www.regjeringen.no/no/dep/asd/org/etatstyring/underliggende-etater/arbeids_og_velferdsetaten/id1511/">underliggende-etater/arbeids_og_velferdsetaten/id1511/</A>,</div>
<div style="position:absolute;left:445.82px;top:337.45px" class="cls_008"><span class="cls_008">2019.</span></div>
<div style="position:absolute;left:145.28px;top:349.40px" class="cls_008"><span class="cls_008">[Online; accessed 18-May-2019].</span></div>
<div style="position:absolute;left:129.78px;top:369.33px" class="cls_008"><span class="cls_008">[3]</span></div>
<div style="position:absolute;left:145.28px;top:369.33px" class="cls_008"><span class="cls_008">Christopher M. Bishop. Pattern Recognition and Machine Learning (Infor-</span></div>
<div style="position:absolute;left:145.28px;top:381.29px" class="cls_008"><span class="cls_008">mation Science and Statistics). Springer-Verlag, Berlin, Heidelberg, 2006.</span></div>
<div style="position:absolute;left:129.78px;top:401.21px" class="cls_008"><span class="cls_008">[4]</span></div>
<div style="position:absolute;left:145.28px;top:401.21px" class="cls_008"><span class="cls_008">Markus M. Breunig, Hans-Peter Kriegel, Raymond T. Ng, and Jörg Sander.</span></div>
<div style="position:absolute;left:145.28px;top:413.17px" class="cls_008"><span class="cls_008">Lof: Identifying density-based local outliers. SIGMOD Rec., 29(2):93-104,</span></div>
<div style="position:absolute;left:145.28px;top:425.12px" class="cls_008"><span class="cls_008">May 2000.</span></div>
<div style="position:absolute;left:129.78px;top:445.05px" class="cls_008"><span class="cls_008">[5]</span></div>
<div style="position:absolute;left:145.28px;top:445.05px" class="cls_008"><span class="cls_008">Lars Buitinck, Gilles Louppe, Mathieu Blondel, Fabian Pedregosa, An-</span></div>
<div style="position:absolute;left:145.28px;top:457.00px" class="cls_008"><span class="cls_008">dreas Mueller, Olivier Grisel, Vlad Niculae, Peter Prettenhofer, Alexandre</span></div>
<div style="position:absolute;left:145.28px;top:468.96px" class="cls_008"><span class="cls_008">Gramfort, Jaques Grobler, Robert Layton, Jake VanderPlas, Arnaud Joly,</span></div>
<div style="position:absolute;left:145.28px;top:480.91px" class="cls_008"><span class="cls_008">Brian Holt, and Gaël Varoquaux. API design for machine learning software:</span></div>
<div style="position:absolute;left:145.28px;top:492.87px" class="cls_008"><span class="cls_008">experiences from the scikit-learn project. In ECML PKDD Workshop: Lan-</span></div>
<div style="position:absolute;left:145.28px;top:504.82px" class="cls_008"><span class="cls_008">guages for Data Mining and Machine Learning, pages 108-122, 2013.</span></div>
<div style="position:absolute;left:129.78px;top:524.75px" class="cls_008"><span class="cls_008">[6]</span></div>
<div style="position:absolute;left:145.28px;top:524.75px" class="cls_008"><span class="cls_008">Martin Ester, Hans-Peter Kriegel, Jörg Sander, and Xiaowei Xu. A density-</span></div>
<div style="position:absolute;left:145.28px;top:536.70px" class="cls_008"><span class="cls_008">based algorithm for discovering clusters a density-based algorithm for dis-</span></div>
<div style="position:absolute;left:145.28px;top:548.66px" class="cls_008"><span class="cls_008">covering clusters in large spatial databases with noise. In Proceedings of the</span></div>
<div style="position:absolute;left:145.28px;top:560.61px" class="cls_008"><span class="cls_008">Second International Conference on Knowledge Discovery and Data Min-</span></div>
<div style="position:absolute;left:145.28px;top:572.57px" class="cls_008"><span class="cls_008">ing, KDD’96, pages 226-231. AAAI Press, 1996.</span></div>
<div style="position:absolute;left:129.78px;top:592.49px" class="cls_008"><span class="cls_008">[7]</span></div>
<div style="position:absolute;left:145.28px;top:592.49px" class="cls_008"><span class="cls_008">Philippe Fournier Viger, Chun-Wei Lin, Bay Vo, Tin Truong, ji zhang, and</span></div>
<div style="position:absolute;left:145.28px;top:604.45px" class="cls_008"><span class="cls_008">Bac Le. A survey of itemset mining. Wiley Interdisciplinary Reviews: Data</span></div>
<div style="position:absolute;left:145.28px;top:616.40px" class="cls_008"><span class="cls_008">Mining and Knowledge Discovery, 04 2017.</span></div>
<div style="position:absolute;left:129.78px;top:636.33px" class="cls_008"><span class="cls_008">[8]</span></div>
<div style="position:absolute;left:145.28px;top:636.33px" class="cls_008"><span class="cls_008">Nizar Grira, Michel Crucianu, and Nozha Boujemaa.  Unsupervised and</span></div>
<div style="position:absolute;left:145.28px;top:648.28px" class="cls_008"><span class="cls_008">semi-supervised clustering: a brief survey. A Review of Machine Learning</span></div>
<div style="position:absolute;left:145.28px;top:660.24px" class="cls_008"><span class="cls_008">Techniques for Processing Multimedia Content, 09 2005.</span></div>
<div style="position:absolute;left:129.78px;top:680.16px" class="cls_008"><span class="cls_008">[9]</span></div>
<div style="position:absolute;left:145.28px;top:680.16px" class="cls_008"><span class="cls_008">Ian Jolliffe. Principal component analysis. In Miodrag Lovric, editor, In-</span></div>
<div style="position:absolute;left:145.28px;top:692.12px" class="cls_008"><span class="cls_008">ternational Encyclopedia of Statistical Science, pages 1094-1096. Springer</span></div>
<div style="position:absolute;left:145.28px;top:704.07px" class="cls_008"><span class="cls_008">Berlin Heidelberg, Berlin, Heidelberg, 2011.</span></div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">123</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:107226px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background127.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">[10]</span></div>
<div style="position:absolute;left:145.28px;top:124.91px" class="cls_008"><span class="cls_008">Yezheng Liu, Zhe Li, Chong Zhou, Yuanchun Jiang, Jianshan Sun, Meng</span></div>
<div style="position:absolute;left:145.28px;top:136.86px" class="cls_008"><span class="cls_008">Wang, and Xiangnan He.  Generative adversarial active learning for un-</span></div>
<div style="position:absolute;left:145.28px;top:148.82px" class="cls_008"><span class="cls_008">supervised outlier detection.  IEEE Transactions on Knowledge and Data</span></div>
<div style="position:absolute;left:145.28px;top:160.77px" class="cls_008"><span class="cls_008">Engineering, PP:1-1, 03 2019.</span></div>
<div style="position:absolute;left:124.80px;top:180.70px" class="cls_008"><span class="cls_008">[11]</span></div>
<div style="position:absolute;left:145.28px;top:180.70px" class="cls_008"><span class="cls_008">Stuart P. Lloyd.  Least squares quantization in pcm.  IEEE Transactions</span></div>
<div style="position:absolute;left:145.28px;top:192.65px" class="cls_008"><span class="cls_008">on Information Theory, 28(2):129-136, 1982.</span></div>
<div style="position:absolute;left:124.80px;top:212.58px" class="cls_008"><span class="cls_008">[12]</span></div>
<div style="position:absolute;left:145.28px;top:212.58px" class="cls_008"><span class="cls_008">Evan Lutins. Dbscan: What is it? when to use it? how to use it. Medium,</span></div>
<div style="position:absolute;left:145.28px;top:224.54px" class="cls_008"><span class="cls_008">9 2016.</span></div>
<div style="position:absolute;left:124.80px;top:244.46px" class="cls_008"><span class="cls_008">[13]</span></div>
<div style="position:absolute;left:145.28px;top:244.46px" class="cls_008"><span class="cls_008">Nita M.Dimble and Bharat A. Tidke. A framework for outlier detection in</span></div>
<div style="position:absolute;left:145.28px;top:256.42px" class="cls_008"><span class="cls_008">geographic spatial data. In FOCS 2015, 2015.</span></div>
<div style="position:absolute;left:124.80px;top:276.34px" class="cls_008"><span class="cls_008">[14]</span></div>
<div style="position:absolute;left:145.28px;top:276.34px" class="cls_008"><span class="cls_008">Lov om offisiell statistikk og Statistisk Sentralbyrå (statistikkloven) (LOV-</span></div>
<div style="position:absolute;left:145.28px;top:288.30px" class="cls_008"><span class="cls_008">1989-06-16-54), 1989.</span></div>
<div style="position:absolute;left:124.80px;top:308.22px" class="cls_008"><span class="cls_008">[15]</span></div>
<div style="position:absolute;left:145.28px;top:308.22px" class="cls_008"><span class="cls_008">F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel,</span></div>
<div style="position:absolute;left:145.28px;top:320.18px" class="cls_008"><span class="cls_008">M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Pas-</span></div>
<div style="position:absolute;left:145.28px;top:332.13px" class="cls_008"><span class="cls_008">sos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay.  Scikit-</span></div>
<div style="position:absolute;left:145.28px;top:344.09px" class="cls_008"><span class="cls_008">learn: Machine learning in Python. Journal of Machine Learning Research,</span></div>
<div style="position:absolute;left:145.28px;top:356.04px" class="cls_008"><span class="cls_008">12:2825-2830, 2011.</span></div>
<div style="position:absolute;left:124.80px;top:375.97px" class="cls_008"><span class="cls_008">[16]</span></div>
<div style="position:absolute;left:145.28px;top:375.97px" class="cls_008"><span class="cls_008">Philippe Fournier-Viger.  Mining minimal rare itemsets using the apri-</span></div>
<div style="position:absolute;left:145.28px;top:387.92px" class="cls_008"><span class="cls_008">orirare  algorithm.   </span><A HREF="http://www.philippe-fournier-viger.com/spmf/AprioriRare.php">http://www.philippe-fournier-viger.com/spmf/</A> </div>
<div style="position:absolute;left:145.28px;top:399.88px" class="cls_008"><span class="cls_008"> </span><A HREF="http://www.philippe-fournier-viger.com/spmf/AprioriRare.php">AprioriRare.php</A>, 2008-2019. [Online; accessed 19-May-2019].</div>
<div style="position:absolute;left:124.80px;top:419.80px" class="cls_008"><span class="cls_008">[17]</span></div>
<div style="position:absolute;left:145.28px;top:419.80px" class="cls_008"><span class="cls_008">M. Salehi, C. Leckie, J. C. Bezdek, T. Vaithianathan, and X. Zhang. Fast</span></div>
<div style="position:absolute;left:145.28px;top:431.76px" class="cls_008"><span class="cls_008">memory efficient local outlier detection in data streams (extended abstract).</span></div>
<div style="position:absolute;left:145.28px;top:443.71px" class="cls_008"><span class="cls_008">In 2017 IEEE 33rd International Conference on Data Engineering (ICDE),</span></div>
<div style="position:absolute;left:145.28px;top:455.67px" class="cls_008"><span class="cls_008">pages 51-52, April 2017.</span></div>
<div style="position:absolute;left:124.80px;top:475.59px" class="cls_008"><span class="cls_008">[18]</span></div>
<div style="position:absolute;left:145.28px;top:475.59px" class="cls_008"><span class="cls_008">Proba samfunnsanalyse.  Trygdesvindel i norge - en kartlegging av fem</span></div>
<div style="position:absolute;left:145.28px;top:487.55px" class="cls_008"><span class="cls_008">stønadsordninger. Proba-rapport, 2013-05, 05 2013.</span></div>
<div style="position:absolute;left:124.80px;top:507.47px" class="cls_008"><span class="cls_008">[19]</span></div>
<div style="position:absolute;left:145.28px;top:507.47px" class="cls_008"><span class="cls_008">Erich Schubert, Jörg Sander, Martin Ester, Hans Peter Kriegel, and Xi-</span></div>
<div style="position:absolute;left:145.28px;top:519.43px" class="cls_008"><span class="cls_008">aowei Xu. Dbscan revisited, revisited: Why and how you should (still) use</span></div>
<div style="position:absolute;left:145.28px;top:531.38px" class="cls_008"><span class="cls_008">dbscan. ACM Trans. Database Syst., 42(3):19:1-19:21, July 2017.</span></div>
<div style="position:absolute;left:124.80px;top:551.31px" class="cls_008"><span class="cls_008">[20]</span></div>
<div style="position:absolute;left:145.28px;top:551.31px" class="cls_008"><span class="cls_008">Shokri Z. Selim and M. A. Ismail. K-means-type algorithms: A generalized</span></div>
<div style="position:absolute;left:145.28px;top:563.26px" class="cls_008"><span class="cls_008">convergence theorem and characterization of local optimality. IEEE Trans.</span></div>
<div style="position:absolute;left:145.28px;top:575.22px" class="cls_008"><span class="cls_008">Pattern Anal. Mach. Intell., 6(1):81-87, January 1984.</span></div>
<div style="position:absolute;left:124.80px;top:595.15px" class="cls_008"><span class="cls_008">[21]</span></div>
<div style="position:absolute;left:145.28px;top:595.15px" class="cls_008"><span class="cls_008">Skatteetaten.</span></div>
<div style="position:absolute;left:219.19px;top:595.15px" class="cls_008"><span class="cls_008">Ordinary  employment.    </span><A HREF="https://www.skatteetaten.no/en/business-and-organisation/employer/the-a-melding/the-a-melding-guide/employment/type-of-employment/ordinary-employment/">https://www.skatteetaten.</A> </div>
<div style="position:absolute;left:145.28px;top:607.10px" class="cls_008"><span class="cls_008"> </span><A HREF="https://www.skatteetaten.no/en/business-and-organisation/employer/the-a-melding/the-a-melding-guide/employment/type-of-employment/ordinary-employment/">no/en/business-and-organisation/employer/the-a-melding/</A> </div>
<div style="position:absolute;left:145.28px;top:619.06px" class="cls_008"><span class="cls_008"> </span><A HREF="https://www.skatteetaten.no/en/business-and-organisation/employer/the-a-melding/the-a-melding-guide/employment/type-of-employment/ordinary-employment/">the-a-melding-guide/employment/type-of-employment/</A> </div>
<div style="position:absolute;left:145.28px;top:631.01px" class="cls_008"><span class="cls_008"> </span><A HREF="https://www.skatteetaten.no/en/business-and-organisation/employer/the-a-melding/the-a-melding-guide/employment/type-of-employment/ordinary-employment/">ordinary-employment/</A>, 2018. [Online; accessed 21-May-2019].</div>
<div style="position:absolute;left:124.80px;top:650.94px" class="cls_008"><span class="cls_008">[22]</span></div>
<div style="position:absolute;left:145.28px;top:650.94px" class="cls_008"><span class="cls_008">Skatteetaten. Working hours arrangement. </span><A HREF="https://www.skatteetaten.no/en/business-and-organisation/employer/the-a-melding/the-a-melding-guide/employment/information-on-employment/working-hours-arrangement/">https://www.skatteetaten.</A> </div>
<div style="position:absolute;left:145.28px;top:662.89px" class="cls_008"><span class="cls_008"> </span><A HREF="https://www.skatteetaten.no/en/business-and-organisation/employer/the-a-melding/the-a-melding-guide/employment/information-on-employment/working-hours-arrangement/">no/en/business-and-organisation/employer/the-a-melding/</A> </div>
<div style="position:absolute;left:145.28px;top:674.85px" class="cls_008"><span class="cls_008"> </span><A HREF="https://www.skatteetaten.no/en/business-and-organisation/employer/the-a-melding/the-a-melding-guide/employment/information-on-employment/working-hours-arrangement/">the-a-melding-guide/employment/information-on-employment/</A> </div>
<div style="position:absolute;left:145.28px;top:686.80px" class="cls_008"><span class="cls_008"> </span><A HREF="https://www.skatteetaten.no/en/business-and-organisation/employer/the-a-melding/the-a-melding-guide/employment/information-on-employment/working-hours-arrangement/">working-hours-arrangement/</A>, 2018. [Online; accessed 21-May-2019].</div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">124</span></div>
</div>
<div style="position:absolute;left:50%;margin-left:-297px;top:108077px;width:595px;height:841px;border-style:outset;overflow:hidden">
<div style="position:absolute;left:0px;top:0px">
<img src="daaba37a-8272-11ec-a980-0cc47a792c0a_id_daaba37a-8272-11ec-a980-0cc47a792c0a_files/background128.jpg" width=595 height=841></div>
<div style="position:absolute;left:124.80px;top:124.91px" class="cls_008"><span class="cls_008">[23] Kamepalli Sujatha and K. Raja Sekhara Rao.  A survey on infrequent</span></div>
<div style="position:absolute;left:145.28px;top:136.86px" class="cls_008"><span class="cls_008">pattern mining. International Journal of Advances in Engineering & Tech-</span></div>
<div style="position:absolute;left:145.28px;top:148.82px" class="cls_008"><span class="cls_008">nology, 6:1728-1732, 9 2013.</span></div>
<div style="position:absolute;left:124.80px;top:168.74px" class="cls_008"><span class="cls_008">[24] Laszlo Szathmary, Amedeo Napoli, and Petko Valtchev. Towards rare item-</span></div>
<div style="position:absolute;left:145.28px;top:180.70px" class="cls_008"><span class="cls_008">set mining. Proceedings - International Conference on Tools with Artificial</span></div>
<div style="position:absolute;left:145.28px;top:192.65px" class="cls_008"><span class="cls_008">Intelligence, ICTAI, 1:305-312, 11 2007.</span></div>
<div style="position:absolute;left:124.80px;top:212.58px" class="cls_008"><span class="cls_008">[25] Laszlo Szathmary, Petko Valtchev, and Amedeo Napoli.  Finding mini-</span></div>
<div style="position:absolute;left:145.28px;top:224.54px" class="cls_008"><span class="cls_008">mal rare itemsets and rare association rules. In Yaxin Bi and Mary-Anne</span></div>
<div style="position:absolute;left:145.28px;top:236.49px" class="cls_008"><span class="cls_008">Williams, editors, Knowledge Science, Engineering and Management, pages</span></div>
<div style="position:absolute;left:145.28px;top:248.45px" class="cls_008"><span class="cls_008">16-27, Berlin, Heidelberg, 2010. Springer Berlin Heidelberg.</span></div>
<div style="position:absolute;left:124.80px;top:268.37px" class="cls_008"><span class="cls_008">[26] Wikipedia contributors.  Curse of dimensionality — Wikipedia, the free</span></div>
<div style="position:absolute;left:145.28px;top:280.33px" class="cls_008"><span class="cls_008">encyclopedia.  </span><A HREF="https://en.wikipedia.org/w/index.php?title=Curse_of_dimensionality&oldid=890330557">https://en.wikipedia.org/w/index.php?title=Curse_</A> </div>
<div style="position:absolute;left:145.28px;top:292.28px" class="cls_008"><span class="cls_008"> </span><A HREF="https://en.wikipedia.org/w/index.php?title=Curse_of_dimensionality&oldid=890330557">of_dimensionality&oldid=890330557</A>, 2019.</div>
<div style="position:absolute;left:354.02px;top:292.28px" class="cls_008"><span class="cls_008">[Online; accessed 21-May-</span></div>
<div style="position:absolute;left:145.28px;top:304.24px" class="cls_008"><span class="cls_008">2019].</span></div>
<div style="position:absolute;left:124.80px;top:324.16px" class="cls_008"><span class="cls_008">[27] Wikipedia contributors.  K-means clustering — Wikipedia, the free en-</span></div>
<div style="position:absolute;left:145.28px;top:336.12px" class="cls_008"><span class="cls_008">cyclopedia.  </span><A HREF="https://en.wikipedia.org/w/index.php?title=K-means_clustering&oldid=898072870">https://en.wikipedia.org/w/index.php?title=K-means_</A> </div>
<div style="position:absolute;left:145.28px;top:348.07px" class="cls_008"><span class="cls_008"> </span><A HREF="https://en.wikipedia.org/w/index.php?title=K-means_clustering&oldid=898072870">clustering&oldid=898072870</A>, 2019. [Online; accessed 21-May-2019].</div>
<div style="position:absolute;left:289.19px;top:740.60px" class="cls_008"><span class="cls_008">125</span></div>
</div>

</body>
</html>
